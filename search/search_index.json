{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]"},"docs":[{"location":"","text":"LUME-services LUME-services provides a set of common services for use in the orchestrations of models (here defined as a self-contained workflow) and simulations: Contextualized file service (local/mounted/remote) Model database service for tracking model deployments Results database service for storing model output Scheduling service for deploying model runs with Prefect Abstracted HPC service for integration with scientific computing infrastructure. The intent of these tools are to streamline the packaging of modeling/simulation code by providing contextual flexibility with respect to service clusters. The framework uses runtime configurations for initializing backend implementation of all services, facilitating portability from local, to distributed dev, or production environments. The service interfaces developed for LUME-services are isolated, which allows for abstraction and modularized update points, and consistent with a microservice-based application architecture, prioritizing scalability, maintainability, and parallelized development and maintenance. Services can be deployed in clusters of containers or on remote resources subject to user constraints. Example configurations of Docker and Kubernetes clusters shown below. * Docker: * Kubernetes: Alternatively, users can execute run workflows directly in their process by configuring a local backend. Features: * Standard schema for managing model metadata * Differentiated local and remote execution environments suitable for fast/slow executing models, respectively * Supports deployment of models into a standardized container by exposing pip and conda commands to container * Versioning at model and workflow levels * Simple reversion and execution of prior model versions * Configurable result persistence * Visualization tools for model results Requirements Use of the LUME-services requires Docker Engine https://docs.docker.com/engine/install/ Installation This package can be installed from GitHub using: pip install git+https://github.com/slaclab/lume-services.git or from conda using ... (once configured with conda-forge)","title":"LUME-Services"},{"location":"#lume-services","text":"LUME-services provides a set of common services for use in the orchestrations of models (here defined as a self-contained workflow) and simulations: Contextualized file service (local/mounted/remote) Model database service for tracking model deployments Results database service for storing model output Scheduling service for deploying model runs with Prefect Abstracted HPC service for integration with scientific computing infrastructure. The intent of these tools are to streamline the packaging of modeling/simulation code by providing contextual flexibility with respect to service clusters. The framework uses runtime configurations for initializing backend implementation of all services, facilitating portability from local, to distributed dev, or production environments. The service interfaces developed for LUME-services are isolated, which allows for abstraction and modularized update points, and consistent with a microservice-based application architecture, prioritizing scalability, maintainability, and parallelized development and maintenance. Services can be deployed in clusters of containers or on remote resources subject to user constraints. Example configurations of Docker and Kubernetes clusters shown below. * Docker: * Kubernetes: Alternatively, users can execute run workflows directly in their process by configuring a local backend. Features: * Standard schema for managing model metadata * Differentiated local and remote execution environments suitable for fast/slow executing models, respectively * Supports deployment of models into a standardized container by exposing pip and conda commands to container * Versioning at model and workflow levels * Simple reversion and execution of prior model versions * Configurable result persistence * Visualization tools for model results","title":"LUME-services"},{"location":"#requirements","text":"Use of the LUME-services requires Docker Engine https://docs.docker.com/engine/install/","title":"Requirements"},{"location":"#installation","text":"This package can be installed from GitHub using: pip install git+https://github.com/slaclab/lume-services.git or from conda using ... (once configured with conda-forge)","title":"Installation"},{"location":"cli/","text":"LUME-services cli LUME-services is packaged with a number of cli tools. lume-services Usage: lume-services [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. docker Usage: lume-services docker [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. start-docker-services Start cluster of docker services. Usage: lume-services docker start-docker-services [OPTIONS] Options: --project_name TEXT Name of docker project for labeling docker-compose. --timeout FLOAT Time allotted for successful docker-compose startup. --pause FLOAT Pause between successive polls of docker-compose services. --help Show this message and exit.","title":"CLI"},{"location":"cli/#lume-services-cli","text":"LUME-services is packaged with a number of cli tools.","title":"LUME-services cli"},{"location":"cli/#lume-services","text":"Usage: lume-services [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit.","title":"lume-services"},{"location":"cli/#docker","text":"Usage: lume-services docker [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit.","title":"docker"},{"location":"cli/#start-docker-services","text":"Start cluster of docker services. Usage: lume-services docker start-docker-services [OPTIONS] Options: --project_name TEXT Name of docker project for labeling docker-compose. --timeout FLOAT Time allotted for successful docker-compose startup. --pause FLOAT Pause between successive polls of docker-compose services. --help Show this message and exit.","title":"start-docker-services"},{"location":"config/","text":"Configuration LUME-services uses injection for runtime configuration of services. This means that programs can use the same code in a number of different environments simply by changing environment variable definitions. Programs using the standard services packaged with LUME-services (the MongoDB implementation of Results Database, MySQL implementation of Model Registry), can use the configuration tools packaged with LUME-services directly by calling the configure script during code execution: from lume_services.config import configure, LUMEServicesSettings lume_services_settings = LUMEServicesSettings( ) # run configure by parsing LUME environment variables configure() # run configure with manual configuration ... LUME_MODEL_DB__HOST=127.0.0.1 LUME_MODEL_DB__USER=root LUME_MODEL_DB__PASSWORD=test LUME_MODEL_DB__PORT=3306 LUME_MODEL_DB__DATABASE=model_db LUME_MODEL_DB__CONNECTION__POOL_SIZE=1 export LUME_PREFECT__SERVER__TAG=core-1.2.4 export LUME_PREFECT__SERVER__HOST_PORT=4200 export LUME_PREFECT__SERVER__HOST=127.0.0.1 export LUME_RESULTS_DB__HOST=127.0.0.1 export LUME_RESULTS_DB__PORT=27017 export LUME_RESULTS_DB__USERNAME=root export LUME_RESULTS_DB__PASSWORD=password export LUME_RESULTS_DB__DATABASE=test Submitting workflows with the appropriate configuration you may elect to change env vars on your submitted jobs Configuration of the job environment must respect hostnames available to their own networks Overriding configuration values model: author: Jaqueline Garrhan laboratory: SLAC facility: LCLS beampath: cu_hxr description: Example model deployment: version: v0.0 source: https://github.com/jacquelinegarrahan/my-model-repo variables: my-model-repo/my_model_repo/files/variables.yaml flow_name: example_cu_hxr_0.0 input_variables: input_variable_1: type: array input_variable_2: type: scalar output_variables: output_variable_1: type: scalar output_variable_2: type: array Multi-flow registration flow: order: - epics_pv_collection - scale - normalize - example_cu_hxr_0.0 epics: example_cu_hxr_epics_map.yaml EPICS mapping.yaml flow: order: - name: epics_pv_collection config_file: example_cu_hxr_epics_map.yaml - name: scale factor: 5 - name: normalize - name: example_cu_hxr_0.0 example_cu_hxr_epics_map.yaml input_variables: input_variable_1: pvname: test:input1 protocol: pva input_variable_1: pvname: test:input2 protocol: ca output: pvname: test:output fields: - output_variable_1 - output_variable_2","title":"Configuration"},{"location":"config/#configuration","text":"LUME-services uses injection for runtime configuration of services. This means that programs can use the same code in a number of different environments simply by changing environment variable definitions. Programs using the standard services packaged with LUME-services (the MongoDB implementation of Results Database, MySQL implementation of Model Registry), can use the configuration tools packaged with LUME-services directly by calling the configure script during code execution: from lume_services.config import configure, LUMEServicesSettings lume_services_settings = LUMEServicesSettings( ) # run configure by parsing LUME environment variables configure() # run configure with manual configuration ... LUME_MODEL_DB__HOST=127.0.0.1 LUME_MODEL_DB__USER=root LUME_MODEL_DB__PASSWORD=test LUME_MODEL_DB__PORT=3306 LUME_MODEL_DB__DATABASE=model_db LUME_MODEL_DB__CONNECTION__POOL_SIZE=1 export LUME_PREFECT__SERVER__TAG=core-1.2.4 export LUME_PREFECT__SERVER__HOST_PORT=4200 export LUME_PREFECT__SERVER__HOST=127.0.0.1 export LUME_RESULTS_DB__HOST=127.0.0.1 export LUME_RESULTS_DB__PORT=27017 export LUME_RESULTS_DB__USERNAME=root export LUME_RESULTS_DB__PASSWORD=password export LUME_RESULTS_DB__DATABASE=test","title":"Configuration"},{"location":"config/#submitting-workflows-with-the-appropriate-configuration","text":"you may elect to change env vars on your submitted jobs Configuration of the job environment must respect hostnames available to their own networks","title":"Submitting workflows with the appropriate configuration"},{"location":"config/#overriding-configuration-values","text":"model: author: Jaqueline Garrhan laboratory: SLAC facility: LCLS beampath: cu_hxr description: Example model deployment: version: v0.0 source: https://github.com/jacquelinegarrahan/my-model-repo variables: my-model-repo/my_model_repo/files/variables.yaml flow_name: example_cu_hxr_0.0 input_variables: input_variable_1: type: array input_variable_2: type: scalar output_variables: output_variable_1: type: scalar output_variable_2: type: array Multi-flow registration flow: order: - epics_pv_collection - scale - normalize - example_cu_hxr_0.0 epics: example_cu_hxr_epics_map.yaml EPICS mapping.yaml flow: order: - name: epics_pv_collection config_file: example_cu_hxr_epics_map.yaml - name: scale factor: 5 - name: normalize - name: example_cu_hxr_0.0 example_cu_hxr_epics_map.yaml input_variables: input_variable_1: pvname: test:input1 protocol: pva input_variable_1: pvname: test:input2 protocol: ca output: pvname: test:output fields: - output_variable_1 - output_variable_2","title":"Overriding configuration values"},{"location":"demo/","text":"Demo LUME-services is packaged with a docker-compose development spec that can be used to spin up a devlopment environment for local testing of packages. Host port forwardings have default values, but can be modified at spin-up using a subset of the LUME-services configuration environment variables. Environment variable Default LUME_MODEL_DB__USER root LUME_MODEL_DB__PASSWORD password LUME_MODEL_DB__PORT 3306 LUME_PREFECT__SERVER__TAG core-1.2.4 LUME_PREFECT__SERVER__HOST_PORT 4200 LUME_RESULTS_DB__PORT 27017 LUME_RESULTS_DB__USERNAME root LUME_RESULTS_DB__PASSWORD password Additional variables control post-spin-up initialization of databases: | LUME_RESULTS_DB__DATABASE | test | export LUME_PREFECT_BACKEND=docker Start services with docker-compose Use utility packaged with lume-services to start dockerized services: python lume_services/cli/docker.py start-docker-services Navigate to: http://localhost:8080/?flows","title":"Demo"},{"location":"demo/#demo","text":"LUME-services is packaged with a docker-compose development spec that can be used to spin up a devlopment environment for local testing of packages. Host port forwardings have default values, but can be modified at spin-up using a subset of the LUME-services configuration environment variables. Environment variable Default LUME_MODEL_DB__USER root LUME_MODEL_DB__PASSWORD password LUME_MODEL_DB__PORT 3306 LUME_PREFECT__SERVER__TAG core-1.2.4 LUME_PREFECT__SERVER__HOST_PORT 4200 LUME_RESULTS_DB__PORT 27017 LUME_RESULTS_DB__USERNAME root LUME_RESULTS_DB__PASSWORD password Additional variables control post-spin-up initialization of databases: | LUME_RESULTS_DB__DATABASE | test | export LUME_PREFECT_BACKEND=docker","title":"Demo"},{"location":"demo/#start-services-with-docker-compose","text":"Use utility packaged with lume-services to start dockerized services: python lume_services/cli/docker.py start-docker-services Navigate to: http://localhost:8080/?flows","title":"Start services with docker-compose"},{"location":"model_packaging/","text":"Model packaging Motivation... Templating allows us to ... Because we've chosen the approach of having a single docker image representing our body of models, Requirements Must include lume-services steps 1. Create package repository .json template \"{{cookiecutter.repo_name}}\" \u251c\u2500 .github/ | \u251c\u2500 workflows/ | | \u251c\u2500 build_flow_docker.yaml \u2502 \u2502 \u251c\u2500 tests.yaml \u251c\u2500 \"{{cookiecutter.project_slug}}\" | \u251c\u2500 files/ | | \u251c\u2500 __init__.py | | \u251c\u2500 variables.yaml | \u251c\u2500 flow/ | | \u251c\u2500 __init__.py | | \u251c\u2500 _entrypoint.sh | | \u251c\u2500 Dockerfile | | \u251c\u2500 flow.py | \u251c\u2500 tests/ | \u251c\u2500 __init__.py | \u251c\u2500 config.py | \u251c\u2500 model.py \u251c\u2500 dev-requirements.txt \u251c\u2500 requirements.txt \u251c\u2500 README.md \u251c\u2500 MANIFEST.in \u251c\u2500 setup.cfg \u251c\u2500 setup.py \u251c\u2500 model.yaml 2. Define your model variables Open your-project/your_project/files/variables.yml . The file will look like: 3. Define your model evaluation method This class is extensible and can accomodate as many additional methods as you'd like to include. 4. Define your flow A minimal flow will accept ... Execution of a flow is defined in the blurb: Where task1 , task2 , and task3 are defined in the module body using the @task decorator. Flow targets: 1. Filesystem target 2. Mongodb target Flows are also extensible and can accomodate plenty of complexity. Using database targets requires a configured resources to be available to the flow at runtime. The README.md file should contain a comprehensive outline of variables accepted by your flow. 5. Actions Define GitHub secret variables Caveats Because the repository is heavily templated, there are several things that may break on modification. The tests defined in the your-project/your_project/tests file are designed to test the following conditions: 1. Clearly defined entrypoints 2. Properly formatted and registerable flows 4. JSON FILE WITH THE FOLLOWING: { \"author\": \"Jacqueline Garrahan\", \"email\": \"jacquelinegarrahan@gmail.com\", \"github_username\": \"jacquelinegarrahan\", \"project_name\": \"My Package\", # Python importable package \"project_slug\": \"{{ cookiecutter.project_name.lower().replace(' ', '_').replace('-', '_') }}\", \"project_short_description\": \"Python Boilerplate contains all the boilerplate you need to create a Python package.\", \"pypi_username\": \"{{ cookiecutter.github_username }}\", \"version\": \"0.1.0\", \"use_pytest\": \"n\", \"use_black\": \"n\", \"use_pypi_deployment_with_travis\": \"y\", \"add_pyup_badge\": \"n\", \"command_line_interface\": [\"Click\", \"Argparse\", \"No command-line interface\"], \"create_author_file\": \"y\", \"open_source_license\": [\"MIT license\", \"BSD license\", \"ISC license\", \"Apache Software License 2.0\", \"GNU General Public License v3\", \"Not open source\"] } docker load --input /tmp/myimage.tar","title":"Model Packaging"},{"location":"model_packaging/#model-packaging","text":"Motivation... Templating allows us to ... Because we've chosen the approach of having a single docker image representing our body of models,","title":"Model packaging"},{"location":"model_packaging/#requirements","text":"Must include lume-services","title":"Requirements"},{"location":"model_packaging/#steps","text":"","title":"steps"},{"location":"model_packaging/#1-create-package-repository","text":".json template \"{{cookiecutter.repo_name}}\" \u251c\u2500 .github/ | \u251c\u2500 workflows/ | | \u251c\u2500 build_flow_docker.yaml \u2502 \u2502 \u251c\u2500 tests.yaml \u251c\u2500 \"{{cookiecutter.project_slug}}\" | \u251c\u2500 files/ | | \u251c\u2500 __init__.py | | \u251c\u2500 variables.yaml | \u251c\u2500 flow/ | | \u251c\u2500 __init__.py | | \u251c\u2500 _entrypoint.sh | | \u251c\u2500 Dockerfile | | \u251c\u2500 flow.py | \u251c\u2500 tests/ | \u251c\u2500 __init__.py | \u251c\u2500 config.py | \u251c\u2500 model.py \u251c\u2500 dev-requirements.txt \u251c\u2500 requirements.txt \u251c\u2500 README.md \u251c\u2500 MANIFEST.in \u251c\u2500 setup.cfg \u251c\u2500 setup.py \u251c\u2500 model.yaml","title":"1. Create package repository"},{"location":"model_packaging/#2-define-your-model-variables","text":"Open your-project/your_project/files/variables.yml . The file will look like:","title":"2. Define your model variables"},{"location":"model_packaging/#3-define-your-model-evaluation-method","text":"This class is extensible and can accomodate as many additional methods as you'd like to include.","title":"3. Define your model evaluation method"},{"location":"model_packaging/#4-define-your-flow","text":"A minimal flow will accept ... Execution of a flow is defined in the blurb: Where task1 , task2 , and task3 are defined in the module body using the @task decorator. Flow targets: 1. Filesystem target 2. Mongodb target Flows are also extensible and can accomodate plenty of complexity. Using database targets requires a configured resources to be available to the flow at runtime. The README.md file should contain a comprehensive outline of variables accepted by your flow.","title":"4.  Define your flow"},{"location":"model_packaging/#5-actions","text":"Define GitHub secret variables","title":"5. Actions"},{"location":"model_packaging/#caveats","text":"Because the repository is heavily templated, there are several things that may break on modification. The tests defined in the your-project/your_project/tests file are designed to test the following conditions: 1. Clearly defined entrypoints 2. Properly formatted and registerable flows 4. JSON FILE WITH THE FOLLOWING: { \"author\": \"Jacqueline Garrahan\", \"email\": \"jacquelinegarrahan@gmail.com\", \"github_username\": \"jacquelinegarrahan\", \"project_name\": \"My Package\", # Python importable package \"project_slug\": \"{{ cookiecutter.project_name.lower().replace(' ', '_').replace('-', '_') }}\", \"project_short_description\": \"Python Boilerplate contains all the boilerplate you need to create a Python package.\", \"pypi_username\": \"{{ cookiecutter.github_username }}\", \"version\": \"0.1.0\", \"use_pytest\": \"n\", \"use_black\": \"n\", \"use_pypi_deployment_with_travis\": \"y\", \"add_pyup_badge\": \"n\", \"command_line_interface\": [\"Click\", \"Argparse\", \"No command-line interface\"], \"create_author_file\": \"y\", \"open_source_license\": [\"MIT license\", \"BSD license\", \"ISC license\", \"Apache Software License 2.0\", \"GNU General Public License v3\", \"Not open source\"] } docker load --input /tmp/myimage.tar","title":"Caveats"},{"location":"workflows/","text":"Workflows LUME-services allows us to build workflows using Prefect's Flow APIs. Flows can be conceptualized of as scoped units of work. A flow looks like: Parameters are data objects passed into the flow at runtime. Variable names inside the flow context are used to compose the workflow Configuring flows for use with LUME-services configure_services task uses environment variable names to configure the lume-services api endpoints must be set as upstream taks to any tasks using those services using my_task.set_upstream(configure_task) within the flow context. Flow parameters Flow Parameters have some constraints. To see why those constraints exist, see developer docs here . 1. Flow-level parameters must be serializable, meaning they must be of types: | Python | JSON | |----------------------------| | dict | object | | list, tuple | array | | str | string | | int, long, float | number | | True | true | | False | false | | None | | In order to access the results of tasks outside a flow, the task-level results must be JSON serializable. LUME-services packages some utilities for interacting with custom result types using JSON representations of the result that can be used to load at runtime. Common tasks from prefect import task, Flow, Parameter from prefect.storage import Module from lume_services.tasks import configure_services, SaveFile from lume_services.files import TextFile import logging logger = logging.getLogger(__name__) logger.setLevel(logging.DEBUG) @task def append_text(text1, text2): return text1 + text2 save_file = SaveFile(name=\"save_text_file\") with Flow(\"flow1\", storage=Module(__name__)) as flow1: text1 = Parameter(\"text1\") text2 = Parameter(\"text2\") filename = Parameter(\"filename\") filesystem_identifier = Parameter(\"filesystem_identifier\") configure = configure_services() new_text = append_text(text1, text2) file = save_file( obj=new_text, file_type=TextFile, filename=filename, filesystem_identifier=filesystem_identifier, ) file.set_upstream(configure) Results name results Database results in order to save multiple results to the database, define a name for the database result File results if saving multiple files in the workflow, task name should be passed when initializing the task Result customization All result tasks are subclasses of the prefect Task object and accept all Task initialization arguments... Flow-of-flows Yaml * task name must match name","title":"Workflows"},{"location":"workflows/#workflows","text":"LUME-services allows us to build workflows using Prefect's Flow APIs. Flows can be conceptualized of as scoped units of work. A flow looks like: Parameters are data objects passed into the flow at runtime. Variable names inside the flow context are used to compose the workflow","title":"Workflows"},{"location":"workflows/#configuring-flows-for-use-with-lume-services","text":"configure_services task uses environment variable names to configure the lume-services api endpoints must be set as upstream taks to any tasks using those services using my_task.set_upstream(configure_task) within the flow context.","title":"Configuring flows for use with LUME-services"},{"location":"workflows/#flow-parameters","text":"Flow Parameters have some constraints. To see why those constraints exist, see developer docs here . 1. Flow-level parameters must be serializable, meaning they must be of types: | Python | JSON | |----------------------------| | dict | object | | list, tuple | array | | str | string | | int, long, float | number | | True | true | | False | false | | None | | In order to access the results of tasks outside a flow, the task-level results must be JSON serializable. LUME-services packages some utilities for interacting with custom result types using JSON representations of the result that can be used to load at runtime.","title":"Flow parameters"},{"location":"workflows/#common-tasks","text":"from prefect import task, Flow, Parameter from prefect.storage import Module from lume_services.tasks import configure_services, SaveFile from lume_services.files import TextFile import logging logger = logging.getLogger(__name__) logger.setLevel(logging.DEBUG) @task def append_text(text1, text2): return text1 + text2 save_file = SaveFile(name=\"save_text_file\") with Flow(\"flow1\", storage=Module(__name__)) as flow1: text1 = Parameter(\"text1\") text2 = Parameter(\"text2\") filename = Parameter(\"filename\") filesystem_identifier = Parameter(\"filesystem_identifier\") configure = configure_services() new_text = append_text(text1, text2) file = save_file( obj=new_text, file_type=TextFile, filename=filename, filesystem_identifier=filesystem_identifier, ) file.set_upstream(configure)","title":"Common tasks"},{"location":"workflows/#results","text":"name results","title":"Results"},{"location":"workflows/#database-results","text":"in order to save multiple results to the database, define a name for the database result","title":"Database results"},{"location":"workflows/#file-results","text":"if saving multiple files in the workflow, task name should be passed when initializing the task","title":"File results"},{"location":"workflows/#result-customization","text":"All result tasks are subclasses of the prefect Task object and accept all Task initialization arguments...","title":"Result customization"},{"location":"workflows/#flow-of-flows","text":"Yaml * task name must match name","title":"Flow-of-flows"},{"location":"api/config/","text":"lume_services.config Attributes context module-attribute context : containers . DeclarativeContainer = None Classes Context Bases: containers . DeclarativeContainer Attributes config class-attribute config = providers . Configuration () mounted_filesystem class-attribute mounted_filesystem = providers . Dependency ( instance_of = MountedFilesystem , default = None ) local_filesystem class-attribute local_filesystem = providers . Singleton ( LocalFilesystem ) model_db class-attribute model_db = providers . Dependency ( ModelDB ) results_db class-attribute results_db = providers . Dependency ( instance_of = ResultsDB ) scheduling_backend class-attribute scheduling_backend = providers . Dependency ( instance_of = Backend ) file_service class-attribute file_service = providers . Singleton ( FileService , filesystems = providers . List ( local_filesystem , mounted_filesystem ), ) model_db_service class-attribute model_db_service = providers . Singleton ( ModelDBService , model_db = model_db ) results_db_service class-attribute results_db_service = providers . Singleton ( ResultsDBService , results_db = results_db ) scheduling_service class-attribute scheduling_service = providers . Singleton ( SchedulingService , backend = scheduling_backend ) wiring_config class-attribute wiring_config = containers . WiringConfiguration ( packages = [ \"lume_services.files\" , \"lume_services.results\" , \"lume_services.flows\" , ] ) LUMEServicesSettings Bases: BaseSettings Settings describing configuration for default LUME-services provider objects. Attributes model_db class-attribute model_db : Optional [ MySQLModelDBConfig ] results_db class-attribute results_db : Optional [ MongodbResultsDBConfig ] prefect class-attribute prefect : Optional [ PrefectConfig ] mounted_filesystem class-attribute mounted_filesystem : Optional [ MountedFilesystem ] backend class-attribute backend : str = 'local' Classes Config Attributes validate_assignment class-attribute validate_assignment = True env_prefix class-attribute env_prefix = 'LUME_' env_nested_delimiter class-attribute env_nested_delimiter = '__' Functions configure configure ( settings : LUMEServicesSettings = None ) Configure method with default methods for lume-services using MySQLModelDB and MongodbResultsDB. Source code in lume_services/config.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def configure ( settings : LUMEServicesSettings = None ): \"\"\"Configure method with default methods for lume-services using MySQLModelDB and MongodbResultsDB. \"\"\" if settings is None : try : settings = LUMEServicesSettings () except ValidationError as e : raise EnvironmentNotConfiguredError ( list_env_vars ( LUMEServicesSettings . schema ()), validation_error = e ) # apply prefect config if settings . prefect is not None : settings . prefect . apply () global context , _settings model_db = None if settings . model_db is not None : model_db = MySQLModelDB ( settings . model_db ) results_db = None if settings . results_db is not None : results_db = MongodbResultsDB ( settings . results_db ) # this could be moved to an enum if settings . backend is not None : if settings . backend == \"kubernetes\" : backend = KubernetesBackend ( config = settings . prefect ) elif settings . backend == \"docker\" : backend = DockerBackend ( config = settings . prefect ) elif settings . backend == \"local\" : backend = LocalBackend () else : raise ValueError ( f \"Unsupported backend { settings . backend } \" ) # default to local else : backend = LocalBackend () context = Context ( model_db = model_db , results_db = results_db , mounted_filesystem = settings . mounted_filesystem , scheduling_backend = backend , ) _settings = settings list_env_vars list_env_vars ( schema : dict = LUMEServicesSettings . schema (), prefix : str = LUMEServicesSettings . Config . env_prefix , delimiter : str = LUMEServicesSettings . Config . env_nested_delimiter , ) -> list Source code in lume_services/config.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def list_env_vars ( schema : dict = LUMEServicesSettings . schema (), prefix : str = LUMEServicesSettings . Config . env_prefix , delimiter : str = LUMEServicesSettings . Config . env_nested_delimiter , ) -> list : env_vars = { \"base\" : []} def unpack_props ( props , parent , env_vars = env_vars , prefix = prefix , delimiter = delimiter , schema = schema , ): for prop_name , prop in props . items (): if \"properties\" in prop : unpack_props ( prop [ \"properties\" ], prefix = f \" { prefix }{ delimiter }{ prop_name } \" ) elif \"allOf\" in prop : sub_prop_reference = prop [ \"allOf\" ][ 0 ][ \"$ref\" ] # prepare from format #/ sub_prop_reference = sub_prop_reference . replace ( \"#/\" , \"\" ) sub_prop_reference = sub_prop_reference . split ( \"/\" ) reference_locale = schema for reference in sub_prop_reference : reference_locale = reference_locale [ reference ] unpack_props ( reference_locale [ \"properties\" ], parent = parent , prefix = f \" { prefix }{ delimiter }{ prop_name } \" , ) else : if \"env_names\" in prop : prop_names = list ( prop [ \"env_names\" ]) env_vars [ parent ] += [ f \" { prefix }{ delimiter }{ name } \" . upper () for name in prop_names ] else : env_vars [ parent ] . append ( f \" { prefix }{ delimiter }{ prop_name } \" . upper ()) # iterate over top level definitions for item_name , item in schema [ \"properties\" ] . items (): env_name = list ( item [ \"env_names\" ])[ 0 ] if \"allOf\" in item : sub_prop_reference = item [ \"allOf\" ][ 0 ][ \"$ref\" ] # prepare from format #/ sub_prop_reference = sub_prop_reference . replace ( \"#/\" , \"\" ) sub_prop_reference = sub_prop_reference . split ( \"/\" ) reference_locale = schema for reference in sub_prop_reference : reference_locale = reference_locale [ reference ] env_vars [ item_name ] = [] unpack_props ( reference_locale [ \"properties\" ], prefix = env_name , parent = item_name ) else : env_vars [ \"base\" ] . append ( env_name . upper ()) # capitalize return env_vars","title":"Config"},{"location":"api/config/#lume_services.config","text":"","title":"config"},{"location":"api/config/#lume_services.config-attributes","text":"","title":"Attributes"},{"location":"api/config/#lume_services.config.context","text":"context : containers . DeclarativeContainer = None","title":"context"},{"location":"api/config/#lume_services.config-classes","text":"","title":"Classes"},{"location":"api/config/#lume_services.config.Context","text":"Bases: containers . DeclarativeContainer","title":"Context"},{"location":"api/config/#lume_services.config.Context-attributes","text":"","title":"Attributes"},{"location":"api/config/#lume_services.config.Context.config","text":"config = providers . Configuration ()","title":"config"},{"location":"api/config/#lume_services.config.Context.mounted_filesystem","text":"mounted_filesystem = providers . Dependency ( instance_of = MountedFilesystem , default = None )","title":"mounted_filesystem"},{"location":"api/config/#lume_services.config.Context.local_filesystem","text":"local_filesystem = providers . Singleton ( LocalFilesystem )","title":"local_filesystem"},{"location":"api/config/#lume_services.config.Context.model_db","text":"model_db = providers . Dependency ( ModelDB )","title":"model_db"},{"location":"api/config/#lume_services.config.Context.results_db","text":"results_db = providers . Dependency ( instance_of = ResultsDB )","title":"results_db"},{"location":"api/config/#lume_services.config.Context.scheduling_backend","text":"scheduling_backend = providers . Dependency ( instance_of = Backend )","title":"scheduling_backend"},{"location":"api/config/#lume_services.config.Context.file_service","text":"file_service = providers . Singleton ( FileService , filesystems = providers . List ( local_filesystem , mounted_filesystem ), )","title":"file_service"},{"location":"api/config/#lume_services.config.Context.model_db_service","text":"model_db_service = providers . Singleton ( ModelDBService , model_db = model_db )","title":"model_db_service"},{"location":"api/config/#lume_services.config.Context.results_db_service","text":"results_db_service = providers . Singleton ( ResultsDBService , results_db = results_db )","title":"results_db_service"},{"location":"api/config/#lume_services.config.Context.scheduling_service","text":"scheduling_service = providers . Singleton ( SchedulingService , backend = scheduling_backend )","title":"scheduling_service"},{"location":"api/config/#lume_services.config.Context.wiring_config","text":"wiring_config = containers . WiringConfiguration ( packages = [ \"lume_services.files\" , \"lume_services.results\" , \"lume_services.flows\" , ] )","title":"wiring_config"},{"location":"api/config/#lume_services.config.LUMEServicesSettings","text":"Bases: BaseSettings Settings describing configuration for default LUME-services provider objects.","title":"LUMEServicesSettings"},{"location":"api/config/#lume_services.config.LUMEServicesSettings-attributes","text":"","title":"Attributes"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.model_db","text":"model_db : Optional [ MySQLModelDBConfig ]","title":"model_db"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.results_db","text":"results_db : Optional [ MongodbResultsDBConfig ]","title":"results_db"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.prefect","text":"prefect : Optional [ PrefectConfig ]","title":"prefect"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.mounted_filesystem","text":"mounted_filesystem : Optional [ MountedFilesystem ]","title":"mounted_filesystem"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.backend","text":"backend : str = 'local'","title":"backend"},{"location":"api/config/#lume_services.config.LUMEServicesSettings-classes","text":"","title":"Classes"},{"location":"api/config/#lume_services.config.LUMEServicesSettings.Config","text":"Attributes validate_assignment class-attribute validate_assignment = True env_prefix class-attribute env_prefix = 'LUME_' env_nested_delimiter class-attribute env_nested_delimiter = '__'","title":"Config"},{"location":"api/config/#lume_services.config-functions","text":"","title":"Functions"},{"location":"api/config/#lume_services.config.configure","text":"configure ( settings : LUMEServicesSettings = None ) Configure method with default methods for lume-services using MySQLModelDB and MongodbResultsDB. Source code in lume_services/config.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def configure ( settings : LUMEServicesSettings = None ): \"\"\"Configure method with default methods for lume-services using MySQLModelDB and MongodbResultsDB. \"\"\" if settings is None : try : settings = LUMEServicesSettings () except ValidationError as e : raise EnvironmentNotConfiguredError ( list_env_vars ( LUMEServicesSettings . schema ()), validation_error = e ) # apply prefect config if settings . prefect is not None : settings . prefect . apply () global context , _settings model_db = None if settings . model_db is not None : model_db = MySQLModelDB ( settings . model_db ) results_db = None if settings . results_db is not None : results_db = MongodbResultsDB ( settings . results_db ) # this could be moved to an enum if settings . backend is not None : if settings . backend == \"kubernetes\" : backend = KubernetesBackend ( config = settings . prefect ) elif settings . backend == \"docker\" : backend = DockerBackend ( config = settings . prefect ) elif settings . backend == \"local\" : backend = LocalBackend () else : raise ValueError ( f \"Unsupported backend { settings . backend } \" ) # default to local else : backend = LocalBackend () context = Context ( model_db = model_db , results_db = results_db , mounted_filesystem = settings . mounted_filesystem , scheduling_backend = backend , ) _settings = settings","title":"configure()"},{"location":"api/config/#lume_services.config.list_env_vars","text":"list_env_vars ( schema : dict = LUMEServicesSettings . schema (), prefix : str = LUMEServicesSettings . Config . env_prefix , delimiter : str = LUMEServicesSettings . Config . env_nested_delimiter , ) -> list Source code in lume_services/config.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def list_env_vars ( schema : dict = LUMEServicesSettings . schema (), prefix : str = LUMEServicesSettings . Config . env_prefix , delimiter : str = LUMEServicesSettings . Config . env_nested_delimiter , ) -> list : env_vars = { \"base\" : []} def unpack_props ( props , parent , env_vars = env_vars , prefix = prefix , delimiter = delimiter , schema = schema , ): for prop_name , prop in props . items (): if \"properties\" in prop : unpack_props ( prop [ \"properties\" ], prefix = f \" { prefix }{ delimiter }{ prop_name } \" ) elif \"allOf\" in prop : sub_prop_reference = prop [ \"allOf\" ][ 0 ][ \"$ref\" ] # prepare from format #/ sub_prop_reference = sub_prop_reference . replace ( \"#/\" , \"\" ) sub_prop_reference = sub_prop_reference . split ( \"/\" ) reference_locale = schema for reference in sub_prop_reference : reference_locale = reference_locale [ reference ] unpack_props ( reference_locale [ \"properties\" ], parent = parent , prefix = f \" { prefix }{ delimiter }{ prop_name } \" , ) else : if \"env_names\" in prop : prop_names = list ( prop [ \"env_names\" ]) env_vars [ parent ] += [ f \" { prefix }{ delimiter }{ name } \" . upper () for name in prop_names ] else : env_vars [ parent ] . append ( f \" { prefix }{ delimiter }{ prop_name } \" . upper ()) # iterate over top level definitions for item_name , item in schema [ \"properties\" ] . items (): env_name = list ( item [ \"env_names\" ])[ 0 ] if \"allOf\" in item : sub_prop_reference = item [ \"allOf\" ][ 0 ][ \"$ref\" ] # prepare from format #/ sub_prop_reference = sub_prop_reference . replace ( \"#/\" , \"\" ) sub_prop_reference = sub_prop_reference . split ( \"/\" ) reference_locale = schema for reference in sub_prop_reference : reference_locale = reference_locale [ reference ] env_vars [ item_name ] = [] unpack_props ( reference_locale [ \"properties\" ], prefix = env_name , parent = item_name ) else : env_vars [ \"base\" ] . append ( env_name . upper ()) # capitalize return env_vars","title":"list_env_vars()"},{"location":"api/errors/","text":"lume_services.errors Classes EnvironmentNotConfiguredError EnvironmentNotConfiguredError ( env_vars , validation_error : ValidationError ) Bases: Exception Error for marking unconfigured environment. Source code in lume_services/errors.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , env_vars , validation_error : ValidationError ): self . env = dict ( os . environ ) self . env_vars = [] for service in env_vars : self . env_vars += env_vars [ service ] self . missing_vars = [ var for var in self . env_vars if var not in self . env ] self . message = \" %s . Evironment variables not defined: %s \" super () . __init__ ( self . message , str ( validation_error ), \", \" . join ( self . missing_vars ) ) Attributes env instance-attribute env = dict ( os . environ ) env_vars instance-attribute env_vars = [] missing_vars instance-attribute missing_vars = [ var for var in self . env_vars if var not in self . env ] message instance-attribute message = ' %s . Evironment variables not defined: %s ' Functions FlowNotFoundError FlowNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 29 30 31 32 def __init__ ( self , query ): self . query = query self . message = \"Flow not found for query: %s .\" super () . __init__ ( self . message , self . query ) Attributes query instance-attribute query = query message instance-attribute message = 'Flow not found for query: %s .' Functions FlowOfFlowsNotFoundError FlowOfFlowsNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 36 37 38 39 def __init__ ( self , query ): self . query = query self . message = \"Flow not found for query: %s .\" super () . __init__ ( self . message , self . query ) Attributes query instance-attribute query = query message instance-attribute message = 'Flow not found for query: %s .' Functions ProjectNotFoundError ProjectNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 43 44 45 46 def __init__ ( self , query ): self . query = query self . message = \"Project not found for query: %s .\" super () . __init__ ( self . message , self . query ) Attributes query instance-attribute query = query message instance-attribute message = 'Project not found for query: %s .' Functions ModelNotFoundError ModelNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 50 51 52 53 def __init__ ( self , query ): self . query = query self . message = \"Model not found for query: %s .\" super () . __init__ ( self . message , self . query ) Attributes query instance-attribute query = query message instance-attribute message = 'Model not found for query: %s .' Functions DeploymentNotFoundError DeploymentNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 57 58 59 60 def __init__ ( self , query ): self . query = query self . message = \"Deployment not found for query: %s .\" super () . __init__ ( self . message , self . query ) Attributes query instance-attribute query = query message instance-attribute message = 'Deployment not found for query: %s .' Functions ParameterNotInFlowError ParameterNotInFlowError ( parameter_name : str , flow_name : str ) Bases: Exception Source code in lume_services/errors.py 67 68 69 70 71 def __init__ ( self , parameter_name : str , flow_name : str ): self . flow_name = flow_name self . parameter_name = parameter_name self . message = \"Parameter %s not in flow %s .\" super () . __init__ ( self . message , self . parameter_name , self . flow_name ) Attributes flow_name instance-attribute flow_name = flow_name parameter_name instance-attribute parameter_name = parameter_name message instance-attribute message = 'Parameter %s not in flow %s .' Functions ParentFlowNotInFlowsError ParentFlowNotInFlowsError ( flow_name : str , flows : List [ str ]) Bases: Exception Source code in lume_services/errors.py 75 76 77 78 79 def __init__ ( self , flow_name : str , flows : List [ str ]): self . flow_name = flow_name self . flows = flows self . message = \"Parent flow %s not in flows: %s \" super () . __init__ ( self . message , self . flow_name , \", \" . join ( self . flows )) Attributes flow_name instance-attribute flow_name = flow_name flows instance-attribute flows = flows message instance-attribute message = 'Parent flow %s not in flows: %s ' Functions TaskNotInFlowError TaskNotInFlowError ( flow_name : str , project_name : str , task_name : str ) Bases: Exception Source code in lume_services/errors.py 83 84 85 86 87 88 89 90 def __init__ ( self , flow_name : str , project_name : str , task_name : str ): self . flow_name = flow_name self . task_name = task_name self . project_name = project_name self . message = \"Task %s not in flow %s .\" super () . __init__ ( self . message , self . task_name , self . project_name , self . flow_name ) Attributes flow_name instance-attribute flow_name = flow_name task_name instance-attribute task_name = task_name project_name instance-attribute project_name = project_name message instance-attribute message = 'Task %s not in flow %s .' Functions TaskNotCompletedError TaskNotCompletedError ( task_slug : str , flow_id : str , flow_run_id : str ) Bases: Exception Source code in lume_services/errors.py 94 95 96 97 98 99 100 101 def __init__ ( self , task_slug : str , flow_id : str , flow_run_id : str ): self . flow_id = flow_id self . flow_run_id = flow_run_id self . task_slug = task_slug self . message = ( \"Task with slug: %s not completed for flow_run_id: %s , flow_id: %s .\" ) super () . __init__ ( self . message , self . task_slug , self . flow_run_id , self . flow_id ) Attributes flow_id instance-attribute flow_id = flow_id flow_run_id instance-attribute flow_run_id = flow_run_id task_slug instance-attribute task_slug = task_slug message instance-attribute message = \"Task with slug: %s not completed for flow_run_id: %s , flow_id: %s .\" Functions FlowFailedError FlowFailedError ( flow_id : str , flow_run_id : str , exception_message : str = None , ) Bases: Exception Source code in lume_services/errors.py 105 106 107 108 109 110 111 112 def __init__ ( self , flow_id : str , flow_run_id : str , exception_message : str = None ): self . flow_id = flow_id self . flow_run_id = flow_run_id self . exception_message = exception_message self . message = \"Flow run: %s failed for flow_id: %s . %s \" super () . __init__ ( self . message , self . flow_run_id , self . flow_id , self . exception_message ) Attributes flow_id instance-attribute flow_id = flow_id flow_run_id instance-attribute flow_run_id = flow_run_id exception_message instance-attribute exception_message = exception_message message instance-attribute message = 'Flow run: %s failed for flow_id: %s . %s ' Functions EmptyResultError EmptyResultError ( flow_id : str , flow_run_id : str , task_slug : Optional [ str ] ) Bases: Exception Source code in lume_services/errors.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def __init__ ( self , flow_id : str , flow_run_id : str , task_slug : Optional [ str ]): self . flow_id = flow_id self . flow_run_id = flow_run_id self . task_slug = task_slug if not self . task_slug : self . message = ( \"Task with slug: %s for flow run: %s of flow_id: %s has no result.\" ) super () . __init__ ( self . message , self . task_slug , self . flow_run_id , self . flow_id ) else : self . message = \"Flow run: %s of flow_id: %s has no result.\" super () . __init__ ( self . message , self . flow_run_id , flow_id ) Attributes flow_id instance-attribute flow_id = flow_id flow_run_id instance-attribute flow_run_id = flow_run_id task_slug instance-attribute task_slug = task_slug message instance-attribute message = \"Task with slug: %s for flow run: %s of flow_id: %s has no result.\" Functions LocalBackendError LocalBackendError () Bases: Exception LocalBackendError indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/errors.py 140 141 142 def __init__ ( self ): self . message = \"Cannot run server-backend operation using LocalBackend.\" super () . __init__ ( self . message ) Attributes message instance-attribute message = \"Cannot run server-backend operation using LocalBackend.\" Functions","title":"Errors"},{"location":"api/errors/#lume_services.errors","text":"","title":"errors"},{"location":"api/errors/#lume_services.errors-classes","text":"","title":"Classes"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError","text":"EnvironmentNotConfiguredError ( env_vars , validation_error : ValidationError ) Bases: Exception Error for marking unconfigured environment. Source code in lume_services/errors.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , env_vars , validation_error : ValidationError ): self . env = dict ( os . environ ) self . env_vars = [] for service in env_vars : self . env_vars += env_vars [ service ] self . missing_vars = [ var for var in self . env_vars if var not in self . env ] self . message = \" %s . Evironment variables not defined: %s \" super () . __init__ ( self . message , str ( validation_error ), \", \" . join ( self . missing_vars ) )","title":"EnvironmentNotConfiguredError"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError.env","text":"env = dict ( os . environ )","title":"env"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError.env_vars","text":"env_vars = []","title":"env_vars"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError.missing_vars","text":"missing_vars = [ var for var in self . env_vars if var not in self . env ]","title":"missing_vars"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError.message","text":"message = ' %s . Evironment variables not defined: %s '","title":"message"},{"location":"api/errors/#lume_services.errors.EnvironmentNotConfiguredError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.FlowNotFoundError","text":"FlowNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 29 30 31 32 def __init__ ( self , query ): self . query = query self . message = \"Flow not found for query: %s .\" super () . __init__ ( self . message , self . query )","title":"FlowNotFoundError"},{"location":"api/errors/#lume_services.errors.FlowNotFoundError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.FlowNotFoundError.query","text":"query = query","title":"query"},{"location":"api/errors/#lume_services.errors.FlowNotFoundError.message","text":"message = 'Flow not found for query: %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.FlowNotFoundError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.FlowOfFlowsNotFoundError","text":"FlowOfFlowsNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 36 37 38 39 def __init__ ( self , query ): self . query = query self . message = \"Flow not found for query: %s .\" super () . __init__ ( self . message , self . query )","title":"FlowOfFlowsNotFoundError"},{"location":"api/errors/#lume_services.errors.FlowOfFlowsNotFoundError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.FlowOfFlowsNotFoundError.query","text":"query = query","title":"query"},{"location":"api/errors/#lume_services.errors.FlowOfFlowsNotFoundError.message","text":"message = 'Flow not found for query: %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.FlowOfFlowsNotFoundError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.ProjectNotFoundError","text":"ProjectNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 43 44 45 46 def __init__ ( self , query ): self . query = query self . message = \"Project not found for query: %s .\" super () . __init__ ( self . message , self . query )","title":"ProjectNotFoundError"},{"location":"api/errors/#lume_services.errors.ProjectNotFoundError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.ProjectNotFoundError.query","text":"query = query","title":"query"},{"location":"api/errors/#lume_services.errors.ProjectNotFoundError.message","text":"message = 'Project not found for query: %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.ProjectNotFoundError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.ModelNotFoundError","text":"ModelNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 50 51 52 53 def __init__ ( self , query ): self . query = query self . message = \"Model not found for query: %s .\" super () . __init__ ( self . message , self . query )","title":"ModelNotFoundError"},{"location":"api/errors/#lume_services.errors.ModelNotFoundError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.ModelNotFoundError.query","text":"query = query","title":"query"},{"location":"api/errors/#lume_services.errors.ModelNotFoundError.message","text":"message = 'Model not found for query: %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.ModelNotFoundError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.DeploymentNotFoundError","text":"DeploymentNotFoundError ( query ) Bases: Exception Source code in lume_services/errors.py 57 58 59 60 def __init__ ( self , query ): self . query = query self . message = \"Deployment not found for query: %s .\" super () . __init__ ( self . message , self . query )","title":"DeploymentNotFoundError"},{"location":"api/errors/#lume_services.errors.DeploymentNotFoundError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.DeploymentNotFoundError.query","text":"query = query","title":"query"},{"location":"api/errors/#lume_services.errors.DeploymentNotFoundError.message","text":"message = 'Deployment not found for query: %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.DeploymentNotFoundError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError","text":"ParameterNotInFlowError ( parameter_name : str , flow_name : str ) Bases: Exception Source code in lume_services/errors.py 67 68 69 70 71 def __init__ ( self , parameter_name : str , flow_name : str ): self . flow_name = flow_name self . parameter_name = parameter_name self . message = \"Parameter %s not in flow %s .\" super () . __init__ ( self . message , self . parameter_name , self . flow_name )","title":"ParameterNotInFlowError"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError.flow_name","text":"flow_name = flow_name","title":"flow_name"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError.parameter_name","text":"parameter_name = parameter_name","title":"parameter_name"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError.message","text":"message = 'Parameter %s not in flow %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.ParameterNotInFlowError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError","text":"ParentFlowNotInFlowsError ( flow_name : str , flows : List [ str ]) Bases: Exception Source code in lume_services/errors.py 75 76 77 78 79 def __init__ ( self , flow_name : str , flows : List [ str ]): self . flow_name = flow_name self . flows = flows self . message = \"Parent flow %s not in flows: %s \" super () . __init__ ( self . message , self . flow_name , \", \" . join ( self . flows ))","title":"ParentFlowNotInFlowsError"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError.flow_name","text":"flow_name = flow_name","title":"flow_name"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError.flows","text":"flows = flows","title":"flows"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError.message","text":"message = 'Parent flow %s not in flows: %s '","title":"message"},{"location":"api/errors/#lume_services.errors.ParentFlowNotInFlowsError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError","text":"TaskNotInFlowError ( flow_name : str , project_name : str , task_name : str ) Bases: Exception Source code in lume_services/errors.py 83 84 85 86 87 88 89 90 def __init__ ( self , flow_name : str , project_name : str , task_name : str ): self . flow_name = flow_name self . task_name = task_name self . project_name = project_name self . message = \"Task %s not in flow %s .\" super () . __init__ ( self . message , self . task_name , self . project_name , self . flow_name )","title":"TaskNotInFlowError"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError.flow_name","text":"flow_name = flow_name","title":"flow_name"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError.task_name","text":"task_name = task_name","title":"task_name"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError.project_name","text":"project_name = project_name","title":"project_name"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError.message","text":"message = 'Task %s not in flow %s .'","title":"message"},{"location":"api/errors/#lume_services.errors.TaskNotInFlowError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError","text":"TaskNotCompletedError ( task_slug : str , flow_id : str , flow_run_id : str ) Bases: Exception Source code in lume_services/errors.py 94 95 96 97 98 99 100 101 def __init__ ( self , task_slug : str , flow_id : str , flow_run_id : str ): self . flow_id = flow_id self . flow_run_id = flow_run_id self . task_slug = task_slug self . message = ( \"Task with slug: %s not completed for flow_run_id: %s , flow_id: %s .\" ) super () . __init__ ( self . message , self . task_slug , self . flow_run_id , self . flow_id )","title":"TaskNotCompletedError"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError.flow_id","text":"flow_id = flow_id","title":"flow_id"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError.flow_run_id","text":"flow_run_id = flow_run_id","title":"flow_run_id"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError.task_slug","text":"task_slug = task_slug","title":"task_slug"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError.message","text":"message = \"Task with slug: %s not completed for flow_run_id: %s , flow_id: %s .\"","title":"message"},{"location":"api/errors/#lume_services.errors.TaskNotCompletedError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.FlowFailedError","text":"FlowFailedError ( flow_id : str , flow_run_id : str , exception_message : str = None , ) Bases: Exception Source code in lume_services/errors.py 105 106 107 108 109 110 111 112 def __init__ ( self , flow_id : str , flow_run_id : str , exception_message : str = None ): self . flow_id = flow_id self . flow_run_id = flow_run_id self . exception_message = exception_message self . message = \"Flow run: %s failed for flow_id: %s . %s \" super () . __init__ ( self . message , self . flow_run_id , self . flow_id , self . exception_message )","title":"FlowFailedError"},{"location":"api/errors/#lume_services.errors.FlowFailedError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.FlowFailedError.flow_id","text":"flow_id = flow_id","title":"flow_id"},{"location":"api/errors/#lume_services.errors.FlowFailedError.flow_run_id","text":"flow_run_id = flow_run_id","title":"flow_run_id"},{"location":"api/errors/#lume_services.errors.FlowFailedError.exception_message","text":"exception_message = exception_message","title":"exception_message"},{"location":"api/errors/#lume_services.errors.FlowFailedError.message","text":"message = 'Flow run: %s failed for flow_id: %s . %s '","title":"message"},{"location":"api/errors/#lume_services.errors.FlowFailedError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.EmptyResultError","text":"EmptyResultError ( flow_id : str , flow_run_id : str , task_slug : Optional [ str ] ) Bases: Exception Source code in lume_services/errors.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def __init__ ( self , flow_id : str , flow_run_id : str , task_slug : Optional [ str ]): self . flow_id = flow_id self . flow_run_id = flow_run_id self . task_slug = task_slug if not self . task_slug : self . message = ( \"Task with slug: %s for flow run: %s of flow_id: %s has no result.\" ) super () . __init__ ( self . message , self . task_slug , self . flow_run_id , self . flow_id ) else : self . message = \"Flow run: %s of flow_id: %s has no result.\" super () . __init__ ( self . message , self . flow_run_id , flow_id )","title":"EmptyResultError"},{"location":"api/errors/#lume_services.errors.EmptyResultError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.EmptyResultError.flow_id","text":"flow_id = flow_id","title":"flow_id"},{"location":"api/errors/#lume_services.errors.EmptyResultError.flow_run_id","text":"flow_run_id = flow_run_id","title":"flow_run_id"},{"location":"api/errors/#lume_services.errors.EmptyResultError.task_slug","text":"task_slug = task_slug","title":"task_slug"},{"location":"api/errors/#lume_services.errors.EmptyResultError.message","text":"message = \"Task with slug: %s for flow run: %s of flow_id: %s has no result.\"","title":"message"},{"location":"api/errors/#lume_services.errors.EmptyResultError-functions","text":"","title":"Functions"},{"location":"api/errors/#lume_services.errors.LocalBackendError","text":"LocalBackendError () Bases: Exception LocalBackendError indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/errors.py 140 141 142 def __init__ ( self ): self . message = \"Cannot run server-backend operation using LocalBackend.\" super () . __init__ ( self . message )","title":"LocalBackendError"},{"location":"api/errors/#lume_services.errors.LocalBackendError-attributes","text":"","title":"Attributes"},{"location":"api/errors/#lume_services.errors.LocalBackendError.message","text":"message = \"Cannot run server-backend operation using LocalBackend.\"","title":"message"},{"location":"api/errors/#lume_services.errors.LocalBackendError-functions","text":"","title":"Functions"},{"location":"api/flows/","text":"lume_services.flows.flow Classes MappedParameter Bases: BaseModel There are three types of mapped parameters: file, db, and raw. file: File parameters are file outputs that will be loaded in downstream flows. Downstream loading must use the packaged load_file task in lume_services.tasks.file . db: Database results ... raw: Raw values are passed from task output to parameter input. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"]): Type of mapping describing the parameters. Attributes parent_flow_name class-attribute parent_flow_name : str parent_task_name class-attribute parent_task_name : str map_type class-attribute map_type : Literal [ 'file' , 'db' , 'raw' ] = 'raw' RawMappedParameter Bases: MappedParameter RawMappedParameters describe parameter mappings where the result of a task is used as the input to a parameter. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"] = \"raw\"): The \"raw\" map type describes the one-to-one result to parameter map. Attributes map_type class-attribute map_type : str = Field ( 'raw' , const = True ) FileMappedParameter Bases: MappedParameter FileMappedParameters describe files passed between different flows. Files are saved as json representations describing file type (and serialization) and filesystem information. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"] = \"file\"): The \"file\" map type describes the Attributes map_type class-attribute map_type : str = Field ( 'file' , const = True ) DBMappedParameter Bases: MappedParameter Attributes map_type class-attribute map_type : str = Field ( 'db' , const = True ) attribute class-attribute attribute : str attribute_index class-attribute attribute_index : Optional [ List [ str ]] Flow Bases: BaseModel Interface to a workflow object. Attributes: Name Type Description name str Name of flow flow_id Optional [ str ] ID of flow as registered with Prefect. If running locally, this will be null. project_name Optional [ str ] Name of Prefect project with which the flow is registered. If running locally this will be null. parameters Optional [ Dict [ str , Parameter ]] Dictionary of Prefect parameters associated with the flow. mapped_parameters Optional [ Dict [ str , MappedParameter ]] Parameters to be collected from results of other flows. task_slugs Optional [ Dict [ str , str ]] Slug of tasks associated with the Prefect flow. labels List[str] = [\"lume-services\"] List of labels to assign to flow when registering with Prefect backend. This label is used to assign agents that will manage deployment. image str Image inside which to run flow if deploying to remote backend. Attributes name class-attribute name : str flow_id class-attribute flow_id : Optional [ str ] project_name class-attribute project_name : Optional [ str ] prefect_flow class-attribute prefect_flow : Optional [ PrefectFlow ] parameters class-attribute parameters : Optional [ Dict [ str , Parameter ]] mapped_parameters class-attribute mapped_parameters : Optional [ Dict [ str , MappedParameter ]] task_slugs class-attribute task_slugs : Optional [ Dict [ str , str ]] labels class-attribute labels : List [ str ] = [ 'lume-services' ] image class-attribute image : str = 'build-test:latest' Classes Config Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True validate_assignment class-attribute validate_assignment = True Functions validate_mapped_parameters validate_mapped_parameters ( v ) Source code in lume_services/flows/flow.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @validator ( \"mapped_parameters\" , pre = True ) def validate_mapped_parameters ( cls , v ): if v is None : return v mapped_parameters = {} for param_name , param in v . items (): # persist instantiated params if isinstance ( param , ( MappedParameter ,)): mapped_parameters [ param_name ] = param elif isinstance ( param , ( dict ,)): # default raw if not param . get ( \"map_type\" ): mapped_parameters [ param_name ] = RawMappedParameter ( ** param ) else : mapped_param_type = _get_mapped_parameter_type ( param [ \"map_type\" ]) mapped_parameters [ param_name ] = mapped_param_type ( ** param ) else : raise ValueError ( \"Mapped parameters must be passed as instantiated \\ MappedParameters or dictionary\" ) return mapped_parameters load_flow load_flow ( scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> None Loads Prefect flow artifact from the backend. Parameters: Name Type Description Default scheduling_service SchedulingService Scheduling service. If not provided, uses injected service. Provide[Context.scheduling_service] Source code in lume_services/flows/flow.py 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 @inject def load_flow ( self , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> None : \"\"\"Loads Prefect flow artifact from the backend. Args: scheduling_service (SchedulingService): Scheduling service. If not provided, uses injected service. \"\"\" flow_dict = scheduling_service . load_flow ( self . name , self . project_name ) flow = flow_dict [ \"flow\" ] # assign attributes self . prefect_flow = flow self . task_slugs = { task . name : task . slug for task in flow . get_tasks ()} self . parameters = { parameter . name : parameter for parameter in flow . parameters ()} self . flow_id = flow_dict [ \"flow_id\" ] register register ( scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> str Register flow with SchedulingService backend. Parameters: Name Type Description Default scheduling_service SchedulingService Scheduling service. If not provided, uses injected service. Provide[Context.scheduling_service] Returns: Name Type Description flow_id str ID of registered flow. Source code in lume_services/flows/flow.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 @inject def register ( self , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> str : \"\"\"Register flow with SchedulingService backend. Args: scheduling_service (SchedulingService): Scheduling service. If not provided, uses injected service. Returns: flow_id (str): ID of registered flow. \"\"\" if self . prefect_flow is None : # attempt loading self . load_flow () self . flow_id = scheduling_service . register_flow ( self . prefect_flow , self . project_name , labels = self . labels , image = self . image ) self . parameters = { parameter . name : parameter for parameter in self . prefect_flow . parameters () } self . task_slugs = { task . name : task . slug for task in self . prefect_flow . get_tasks () } return self . flow_id run run ( parameters , run_config , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Run the flow. Source code in lume_services/flows/flow.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def run ( self , parameters , run_config , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): \"\"\"Run the flow.\"\"\" if isinstance ( scheduling_service . backend , ( LocalBackend ,)): if self . prefect_flow is None : self . load_flow () scheduling_service . run ( parameters = parameters , run_config = run_config , flow = self . prefect_flow ) elif isinstance ( scheduling_service . backend , ( ServerBackend ,)): scheduling_service . run ( parameters = parameters , run_config = run_config , flow_id = self . flow_id ) run_and_return run_and_return ( parameters , run_config , task_name : Optional [ str ], scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Run flow and return result. Result will reference either passed task name or the result of all tasks. Source code in lume_services/flows/flow.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def run_and_return ( self , parameters , run_config , task_name : Optional [ str ], scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): \"\"\"Run flow and return result. Result will reference either passed task name or the result of all tasks. \"\"\" if isinstance ( scheduling_service . backend , ( LocalBackend ,)): if self . prefect_flow is None : self . load_flow () scheduling_service . run_and_return ( parameters = parameters , run_config = run_config , flow = self . prefect_flow , task_name = task_name , ) elif isinstance ( scheduling_service . backend , ( ServerBackend ,)): scheduling_service . run_and_return ( parameters = parameters , run_config = run_config , flow_id = self . flow_id , task_name = task_name , ) FlowConfig Bases: BaseModel Attributes image class-attribute image : Optional [ str ] env class-attribute env : Optional [ List [ str ]] FlowRunConfig Bases: BaseModel Attributes poll_interval class-attribute poll_interval : timedelta = timedelta ( seconds = 10 ) scheduled_start_time class-attribute scheduled_start_time : Optional [ datetime ] parameters class-attribute parameters : Optional [ Dict [ str , Any ]] run_config class-attribute run_config : Optional [ RunConfig ] labels class-attribute labels : Optional [ List [ str ]] run_name class-attribute run_name : Optional [ str ] Classes Config Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True lume_services.flows.flow_of_flows Classes FlowOfFlows Bases: Flow Attributes composing_flows class-attribute composing_flows : dict Classes Config Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True Functions validate validate ( values : dict ) Validate composing flow data against Prefect server. Source code in lume_services/flows/flow_of_flows.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @root_validator ( pre = True ) def validate ( cls , values : dict ): \"\"\"Validate composing flow data against Prefect server.\"\"\" flows = {} scheduling_service = None if \"scheduling_service\" in values : scheduling_service = values . pop ( \"scheduling_service\" ) # validate composing flow existence composing_flows = values . get ( \"composing_flows\" ) if isinstance ( composing_flows , ( dict ,)): pass # iterate to create dict elif isinstance ( composing_flows , ( list ,)): for flow in values [ \"composing_flows\" ]: # compose flow objects flow_obj = Flow ( name = flow [ \"name\" ], project_name = flow [ \"project_name\" ], mapped_parameters = flow . get ( \"mapped_parameters\" ), ) # load Prefect parameters if scheduling_service is not None : flow_obj . load_flow ( scheduling_service = scheduling_service ) else : flow_obj . load_flow () flows [ flow [ \"name\" ]] = flow_obj # validate flow parameters for flow_name , flow in flows . items (): if flow . mapped_parameters is not None : for parameter_name , parameter in flow . mapped_parameters . items (): # validate parameter is in flow spec parameter_obj = flow . parameters . get ( parameter_name ) if parameter_obj is None : raise ParameterNotInFlowError ( parameter_name , flow_name ) # validate parent flow is included in listed flows parent_flow = flows . get ( parameter . parent_flow_name ) if parent_flow is None : raise ParentFlowNotInFlowsError ( parameter . parent_flow_name , list ( flows . keys ()) ) # validate task is in the parent flow task = parent_flow . task_slugs . get ( parameter . parent_task_name ) if task is None : raise TaskNotInFlowError ( parameter . parent_flow_name , parameter . parent_task_name ) values [ \"composing_flows\" ] = flows return values compose compose ( image_name : str , image_tag : str = \"latest\" , local : bool = False , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> PrefectFlow Compose Prefect flow from FlowOfFlows object. Uses base image assigned to the FlowOfFlows Object and builds a new Docker image containing the composite flow. Parameters: Name Type Description Default image_name str Name of generated image. required image_tag str Tag of generated image. 'latest' local bool=False Whether to use local images for the base image. False Returns: Type Description PrefectFlow PrefectFlow Source code in lume_services/flows/flow_of_flows.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def compose ( self , image_name : str , image_tag : str = \"latest\" , local : bool = False , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> PrefectFlow : \"\"\"Compose Prefect flow from FlowOfFlows object. Uses base image assigned to the FlowOfFlows Object and builds a new Docker image containing the composite flow. Args: image_name (str): Name of generated image. image_tag (str): Tag of generated image. local (bool=False): Whether to use local images for the base image. Returns: PrefectFlow \"\"\" # compose flow of flows with PrefectFlow ( self . name , storage = Docker ( base_image = self . image , image_name = image_name , image_tag = image_tag , local_image = local , ), ) as composed_flow : flow_runs = {} flow_waits = {} params = {} for i , ( flow_name , flow ) in enumerate ( self . composing_flows . items ()): # begin by creating parameters for all flow parameters flow_params = {} for param_name , param in flow . parameters . items (): # update name and slug param . name = f \" { flow_name } - { param_name } \" param . slug = f \" { flow_name } - { param_name } \" params [ param . name ] = param # use original param name for flow config flow_params [ param_name ] = param # set up entry task if i == 0 : flow_run = create_flow_run ( flow_id = flow . flow_id , parameters = flow_params , labels = flow . labels , ) # setup other tasks elif i > 0 : # create references to parameters upstream_flows = set () if flow . mapped_parameters is not None : # update flow_params with mapping for param_name , mapped_param in flow . mapped_parameters . items (): task_slug = self . composing_flows [ mapped_param . parent_flow_name ] . task_slugs [ mapped_param . parent_task_name ] task_run_result = get_task_run_result ( flow_runs [ mapped_param . parent_flow_name ], task_slug ) # raw results and file results use their values directly if mapped_param . map_type in [ \"raw\" , \"file\" ]: flow . prefect_flow . replace ( flow_params . pop ( param_name ), task_run_result ) # handle database results elif mapped_param . map_type == \"db\" : load_db_result = LoadDBResult () db_result = load_db_result ( task_run_result , mapped_param . attribute , attribute_index = mapped_param . attribute_index , ) flow . prefect_flow . replace ( flow_params . pop ( param_name ), db_result ) # add db result parameters to the task and create edge for param in load_db_result . parameters : flow . prefect_flow . add_task ( param ) flow . prefect_flow . add_edge ( param , load_db_result , mapped = True ) else : # should never reach if instantiating MappedParameter mapped_param_types = get_args ( MappedParameter . __fields__ [ \"map_type\" ] . type_ ) raise ValueError ( f \"Task type { mapped_param . map_type } not in task. \\ Allowed types: { mapped_param_types } .\" ) # add flow to upstream upstream_flows . add ( mapped_param . parent_flow_name ) # add creation of flow run to flow flow_run = create_flow_run ( flow_id = flow . flow_id , parameters = flow_params , labels = flow . labels , ) # configure upstreams if any for upstream in upstream_flows : flow_run . set_upstream ( flow_waits [ upstream ]) flow_wait = wait_for_flow_run ( flow_run , raise_final_state = True ) flow_runs [ flow_name ] = flow_run flow_waits [ flow_name ] = flow_wait # validate flow of flows composed_flow . validate () # assign to obj self . prefect_flow = composed_flow self . image = f \" { image_name } : { image_tag } \" return composed_flow compose_and_register compose_and_register () Compose flow and register with project. Returns: Name Type Description str Registered flow id Source code in lume_services/flows/flow_of_flows.py 235 236 237 238 239 240 241 242 243 244 245 def compose_and_register ( self ): \"\"\"Compose flow and register with project. Returns: str: Registered flow id \"\"\" flow = self . compose () self . prefect_flow = flow return self . register ( self . project_name ) from_yaml classmethod from_yaml ( yaml_obj , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Source code in lume_services/flows/flow_of_flows.py 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 @classmethod @inject def from_yaml ( cls , yaml_obj , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): if os . path . exists ( yaml_obj ): flow_of_flow_config = yaml . safe_load ( open ( yaml_obj )) else : flow_of_flow_config = yaml_obj # now validate return cls ( ** flow_of_flow_config , scheduling_service = scheduling_service )","title":"Flows"},{"location":"api/flows/#lume_services.flows.flow","text":"","title":"flow"},{"location":"api/flows/#lume_services.flows.flow-classes","text":"","title":"Classes"},{"location":"api/flows/#lume_services.flows.flow.MappedParameter","text":"Bases: BaseModel There are three types of mapped parameters: file, db, and raw. file: File parameters are file outputs that will be loaded in downstream flows. Downstream loading must use the packaged load_file task in lume_services.tasks.file . db: Database results ... raw: Raw values are passed from task output to parameter input. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"]): Type of mapping describing the parameters.","title":"MappedParameter"},{"location":"api/flows/#lume_services.flows.flow.MappedParameter-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.MappedParameter.parent_flow_name","text":"parent_flow_name : str","title":"parent_flow_name"},{"location":"api/flows/#lume_services.flows.flow.MappedParameter.parent_task_name","text":"parent_task_name : str","title":"parent_task_name"},{"location":"api/flows/#lume_services.flows.flow.MappedParameter.map_type","text":"map_type : Literal [ 'file' , 'db' , 'raw' ] = 'raw'","title":"map_type"},{"location":"api/flows/#lume_services.flows.flow.RawMappedParameter","text":"Bases: MappedParameter RawMappedParameters describe parameter mappings where the result of a task is used as the input to a parameter. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"] = \"raw\"): The \"raw\" map type describes the one-to-one result to parameter map.","title":"RawMappedParameter"},{"location":"api/flows/#lume_services.flows.flow.RawMappedParameter-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.RawMappedParameter.map_type","text":"map_type : str = Field ( 'raw' , const = True )","title":"map_type"},{"location":"api/flows/#lume_services.flows.flow.FileMappedParameter","text":"Bases: MappedParameter FileMappedParameters describe files passed between different flows. Files are saved as json representations describing file type (and serialization) and filesystem information. Attr parent_flow_name (str): Parent flow holding origin of mapped parameter. parent_task_name (str): Task whose result is mapped to the parameter. map_type (Literal[\"file\", \"db\", \"raw\"] = \"file\"): The \"file\" map type describes the","title":"FileMappedParameter"},{"location":"api/flows/#lume_services.flows.flow.FileMappedParameter-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.FileMappedParameter.map_type","text":"map_type : str = Field ( 'file' , const = True )","title":"map_type"},{"location":"api/flows/#lume_services.flows.flow.DBMappedParameter","text":"Bases: MappedParameter","title":"DBMappedParameter"},{"location":"api/flows/#lume_services.flows.flow.DBMappedParameter-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.DBMappedParameter.map_type","text":"map_type : str = Field ( 'db' , const = True )","title":"map_type"},{"location":"api/flows/#lume_services.flows.flow.DBMappedParameter.attribute","text":"attribute : str","title":"attribute"},{"location":"api/flows/#lume_services.flows.flow.DBMappedParameter.attribute_index","text":"attribute_index : Optional [ List [ str ]]","title":"attribute_index"},{"location":"api/flows/#lume_services.flows.flow.Flow","text":"Bases: BaseModel Interface to a workflow object. Attributes: Name Type Description name str Name of flow flow_id Optional [ str ] ID of flow as registered with Prefect. If running locally, this will be null. project_name Optional [ str ] Name of Prefect project with which the flow is registered. If running locally this will be null. parameters Optional [ Dict [ str , Parameter ]] Dictionary of Prefect parameters associated with the flow. mapped_parameters Optional [ Dict [ str , MappedParameter ]] Parameters to be collected from results of other flows. task_slugs Optional [ Dict [ str , str ]] Slug of tasks associated with the Prefect flow. labels List[str] = [\"lume-services\"] List of labels to assign to flow when registering with Prefect backend. This label is used to assign agents that will manage deployment. image str Image inside which to run flow if deploying to remote backend.","title":"Flow"},{"location":"api/flows/#lume_services.flows.flow.Flow-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.Flow.name","text":"name : str","title":"name"},{"location":"api/flows/#lume_services.flows.flow.Flow.flow_id","text":"flow_id : Optional [ str ]","title":"flow_id"},{"location":"api/flows/#lume_services.flows.flow.Flow.project_name","text":"project_name : Optional [ str ]","title":"project_name"},{"location":"api/flows/#lume_services.flows.flow.Flow.prefect_flow","text":"prefect_flow : Optional [ PrefectFlow ]","title":"prefect_flow"},{"location":"api/flows/#lume_services.flows.flow.Flow.parameters","text":"parameters : Optional [ Dict [ str , Parameter ]]","title":"parameters"},{"location":"api/flows/#lume_services.flows.flow.Flow.mapped_parameters","text":"mapped_parameters : Optional [ Dict [ str , MappedParameter ]]","title":"mapped_parameters"},{"location":"api/flows/#lume_services.flows.flow.Flow.task_slugs","text":"task_slugs : Optional [ Dict [ str , str ]]","title":"task_slugs"},{"location":"api/flows/#lume_services.flows.flow.Flow.labels","text":"labels : List [ str ] = [ 'lume-services' ]","title":"labels"},{"location":"api/flows/#lume_services.flows.flow.Flow.image","text":"image : str = 'build-test:latest'","title":"image"},{"location":"api/flows/#lume_services.flows.flow.Flow-classes","text":"","title":"Classes"},{"location":"api/flows/#lume_services.flows.flow.Flow.Config","text":"Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True validate_assignment class-attribute validate_assignment = True","title":"Config"},{"location":"api/flows/#lume_services.flows.flow.Flow-functions","text":"","title":"Functions"},{"location":"api/flows/#lume_services.flows.flow.Flow.validate_mapped_parameters","text":"validate_mapped_parameters ( v ) Source code in lume_services/flows/flow.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @validator ( \"mapped_parameters\" , pre = True ) def validate_mapped_parameters ( cls , v ): if v is None : return v mapped_parameters = {} for param_name , param in v . items (): # persist instantiated params if isinstance ( param , ( MappedParameter ,)): mapped_parameters [ param_name ] = param elif isinstance ( param , ( dict ,)): # default raw if not param . get ( \"map_type\" ): mapped_parameters [ param_name ] = RawMappedParameter ( ** param ) else : mapped_param_type = _get_mapped_parameter_type ( param [ \"map_type\" ]) mapped_parameters [ param_name ] = mapped_param_type ( ** param ) else : raise ValueError ( \"Mapped parameters must be passed as instantiated \\ MappedParameters or dictionary\" ) return mapped_parameters","title":"validate_mapped_parameters()"},{"location":"api/flows/#lume_services.flows.flow.Flow.load_flow","text":"load_flow ( scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> None Loads Prefect flow artifact from the backend. Parameters: Name Type Description Default scheduling_service SchedulingService Scheduling service. If not provided, uses injected service. Provide[Context.scheduling_service] Source code in lume_services/flows/flow.py 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 @inject def load_flow ( self , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> None : \"\"\"Loads Prefect flow artifact from the backend. Args: scheduling_service (SchedulingService): Scheduling service. If not provided, uses injected service. \"\"\" flow_dict = scheduling_service . load_flow ( self . name , self . project_name ) flow = flow_dict [ \"flow\" ] # assign attributes self . prefect_flow = flow self . task_slugs = { task . name : task . slug for task in flow . get_tasks ()} self . parameters = { parameter . name : parameter for parameter in flow . parameters ()} self . flow_id = flow_dict [ \"flow_id\" ]","title":"load_flow()"},{"location":"api/flows/#lume_services.flows.flow.Flow.register","text":"register ( scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> str Register flow with SchedulingService backend. Parameters: Name Type Description Default scheduling_service SchedulingService Scheduling service. If not provided, uses injected service. Provide[Context.scheduling_service] Returns: Name Type Description flow_id str ID of registered flow. Source code in lume_services/flows/flow.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 @inject def register ( self , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> str : \"\"\"Register flow with SchedulingService backend. Args: scheduling_service (SchedulingService): Scheduling service. If not provided, uses injected service. Returns: flow_id (str): ID of registered flow. \"\"\" if self . prefect_flow is None : # attempt loading self . load_flow () self . flow_id = scheduling_service . register_flow ( self . prefect_flow , self . project_name , labels = self . labels , image = self . image ) self . parameters = { parameter . name : parameter for parameter in self . prefect_flow . parameters () } self . task_slugs = { task . name : task . slug for task in self . prefect_flow . get_tasks () } return self . flow_id","title":"register()"},{"location":"api/flows/#lume_services.flows.flow.Flow.run","text":"run ( parameters , run_config , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Run the flow. Source code in lume_services/flows/flow.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def run ( self , parameters , run_config , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): \"\"\"Run the flow.\"\"\" if isinstance ( scheduling_service . backend , ( LocalBackend ,)): if self . prefect_flow is None : self . load_flow () scheduling_service . run ( parameters = parameters , run_config = run_config , flow = self . prefect_flow ) elif isinstance ( scheduling_service . backend , ( ServerBackend ,)): scheduling_service . run ( parameters = parameters , run_config = run_config , flow_id = self . flow_id )","title":"run()"},{"location":"api/flows/#lume_services.flows.flow.Flow.run_and_return","text":"run_and_return ( parameters , run_config , task_name : Optional [ str ], scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Run flow and return result. Result will reference either passed task name or the result of all tasks. Source code in lume_services/flows/flow.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def run_and_return ( self , parameters , run_config , task_name : Optional [ str ], scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): \"\"\"Run flow and return result. Result will reference either passed task name or the result of all tasks. \"\"\" if isinstance ( scheduling_service . backend , ( LocalBackend ,)): if self . prefect_flow is None : self . load_flow () scheduling_service . run_and_return ( parameters = parameters , run_config = run_config , flow = self . prefect_flow , task_name = task_name , ) elif isinstance ( scheduling_service . backend , ( ServerBackend ,)): scheduling_service . run_and_return ( parameters = parameters , run_config = run_config , flow_id = self . flow_id , task_name = task_name , )","title":"run_and_return()"},{"location":"api/flows/#lume_services.flows.flow.FlowConfig","text":"Bases: BaseModel","title":"FlowConfig"},{"location":"api/flows/#lume_services.flows.flow.FlowConfig-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.FlowConfig.image","text":"image : Optional [ str ]","title":"image"},{"location":"api/flows/#lume_services.flows.flow.FlowConfig.env","text":"env : Optional [ List [ str ]]","title":"env"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig","text":"Bases: BaseModel","title":"FlowRunConfig"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.poll_interval","text":"poll_interval : timedelta = timedelta ( seconds = 10 )","title":"poll_interval"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.scheduled_start_time","text":"scheduled_start_time : Optional [ datetime ]","title":"scheduled_start_time"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.parameters","text":"parameters : Optional [ Dict [ str , Any ]]","title":"parameters"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.run_config","text":"run_config : Optional [ RunConfig ]","title":"run_config"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.labels","text":"labels : Optional [ List [ str ]]","title":"labels"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.run_name","text":"run_name : Optional [ str ]","title":"run_name"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig-classes","text":"","title":"Classes"},{"location":"api/flows/#lume_services.flows.flow.FlowRunConfig.Config","text":"Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True","title":"Config"},{"location":"api/flows/#lume_services.flows.flow_of_flows","text":"","title":"flow_of_flows"},{"location":"api/flows/#lume_services.flows.flow_of_flows-classes","text":"","title":"Classes"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows","text":"Bases: Flow","title":"FlowOfFlows"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows-attributes","text":"","title":"Attributes"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.composing_flows","text":"composing_flows : dict","title":"composing_flows"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows-classes","text":"","title":"Classes"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.Config","text":"Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True","title":"Config"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows-functions","text":"","title":"Functions"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.validate","text":"validate ( values : dict ) Validate composing flow data against Prefect server. Source code in lume_services/flows/flow_of_flows.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @root_validator ( pre = True ) def validate ( cls , values : dict ): \"\"\"Validate composing flow data against Prefect server.\"\"\" flows = {} scheduling_service = None if \"scheduling_service\" in values : scheduling_service = values . pop ( \"scheduling_service\" ) # validate composing flow existence composing_flows = values . get ( \"composing_flows\" ) if isinstance ( composing_flows , ( dict ,)): pass # iterate to create dict elif isinstance ( composing_flows , ( list ,)): for flow in values [ \"composing_flows\" ]: # compose flow objects flow_obj = Flow ( name = flow [ \"name\" ], project_name = flow [ \"project_name\" ], mapped_parameters = flow . get ( \"mapped_parameters\" ), ) # load Prefect parameters if scheduling_service is not None : flow_obj . load_flow ( scheduling_service = scheduling_service ) else : flow_obj . load_flow () flows [ flow [ \"name\" ]] = flow_obj # validate flow parameters for flow_name , flow in flows . items (): if flow . mapped_parameters is not None : for parameter_name , parameter in flow . mapped_parameters . items (): # validate parameter is in flow spec parameter_obj = flow . parameters . get ( parameter_name ) if parameter_obj is None : raise ParameterNotInFlowError ( parameter_name , flow_name ) # validate parent flow is included in listed flows parent_flow = flows . get ( parameter . parent_flow_name ) if parent_flow is None : raise ParentFlowNotInFlowsError ( parameter . parent_flow_name , list ( flows . keys ()) ) # validate task is in the parent flow task = parent_flow . task_slugs . get ( parameter . parent_task_name ) if task is None : raise TaskNotInFlowError ( parameter . parent_flow_name , parameter . parent_task_name ) values [ \"composing_flows\" ] = flows return values","title":"validate()"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.compose","text":"compose ( image_name : str , image_tag : str = \"latest\" , local : bool = False , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> PrefectFlow Compose Prefect flow from FlowOfFlows object. Uses base image assigned to the FlowOfFlows Object and builds a new Docker image containing the composite flow. Parameters: Name Type Description Default image_name str Name of generated image. required image_tag str Tag of generated image. 'latest' local bool=False Whether to use local images for the base image. False Returns: Type Description PrefectFlow PrefectFlow Source code in lume_services/flows/flow_of_flows.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def compose ( self , image_name : str , image_tag : str = \"latest\" , local : bool = False , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) -> PrefectFlow : \"\"\"Compose Prefect flow from FlowOfFlows object. Uses base image assigned to the FlowOfFlows Object and builds a new Docker image containing the composite flow. Args: image_name (str): Name of generated image. image_tag (str): Tag of generated image. local (bool=False): Whether to use local images for the base image. Returns: PrefectFlow \"\"\" # compose flow of flows with PrefectFlow ( self . name , storage = Docker ( base_image = self . image , image_name = image_name , image_tag = image_tag , local_image = local , ), ) as composed_flow : flow_runs = {} flow_waits = {} params = {} for i , ( flow_name , flow ) in enumerate ( self . composing_flows . items ()): # begin by creating parameters for all flow parameters flow_params = {} for param_name , param in flow . parameters . items (): # update name and slug param . name = f \" { flow_name } - { param_name } \" param . slug = f \" { flow_name } - { param_name } \" params [ param . name ] = param # use original param name for flow config flow_params [ param_name ] = param # set up entry task if i == 0 : flow_run = create_flow_run ( flow_id = flow . flow_id , parameters = flow_params , labels = flow . labels , ) # setup other tasks elif i > 0 : # create references to parameters upstream_flows = set () if flow . mapped_parameters is not None : # update flow_params with mapping for param_name , mapped_param in flow . mapped_parameters . items (): task_slug = self . composing_flows [ mapped_param . parent_flow_name ] . task_slugs [ mapped_param . parent_task_name ] task_run_result = get_task_run_result ( flow_runs [ mapped_param . parent_flow_name ], task_slug ) # raw results and file results use their values directly if mapped_param . map_type in [ \"raw\" , \"file\" ]: flow . prefect_flow . replace ( flow_params . pop ( param_name ), task_run_result ) # handle database results elif mapped_param . map_type == \"db\" : load_db_result = LoadDBResult () db_result = load_db_result ( task_run_result , mapped_param . attribute , attribute_index = mapped_param . attribute_index , ) flow . prefect_flow . replace ( flow_params . pop ( param_name ), db_result ) # add db result parameters to the task and create edge for param in load_db_result . parameters : flow . prefect_flow . add_task ( param ) flow . prefect_flow . add_edge ( param , load_db_result , mapped = True ) else : # should never reach if instantiating MappedParameter mapped_param_types = get_args ( MappedParameter . __fields__ [ \"map_type\" ] . type_ ) raise ValueError ( f \"Task type { mapped_param . map_type } not in task. \\ Allowed types: { mapped_param_types } .\" ) # add flow to upstream upstream_flows . add ( mapped_param . parent_flow_name ) # add creation of flow run to flow flow_run = create_flow_run ( flow_id = flow . flow_id , parameters = flow_params , labels = flow . labels , ) # configure upstreams if any for upstream in upstream_flows : flow_run . set_upstream ( flow_waits [ upstream ]) flow_wait = wait_for_flow_run ( flow_run , raise_final_state = True ) flow_runs [ flow_name ] = flow_run flow_waits [ flow_name ] = flow_wait # validate flow of flows composed_flow . validate () # assign to obj self . prefect_flow = composed_flow self . image = f \" { image_name } : { image_tag } \" return composed_flow","title":"compose()"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.compose_and_register","text":"compose_and_register () Compose flow and register with project. Returns: Name Type Description str Registered flow id Source code in lume_services/flows/flow_of_flows.py 235 236 237 238 239 240 241 242 243 244 245 def compose_and_register ( self ): \"\"\"Compose flow and register with project. Returns: str: Registered flow id \"\"\" flow = self . compose () self . prefect_flow = flow return self . register ( self . project_name )","title":"compose_and_register()"},{"location":"api/flows/#lume_services.flows.flow_of_flows.FlowOfFlows.from_yaml","text":"from_yaml ( yaml_obj , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ) Source code in lume_services/flows/flow_of_flows.py 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 @classmethod @inject def from_yaml ( cls , yaml_obj , scheduling_service : SchedulingService = Provide [ Context . scheduling_service ], ): if os . path . exists ( yaml_obj ): flow_of_flow_config = yaml . safe_load ( open ( yaml_obj )) else : flow_of_flow_config = yaml_obj # now validate return cls ( ** flow_of_flow_config , scheduling_service = scheduling_service )","title":"from_yaml()"},{"location":"api/results/","text":"lume_services.results.generic Attributes Classes Result Bases: BaseModel Creates a data model for a result and generates a unique result hash. Attributes model_type class-attribute model_type : str = Field ( 'generic' , alias = 'collection' ) id class-attribute id : Optional [ str ] = Field ( alias = '_id' , exclude = True ) flow_id class-attribute flow_id : str inputs class-attribute inputs : dict outputs class-attribute outputs : dict date_modified class-attribute date_modified : datetime = datetime . utcnow () unique_on class-attribute unique_on : List [ str ] = Field ( [ \"inputs\" , \"outputs\" , \"flow_id\" ], alias = \"index\" , exclude = True , ) unique_hash class-attribute unique_hash : str result_type_string class-attribute result_type_string : str Classes Config Attributes allow_arbitrary_types class-attribute allow_arbitrary_types = True json_encoders class-attribute json_encoders = JSON_ENCODERS allow_population_by_field_name class-attribute allow_population_by_field_name = True extra class-attribute extra = Extra . forbid Functions validate_all validate_all ( values ) Source code in lume_services/results/generic.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @root_validator ( pre = True ) def validate_all ( cls , values ): unique_fields = cls . __fields__ [ \"unique_on\" ] . default # If flow_id is not passed, check prefect context if not values . get ( \"flow_id\" ): if not context . flow_id : raise ValueError ( \"No flow_id passed to result\" ) values [ \"flow_id\" ] = context . flow_id # create index hash if not values . get ( \"unique_hash\" ): for field in unique_fields : if not values . get ( field ): raise ValueError ( \" %s not provided.\" , field ) values [ \"unique_hash\" ] = fingerprint_dict ( { index : values [ index ] for index in unique_fields } ) if values . get ( \"_id\" ): id = values [ \"_id\" ] if isinstance ( id , ( ObjectId ,)): values [ \"_id\" ] = str ( values [ \"_id\" ]) values [ \"result_type_string\" ] = f \" { cls . __module__ } : { cls . __name__ } \" return values get_unique_result_index get_unique_result_index () -> dict Source code in lume_services/results/generic.py 78 79 def get_unique_result_index ( self ) -> dict : return { field : getattr ( self , field ) for field in self . unique_on } insert insert ( results_db_service : ResultsDB = Provide [ Context . results_db_service ], ) Source code in lume_services/results/generic.py 81 82 83 84 85 86 87 88 @inject def insert ( self , results_db_service : ResultsDB = Provide [ Context . results_db_service ] ): # must convert to jsonable dict rep = self . jsonable_dict () return results_db_service . insert_one ( rep ) load_from_query classmethod load_from_query ( query , results_db_service : ResultsDB = Provide [ Context . results_db_service ], ) Source code in lume_services/results/generic.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @classmethod @inject def load_from_query ( cls , query , results_db_service : ResultsDB = Provide [ Context . results_db_service ], ): res = results_db_service . find ( collection = cls . __fields__ [ \"model_type\" ] . default , query = query ) if len ( res ) == 0 : raise ValueError ( \"Provided query returned no results. %s \" , query ) elif len ( res ) > 1 : raise ValueError ( \"Provided query returned multiple results. %s \" , query ) return cls ( ** res [ 0 ]) jsonable_dict jsonable_dict () -> dict Source code in lume_services/results/generic.py 109 110 def jsonable_dict ( self ) -> dict : return json . loads ( self . json ( by_alias = True )) unique_rep unique_rep () -> dict Get minimal representation needed to load result object from database. Source code in lume_services/results/generic.py 112 113 114 115 116 117 def unique_rep ( self ) -> dict : \"\"\"Get minimal representation needed to load result object from database.\"\"\" return { \"result_type_string\" : self . result_type_string , \"query\" : self . get_unique_result_index (), } Functions lume_services.results.impact Attributes Classes ImpactResult Bases: Result Extends Result base and implements Impact specific attributes Attributes model_type class-attribute model_type : str = Field ( 'Impact' , alias = 'collection' ) plot_file class-attribute plot_file : Optional [ ImageFile ] archive class-attribute archive : HDF5File pv_collection_isotime class-attribute pv_collection_isotime : datetime config class-attribute config : dict","title":"Results"},{"location":"api/results/#lume_services.results.generic","text":"","title":"generic"},{"location":"api/results/#lume_services.results.generic-attributes","text":"","title":"Attributes"},{"location":"api/results/#lume_services.results.generic-classes","text":"","title":"Classes"},{"location":"api/results/#lume_services.results.generic.Result","text":"Bases: BaseModel Creates a data model for a result and generates a unique result hash.","title":"Result"},{"location":"api/results/#lume_services.results.generic.Result-attributes","text":"","title":"Attributes"},{"location":"api/results/#lume_services.results.generic.Result.model_type","text":"model_type : str = Field ( 'generic' , alias = 'collection' )","title":"model_type"},{"location":"api/results/#lume_services.results.generic.Result.id","text":"id : Optional [ str ] = Field ( alias = '_id' , exclude = True )","title":"id"},{"location":"api/results/#lume_services.results.generic.Result.flow_id","text":"flow_id : str","title":"flow_id"},{"location":"api/results/#lume_services.results.generic.Result.inputs","text":"inputs : dict","title":"inputs"},{"location":"api/results/#lume_services.results.generic.Result.outputs","text":"outputs : dict","title":"outputs"},{"location":"api/results/#lume_services.results.generic.Result.date_modified","text":"date_modified : datetime = datetime . utcnow ()","title":"date_modified"},{"location":"api/results/#lume_services.results.generic.Result.unique_on","text":"unique_on : List [ str ] = Field ( [ \"inputs\" , \"outputs\" , \"flow_id\" ], alias = \"index\" , exclude = True , )","title":"unique_on"},{"location":"api/results/#lume_services.results.generic.Result.unique_hash","text":"unique_hash : str","title":"unique_hash"},{"location":"api/results/#lume_services.results.generic.Result.result_type_string","text":"result_type_string : str","title":"result_type_string"},{"location":"api/results/#lume_services.results.generic.Result-classes","text":"","title":"Classes"},{"location":"api/results/#lume_services.results.generic.Result.Config","text":"Attributes allow_arbitrary_types class-attribute allow_arbitrary_types = True json_encoders class-attribute json_encoders = JSON_ENCODERS allow_population_by_field_name class-attribute allow_population_by_field_name = True extra class-attribute extra = Extra . forbid","title":"Config"},{"location":"api/results/#lume_services.results.generic.Result-functions","text":"","title":"Functions"},{"location":"api/results/#lume_services.results.generic.Result.validate_all","text":"validate_all ( values ) Source code in lume_services/results/generic.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @root_validator ( pre = True ) def validate_all ( cls , values ): unique_fields = cls . __fields__ [ \"unique_on\" ] . default # If flow_id is not passed, check prefect context if not values . get ( \"flow_id\" ): if not context . flow_id : raise ValueError ( \"No flow_id passed to result\" ) values [ \"flow_id\" ] = context . flow_id # create index hash if not values . get ( \"unique_hash\" ): for field in unique_fields : if not values . get ( field ): raise ValueError ( \" %s not provided.\" , field ) values [ \"unique_hash\" ] = fingerprint_dict ( { index : values [ index ] for index in unique_fields } ) if values . get ( \"_id\" ): id = values [ \"_id\" ] if isinstance ( id , ( ObjectId ,)): values [ \"_id\" ] = str ( values [ \"_id\" ]) values [ \"result_type_string\" ] = f \" { cls . __module__ } : { cls . __name__ } \" return values","title":"validate_all()"},{"location":"api/results/#lume_services.results.generic.Result.get_unique_result_index","text":"get_unique_result_index () -> dict Source code in lume_services/results/generic.py 78 79 def get_unique_result_index ( self ) -> dict : return { field : getattr ( self , field ) for field in self . unique_on }","title":"get_unique_result_index()"},{"location":"api/results/#lume_services.results.generic.Result.insert","text":"insert ( results_db_service : ResultsDB = Provide [ Context . results_db_service ], ) Source code in lume_services/results/generic.py 81 82 83 84 85 86 87 88 @inject def insert ( self , results_db_service : ResultsDB = Provide [ Context . results_db_service ] ): # must convert to jsonable dict rep = self . jsonable_dict () return results_db_service . insert_one ( rep )","title":"insert()"},{"location":"api/results/#lume_services.results.generic.Result.load_from_query","text":"load_from_query ( query , results_db_service : ResultsDB = Provide [ Context . results_db_service ], ) Source code in lume_services/results/generic.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @classmethod @inject def load_from_query ( cls , query , results_db_service : ResultsDB = Provide [ Context . results_db_service ], ): res = results_db_service . find ( collection = cls . __fields__ [ \"model_type\" ] . default , query = query ) if len ( res ) == 0 : raise ValueError ( \"Provided query returned no results. %s \" , query ) elif len ( res ) > 1 : raise ValueError ( \"Provided query returned multiple results. %s \" , query ) return cls ( ** res [ 0 ])","title":"load_from_query()"},{"location":"api/results/#lume_services.results.generic.Result.jsonable_dict","text":"jsonable_dict () -> dict Source code in lume_services/results/generic.py 109 110 def jsonable_dict ( self ) -> dict : return json . loads ( self . json ( by_alias = True ))","title":"jsonable_dict()"},{"location":"api/results/#lume_services.results.generic.Result.unique_rep","text":"unique_rep () -> dict Get minimal representation needed to load result object from database. Source code in lume_services/results/generic.py 112 113 114 115 116 117 def unique_rep ( self ) -> dict : \"\"\"Get minimal representation needed to load result object from database.\"\"\" return { \"result_type_string\" : self . result_type_string , \"query\" : self . get_unique_result_index (), }","title":"unique_rep()"},{"location":"api/results/#lume_services.results.generic-functions","text":"","title":"Functions"},{"location":"api/results/#lume_services.results.impact","text":"","title":"impact"},{"location":"api/results/#lume_services.results.impact-attributes","text":"","title":"Attributes"},{"location":"api/results/#lume_services.results.impact-classes","text":"","title":"Classes"},{"location":"api/results/#lume_services.results.impact.ImpactResult","text":"Bases: Result Extends Result base and implements Impact specific attributes","title":"ImpactResult"},{"location":"api/results/#lume_services.results.impact.ImpactResult-attributes","text":"","title":"Attributes"},{"location":"api/results/#lume_services.results.impact.ImpactResult.model_type","text":"model_type : str = Field ( 'Impact' , alias = 'collection' )","title":"model_type"},{"location":"api/results/#lume_services.results.impact.ImpactResult.plot_file","text":"plot_file : Optional [ ImageFile ]","title":"plot_file"},{"location":"api/results/#lume_services.results.impact.ImpactResult.archive","text":"archive : HDF5File","title":"archive"},{"location":"api/results/#lume_services.results.impact.ImpactResult.pv_collection_isotime","text":"pv_collection_isotime : datetime","title":"pv_collection_isotime"},{"location":"api/results/#lume_services.results.impact.ImpactResult.config","text":"config : dict","title":"config"},{"location":"api/utils/","text":"lume_services.utils Attributes ObjType module-attribute ObjType = TypeVar ( 'ObjType' ) JSON_ENCODERS module-attribute JSON_ENCODERS = { FunctionType : lambda x : f \" { x . __module__ } . { x . __qualname__ } \" , MethodType : lambda x : f \" { x . __module__ } . { x . __qualname__ } \" , Callable : lambda x : f \" { x . __module__ } . { type ( x ) . __qualname__ } \" , type : lambda x : f \" { x . __module__ } . { x . __name__ } \" , ObjType : lambda x : f \" { x . __module__ } . { x . __class__ . __qualname__ } \" , } Classes SignatureModel Bases: BaseModel Classes Config Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True Functions build build ( * args , ** kwargs ) Source code in lume_services/utils.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def build ( self , * args , ** kwargs ): stored_kwargs = self . dict () stored_args = [] if \"args\" in stored_kwargs : stored_args = stored_kwargs . pop ( \"args\" ) # adjust for positional args = list ( args ) n_pos_only = len ( stored_args ) positional_kwargs = [] if len ( args ) < n_pos_only : stored_args [: n_pos_only ] = args else : stored_args = args [: n_pos_only ] positional_kwargs = args [ n_pos_only :] stored_kwargs . update ( kwargs ) # exclude empty parameters stored_kwargs = { key : value for key , value in stored_kwargs . items () if not value == inspect . Parameter . empty } if len ( positional_kwargs ): for i , positional_kwarg in enumerate ( positional_kwargs ): stored_kwargs [ self . kwarg_order [ i ]] = positional_kwarg return stored_args , stored_kwargs CallableModel Bases: BaseModel Attributes callable class-attribute callable : Callable signature class-attribute signature : SignatureModel Classes Config Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True json_encoders class-attribute json_encoders = JSON_ENCODERS extra class-attribute extra = Extra . forbid Functions validate_all validate_all ( values ) Source code in lume_services/utils.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 @root_validator ( pre = True ) def validate_all ( cls , values ): callable = values . pop ( \"callable\" ) if not isinstance ( callable , ( str , Callable , ), ): raise ValueError ( \"Callable must be object or a string. Provided %s \" , type ( callable ) ) # parse string to callable if isinstance ( callable , ( str ,)): # for function loading if \"bind\" in values : callable = get_callable_from_string ( callable , bind = values . pop ( \"bind\" )) else : callable = get_callable_from_string ( callable ) values [ \"callable\" ] = callable # for reloading: kwargs = {} args = [] if \"args\" in values : args = values . pop ( \"args\" ) if \"kwargs\" in values : kwargs = values . pop ( \"kwargs\" ) if \"signature\" in values : if \"args\" in values [ \"signature\" ]: args = values [ \"signature\" ] . pop ( \"args\" ) # not needed during reserialization if \"kwarg_order\" in values [ \"signature\" ]: values [ \"signature\" ] . pop ( \"kwarg_order\" ) if \"kwargs\" in values : kwargs = values [ \"signature\" ][ \"kwargs\" ] else : kwargs = values [ \"signature\" ] values [ \"signature\" ] = validate_and_compose_signature ( callable , * args , ** kwargs ) return values ObjLoader Bases: GenericModel , Generic [ ObjType ] Attributes object class-attribute object : Optional [ ObjType ] loader class-attribute loader : CallableModel = None object_type class-attribute object_type : Optional [ type ] Functions validate_all validate_all ( values ) Source code in lume_services/utils.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 @root_validator ( pre = True ) def validate_all ( cls , values ): # inspect class init signature obj_type = cls . __fields__ [ \"object\" ] . type_ # adjust for re init from json if \"loader\" not in values : loader = CallableModel ( callable = obj_type , ** values ) else : # if already-initialized callable, do nothing if isinstance ( values [ \"loader\" ], ( CallableModel ,)): loader = values [ \"loader\" ] else : # validate loader callable is same as obj type if values [ \"loader\" ] . get ( \"callable\" ) is not None : # unparameterized callable will handle parsing callable = CallableModel ( callable = values [ \"loader\" ][ \"callable\" ]) if callable . callable is not obj_type : raise ValueError ( \"Provided loader of type %s . ObjLoader parameterized for \\ %s \" , callable . callable . __name__ , obj_type , ) # opt for obj type values [ \"loader\" ] . pop ( \"callable\" ) # re-init drop callable from loader vals to use new instance loader = CallableModel ( callable = obj_type , ** values [ \"loader\" ]) # update the class json encoders. Will only execute on initial type construction if obj_type not in cls . __config__ . json_encoders : cls . __config__ . json_encoders [ obj_type ] = cls . __config__ . json_encoders . pop ( ObjType ) return { \"object_type\" : obj_type , \"loader\" : loader } load load ( store : bool = False ) Source code in lume_services/utils.py 394 395 396 397 398 399 400 401 402 def load ( self , store : bool = False ): # store object reference on loader if store : self . object = self . loader . call () return self . object # return loaded object w/o storing else : return self . loader () Functions docker_api_version docker_api_version () Source code in lume_services/utils.py 16 17 18 def docker_api_version (): client = docker . from_env () return client . api . version ()[ \"ApiVersion\" ] filter_keys_in_settings filter_keys_in_settings ( dictionary : dict , settings_obj : BaseSettings ) -> dict Utility function for checking the membership of dictionary keys in a settings class definition. Parameters: Name Type Description Default dictionary dict Dictionary to check required settings_obj BaseSettings Settings object for composing required Source code in lume_services/utils.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def filter_keys_in_settings ( dictionary : dict , settings_obj : BaseSettings ) -> dict : \"\"\"Utility function for checking the membership of dictionary keys in a settings class definition. Args: dictionary (dict): Dictionary to check settings_obj (BaseSettings): Settings object for composing \"\"\" not_in_settings = [ key for key in dictionary . keys () if key not in settings_obj . attributes ] in_settings = [ key for key in dictionary . keys () if key not in settings_obj . attributes ] if len ( not_in_settings ): logger . warning ( \"Key %s not found in settings. Allowed keys are for %s are %s \" , \",\" . join ( not_in_settings ), settings_obj . class_name , \",\" . join ( settings_obj . attributes ), ) return { key : value for key , value in dictionary . items () if key in in_settings } fingerprint_dict fingerprint_dict ( dictionary : dict ) Source code in lume_services/utils.py 48 49 50 51 52 def fingerprint_dict ( dictionary : dict ): hasher = hashlib . md5 () hasher . update ( json . dumps ( dictionary ) . encode ( \"utf-8\" )) return hasher . hexdigest () flatten_dict flatten_dict ( d ) Source code in lume_services/utils.py 55 56 57 58 59 60 61 62 63 64 def flatten_dict ( d ): def expand ( key , value ): if isinstance ( value , dict ): return [( k , v ) for k , v in flatten_dict ( value ) . items ()] else : return [( key , value )] items = [ item for k , v in d . items () for item in expand ( k , v )] return dict ( items ) get_callable_from_string get_callable_from_string ( callable : str , bind : Any = None ) -> Callable Get callable from a string. In the case that the callable points to a bound method, the function returns a callable taking the bind instance as the first arg. Parameters: Name Type Description Default callable str String representation of callable abiding convention module :callable required bind Any Class to bind as self None Returns: Type Description Callable Callable Source code in lume_services/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def get_callable_from_string ( callable : str , bind : Any = None ) -> Callable : \"\"\"Get callable from a string. In the case that the callable points to a bound method, the function returns a callable taking the bind instance as the first arg. Args: callable: String representation of callable abiding convention __module__:callable bind: Class to bind as self Returns: Callable \"\"\" callable_split = callable . rsplit ( \".\" , 1 ) if len ( callable_split ) != 2 : raise ValueError ( f \"Improperly formatted callable string: { callable_split } \" ) module_name , callable_name = callable_split try : module = import_module ( module_name ) except ModuleNotFoundError : try : module_split = module_name . rsplit ( \".\" , 1 ) if len ( module_split ) != 2 : raise ValueError ( f \"Unable to access: { callable } \" ) module_name , class_name = module_split module = import_module ( module_name ) callable_name = f \" { class_name } . { callable_name } \" except ModuleNotFoundError as err : logger . error ( \"Unable to import module %s \" , module_name ) raise err except ValueError as err : logger . error ( err ) raise err # construct partial in case of bound method if \".\" in callable_name : bound_class , callable_name = callable_name . rsplit ( \".\" ) try : bound_class = getattr ( module , bound_class ) except Exception as e : logger . error ( \"Unable to get %s from %s \" , bound_class , module_name ) raise e # require right partial for assembly of callable # https://funcy.readthedocs.io/en/stable/funcs.html#rpartial def rpartial ( func , * args ): return lambda * a : func ( * ( a + args )) callable = getattr ( bound_class , callable_name ) params = inspect . signature ( callable ) . parameters # check bindings is_bound = params . get ( \"self\" , None ) is not None if not is_bound and bind is not None : raise ValueError ( \"Cannot bind %s to %s .\" , callable_name , bind ) # bound, return partial if bind is not None : if not isinstance ( bind , ( bound_class ,)): raise ValueError ( \"Provided bind %s is not instance of %s \" , bind , bound_class . __qualname__ , ) if is_bound and isinstance ( callable , ( FunctionType ,)) and bind is None : callable = rpartial ( getattr , callable_name ) elif is_bound and isinstance ( callable , ( FunctionType ,)) and bind is not None : callable = getattr ( bind , callable_name ) else : if bind is not None : raise ValueError ( \"Cannot bind %s to %s .\" , callable_name , type ( bind )) try : callable = getattr ( module , callable_name ) except Exception as e : logger . error ( \"Unable to get %s from %s \" , callable_name , module_name ) raise e return callable validate_and_compose_signature validate_and_compose_signature ( callable : Callable , * args , ** kwargs ) Source code in lume_services/utils.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def validate_and_compose_signature ( callable : Callable , * args , ** kwargs ): # try partial bind to validate signature = inspect . signature ( callable ) bound_args = signature . bind_partial ( * args , ** kwargs ) sig_kw = bound_args . arguments . get ( \"kwargs\" , {}) sig_args = bound_args . arguments . get ( \"args\" , []) sig_kwargs = {} # Now go parameter by parameter and assemble kwargs for i , param in enumerate ( signature . parameters . values ()): if param . kind in [ param . POSITIONAL_OR_KEYWORD , param . KEYWORD_ONLY ]: # if param not bound use default/ compose field rep if not sig_kw . get ( param . name ): # create a field representation if param . default == param . empty : sig_kwargs [ param . name ] = param . empty else : sig_kwargs [ param . name ] = param . default else : sig_kwargs [ param . name ] = sig_kw . get ( param . name ) # assign via binding if param . name in bound_args . arguments : sig_kwargs [ param . name ] = bound_args . arguments [ param . name ] # create pydantic model pydantic_fields = { \"args\" : ( List [ Any ], Field ( list ( sig_args ))), \"kwarg_order\" : Field ( list ( sig_kwargs . keys ()), exclude = True ), } for key , value in sig_kwargs . items (): if isinstance ( value , ( tuple ,)): pydantic_fields [ key ] = ( tuple , Field ( None )) elif value == inspect . Parameter . empty : pydantic_fields [ key ] = ( inspect . Parameter . empty , Field ( value )) else : # assigning empty default if value is None : pydantic_fields [ key ] = ( inspect . Parameter . empty , Field ( None )) else : pydantic_fields [ key ] = value model = create_model ( f \"Kwargs_ { callable . __qualname__ } \" , __base__ = SignatureModel , ** pydantic_fields ) return model ()","title":"Utils"},{"location":"api/utils/#lume_services.utils","text":"","title":"utils"},{"location":"api/utils/#lume_services.utils-attributes","text":"","title":"Attributes"},{"location":"api/utils/#lume_services.utils.ObjType","text":"ObjType = TypeVar ( 'ObjType' )","title":"ObjType"},{"location":"api/utils/#lume_services.utils.JSON_ENCODERS","text":"JSON_ENCODERS = { FunctionType : lambda x : f \" { x . __module__ } . { x . __qualname__ } \" , MethodType : lambda x : f \" { x . __module__ } . { x . __qualname__ } \" , Callable : lambda x : f \" { x . __module__ } . { type ( x ) . __qualname__ } \" , type : lambda x : f \" { x . __module__ } . { x . __name__ } \" , ObjType : lambda x : f \" { x . __module__ } . { x . __class__ . __qualname__ } \" , }","title":"JSON_ENCODERS"},{"location":"api/utils/#lume_services.utils-classes","text":"","title":"Classes"},{"location":"api/utils/#lume_services.utils.SignatureModel","text":"Bases: BaseModel","title":"SignatureModel"},{"location":"api/utils/#lume_services.utils.SignatureModel-classes","text":"","title":"Classes"},{"location":"api/utils/#lume_services.utils.SignatureModel.Config","text":"Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True","title":"Config"},{"location":"api/utils/#lume_services.utils.SignatureModel-functions","text":"","title":"Functions"},{"location":"api/utils/#lume_services.utils.SignatureModel.build","text":"build ( * args , ** kwargs ) Source code in lume_services/utils.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def build ( self , * args , ** kwargs ): stored_kwargs = self . dict () stored_args = [] if \"args\" in stored_kwargs : stored_args = stored_kwargs . pop ( \"args\" ) # adjust for positional args = list ( args ) n_pos_only = len ( stored_args ) positional_kwargs = [] if len ( args ) < n_pos_only : stored_args [: n_pos_only ] = args else : stored_args = args [: n_pos_only ] positional_kwargs = args [ n_pos_only :] stored_kwargs . update ( kwargs ) # exclude empty parameters stored_kwargs = { key : value for key , value in stored_kwargs . items () if not value == inspect . Parameter . empty } if len ( positional_kwargs ): for i , positional_kwarg in enumerate ( positional_kwargs ): stored_kwargs [ self . kwarg_order [ i ]] = positional_kwarg return stored_args , stored_kwargs","title":"build()"},{"location":"api/utils/#lume_services.utils.CallableModel","text":"Bases: BaseModel","title":"CallableModel"},{"location":"api/utils/#lume_services.utils.CallableModel-attributes","text":"","title":"Attributes"},{"location":"api/utils/#lume_services.utils.CallableModel.callable","text":"callable : Callable","title":"callable"},{"location":"api/utils/#lume_services.utils.CallableModel.signature","text":"signature : SignatureModel","title":"signature"},{"location":"api/utils/#lume_services.utils.CallableModel-classes","text":"","title":"Classes"},{"location":"api/utils/#lume_services.utils.CallableModel.Config","text":"Attributes arbitrary_types_allowed class-attribute arbitrary_types_allowed = True json_encoders class-attribute json_encoders = JSON_ENCODERS extra class-attribute extra = Extra . forbid","title":"Config"},{"location":"api/utils/#lume_services.utils.CallableModel-functions","text":"","title":"Functions"},{"location":"api/utils/#lume_services.utils.CallableModel.validate_all","text":"validate_all ( values ) Source code in lume_services/utils.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 @root_validator ( pre = True ) def validate_all ( cls , values ): callable = values . pop ( \"callable\" ) if not isinstance ( callable , ( str , Callable , ), ): raise ValueError ( \"Callable must be object or a string. Provided %s \" , type ( callable ) ) # parse string to callable if isinstance ( callable , ( str ,)): # for function loading if \"bind\" in values : callable = get_callable_from_string ( callable , bind = values . pop ( \"bind\" )) else : callable = get_callable_from_string ( callable ) values [ \"callable\" ] = callable # for reloading: kwargs = {} args = [] if \"args\" in values : args = values . pop ( \"args\" ) if \"kwargs\" in values : kwargs = values . pop ( \"kwargs\" ) if \"signature\" in values : if \"args\" in values [ \"signature\" ]: args = values [ \"signature\" ] . pop ( \"args\" ) # not needed during reserialization if \"kwarg_order\" in values [ \"signature\" ]: values [ \"signature\" ] . pop ( \"kwarg_order\" ) if \"kwargs\" in values : kwargs = values [ \"signature\" ][ \"kwargs\" ] else : kwargs = values [ \"signature\" ] values [ \"signature\" ] = validate_and_compose_signature ( callable , * args , ** kwargs ) return values","title":"validate_all()"},{"location":"api/utils/#lume_services.utils.ObjLoader","text":"Bases: GenericModel , Generic [ ObjType ]","title":"ObjLoader"},{"location":"api/utils/#lume_services.utils.ObjLoader-attributes","text":"","title":"Attributes"},{"location":"api/utils/#lume_services.utils.ObjLoader.object","text":"object : Optional [ ObjType ]","title":"object"},{"location":"api/utils/#lume_services.utils.ObjLoader.loader","text":"loader : CallableModel = None","title":"loader"},{"location":"api/utils/#lume_services.utils.ObjLoader.object_type","text":"object_type : Optional [ type ]","title":"object_type"},{"location":"api/utils/#lume_services.utils.ObjLoader-functions","text":"","title":"Functions"},{"location":"api/utils/#lume_services.utils.ObjLoader.validate_all","text":"validate_all ( values ) Source code in lume_services/utils.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 @root_validator ( pre = True ) def validate_all ( cls , values ): # inspect class init signature obj_type = cls . __fields__ [ \"object\" ] . type_ # adjust for re init from json if \"loader\" not in values : loader = CallableModel ( callable = obj_type , ** values ) else : # if already-initialized callable, do nothing if isinstance ( values [ \"loader\" ], ( CallableModel ,)): loader = values [ \"loader\" ] else : # validate loader callable is same as obj type if values [ \"loader\" ] . get ( \"callable\" ) is not None : # unparameterized callable will handle parsing callable = CallableModel ( callable = values [ \"loader\" ][ \"callable\" ]) if callable . callable is not obj_type : raise ValueError ( \"Provided loader of type %s . ObjLoader parameterized for \\ %s \" , callable . callable . __name__ , obj_type , ) # opt for obj type values [ \"loader\" ] . pop ( \"callable\" ) # re-init drop callable from loader vals to use new instance loader = CallableModel ( callable = obj_type , ** values [ \"loader\" ]) # update the class json encoders. Will only execute on initial type construction if obj_type not in cls . __config__ . json_encoders : cls . __config__ . json_encoders [ obj_type ] = cls . __config__ . json_encoders . pop ( ObjType ) return { \"object_type\" : obj_type , \"loader\" : loader }","title":"validate_all()"},{"location":"api/utils/#lume_services.utils.ObjLoader.load","text":"load ( store : bool = False ) Source code in lume_services/utils.py 394 395 396 397 398 399 400 401 402 def load ( self , store : bool = False ): # store object reference on loader if store : self . object = self . loader . call () return self . object # return loaded object w/o storing else : return self . loader ()","title":"load()"},{"location":"api/utils/#lume_services.utils-functions","text":"","title":"Functions"},{"location":"api/utils/#lume_services.utils.docker_api_version","text":"docker_api_version () Source code in lume_services/utils.py 16 17 18 def docker_api_version (): client = docker . from_env () return client . api . version ()[ \"ApiVersion\" ]","title":"docker_api_version()"},{"location":"api/utils/#lume_services.utils.filter_keys_in_settings","text":"filter_keys_in_settings ( dictionary : dict , settings_obj : BaseSettings ) -> dict Utility function for checking the membership of dictionary keys in a settings class definition. Parameters: Name Type Description Default dictionary dict Dictionary to check required settings_obj BaseSettings Settings object for composing required Source code in lume_services/utils.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def filter_keys_in_settings ( dictionary : dict , settings_obj : BaseSettings ) -> dict : \"\"\"Utility function for checking the membership of dictionary keys in a settings class definition. Args: dictionary (dict): Dictionary to check settings_obj (BaseSettings): Settings object for composing \"\"\" not_in_settings = [ key for key in dictionary . keys () if key not in settings_obj . attributes ] in_settings = [ key for key in dictionary . keys () if key not in settings_obj . attributes ] if len ( not_in_settings ): logger . warning ( \"Key %s not found in settings. Allowed keys are for %s are %s \" , \",\" . join ( not_in_settings ), settings_obj . class_name , \",\" . join ( settings_obj . attributes ), ) return { key : value for key , value in dictionary . items () if key in in_settings }","title":"filter_keys_in_settings()"},{"location":"api/utils/#lume_services.utils.fingerprint_dict","text":"fingerprint_dict ( dictionary : dict ) Source code in lume_services/utils.py 48 49 50 51 52 def fingerprint_dict ( dictionary : dict ): hasher = hashlib . md5 () hasher . update ( json . dumps ( dictionary ) . encode ( \"utf-8\" )) return hasher . hexdigest ()","title":"fingerprint_dict()"},{"location":"api/utils/#lume_services.utils.flatten_dict","text":"flatten_dict ( d ) Source code in lume_services/utils.py 55 56 57 58 59 60 61 62 63 64 def flatten_dict ( d ): def expand ( key , value ): if isinstance ( value , dict ): return [( k , v ) for k , v in flatten_dict ( value ) . items ()] else : return [( key , value )] items = [ item for k , v in d . items () for item in expand ( k , v )] return dict ( items )","title":"flatten_dict()"},{"location":"api/utils/#lume_services.utils.get_callable_from_string","text":"get_callable_from_string ( callable : str , bind : Any = None ) -> Callable Get callable from a string. In the case that the callable points to a bound method, the function returns a callable taking the bind instance as the first arg. Parameters: Name Type Description Default callable str String representation of callable abiding convention module :callable required bind Any Class to bind as self None Returns: Type Description Callable Callable Source code in lume_services/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def get_callable_from_string ( callable : str , bind : Any = None ) -> Callable : \"\"\"Get callable from a string. In the case that the callable points to a bound method, the function returns a callable taking the bind instance as the first arg. Args: callable: String representation of callable abiding convention __module__:callable bind: Class to bind as self Returns: Callable \"\"\" callable_split = callable . rsplit ( \".\" , 1 ) if len ( callable_split ) != 2 : raise ValueError ( f \"Improperly formatted callable string: { callable_split } \" ) module_name , callable_name = callable_split try : module = import_module ( module_name ) except ModuleNotFoundError : try : module_split = module_name . rsplit ( \".\" , 1 ) if len ( module_split ) != 2 : raise ValueError ( f \"Unable to access: { callable } \" ) module_name , class_name = module_split module = import_module ( module_name ) callable_name = f \" { class_name } . { callable_name } \" except ModuleNotFoundError as err : logger . error ( \"Unable to import module %s \" , module_name ) raise err except ValueError as err : logger . error ( err ) raise err # construct partial in case of bound method if \".\" in callable_name : bound_class , callable_name = callable_name . rsplit ( \".\" ) try : bound_class = getattr ( module , bound_class ) except Exception as e : logger . error ( \"Unable to get %s from %s \" , bound_class , module_name ) raise e # require right partial for assembly of callable # https://funcy.readthedocs.io/en/stable/funcs.html#rpartial def rpartial ( func , * args ): return lambda * a : func ( * ( a + args )) callable = getattr ( bound_class , callable_name ) params = inspect . signature ( callable ) . parameters # check bindings is_bound = params . get ( \"self\" , None ) is not None if not is_bound and bind is not None : raise ValueError ( \"Cannot bind %s to %s .\" , callable_name , bind ) # bound, return partial if bind is not None : if not isinstance ( bind , ( bound_class ,)): raise ValueError ( \"Provided bind %s is not instance of %s \" , bind , bound_class . __qualname__ , ) if is_bound and isinstance ( callable , ( FunctionType ,)) and bind is None : callable = rpartial ( getattr , callable_name ) elif is_bound and isinstance ( callable , ( FunctionType ,)) and bind is not None : callable = getattr ( bind , callable_name ) else : if bind is not None : raise ValueError ( \"Cannot bind %s to %s .\" , callable_name , type ( bind )) try : callable = getattr ( module , callable_name ) except Exception as e : logger . error ( \"Unable to get %s from %s \" , callable_name , module_name ) raise e return callable","title":"get_callable_from_string()"},{"location":"api/utils/#lume_services.utils.validate_and_compose_signature","text":"validate_and_compose_signature ( callable : Callable , * args , ** kwargs ) Source code in lume_services/utils.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def validate_and_compose_signature ( callable : Callable , * args , ** kwargs ): # try partial bind to validate signature = inspect . signature ( callable ) bound_args = signature . bind_partial ( * args , ** kwargs ) sig_kw = bound_args . arguments . get ( \"kwargs\" , {}) sig_args = bound_args . arguments . get ( \"args\" , []) sig_kwargs = {} # Now go parameter by parameter and assemble kwargs for i , param in enumerate ( signature . parameters . values ()): if param . kind in [ param . POSITIONAL_OR_KEYWORD , param . KEYWORD_ONLY ]: # if param not bound use default/ compose field rep if not sig_kw . get ( param . name ): # create a field representation if param . default == param . empty : sig_kwargs [ param . name ] = param . empty else : sig_kwargs [ param . name ] = param . default else : sig_kwargs [ param . name ] = sig_kw . get ( param . name ) # assign via binding if param . name in bound_args . arguments : sig_kwargs [ param . name ] = bound_args . arguments [ param . name ] # create pydantic model pydantic_fields = { \"args\" : ( List [ Any ], Field ( list ( sig_args ))), \"kwarg_order\" : Field ( list ( sig_kwargs . keys ()), exclude = True ), } for key , value in sig_kwargs . items (): if isinstance ( value , ( tuple ,)): pydantic_fields [ key ] = ( tuple , Field ( None )) elif value == inspect . Parameter . empty : pydantic_fields [ key ] = ( inspect . Parameter . empty , Field ( value )) else : # assigning empty default if value is None : pydantic_fields [ key ] = ( inspect . Parameter . empty , Field ( None )) else : pydantic_fields [ key ] = value model = create_model ( f \"Kwargs_ { callable . __qualname__ } \" , __base__ = SignatureModel , ** pydantic_fields ) return model ()","title":"validate_and_compose_signature()"},{"location":"api/files/files/","text":"lume_services.files.file Attributes logger module-attribute logger = logging . getLogger ( __name__ ) TextFile module-attribute TextFile = File [ TextSerializer ] HDF5File module-attribute HDF5File = File [ HDF5Serializer ] ImageFile module-attribute ImageFile = File [ ImageSerializer ] YAMLFile module-attribute YAMLFile = File [ YAMLSerializer ] Classes File Bases: GenericModel , Generic [ ObjType ] Attributes filename class-attribute filename : str obj class-attribute obj : Any = Field ( None , exclude = True ) loader class-attribute loader : Optional [ ObjLoader [ ObjType ]] serializer class-attribute serializer : ObjType = Field ( exclude = True ) filesystem_identifier class-attribute filesystem_identifier : str = 'local' file_type_string class-attribute file_type_string : str load class-attribute load : bool = Field ( False , exclude = True ) Functions validate_all validate_all ( values ) Source code in lume_services/files/file.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @root_validator ( pre = True ) def validate_all ( cls , values ): serializer_type = cls . __fields__ [ \"serializer\" ] . type_ # Compose loader utility if values . get ( \"loader\" ) is not None : loader_values = values [ \"loader\" ] loader = ObjLoader [ serializer_type ]( ** loader_values ) else : # maintain reference to original object loader_values = copy . copy ( values ) # if serializer in values, need to remove if \"serializer\" in loader_values : loader_values . pop ( \"serializer\" ) # if serializer_type in values, need to remove if \"serializer_type\" in loader_values : loader_values . pop ( \"serializer_type\" ) # if serializer_type in values, need to remove if \"filename\" in loader_values : loader_values . pop ( \"filename\" ) # if filesystem_identifier in values, need to remove if \"filesystem_identifier\" in loader_values : loader_values . pop ( \"filesystem_identifier\" ) # if obj in values, need to remove if \"obj\" in loader_values : loader_values . pop ( \"obj\" ) loader = ObjLoader [ serializer_type ]( ** loader_values ) values [ \"serializer_type\" ] = serializer_type values [ \"loader\" ] = loader values [ \"serializer\" ] = loader . load () values [ \"file_type_string\" ] = f \" { cls . __module__ } : { cls . __name__ } \" # update the class json encoders. Will only execute on initial type construction if serializer_type not in cls . __config__ . json_encoders : cls . __config__ . json_encoders [ serializer_type ] = cls . __config__ . json_encoders . pop ( ObjType ) return values write write ( obj = None , file_service : FileService = Provide [ Context . file_service ], create_dir = False , ) Source code in lume_services/files/file.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 @inject def write ( self , obj = None , file_service : FileService = Provide [ Context . file_service ], create_dir = False , ): if not obj : if not self . obj : raise ValueError ( \"Must provide object to write.\" ) file_service . write ( self . filesystem_identifier , self . filename , self . obj , self . serializer , create_dir = create_dir , ) else : self . obj = obj file_service . write ( self . filesystem_identifier , self . filename , obj , self . serializer , create_dir = create_dir , ) read read ( file_service : FileService = Provide [ Context . file_service ], ) Source code in lume_services/files/file.py 121 122 123 124 125 126 127 @inject def read ( self , file_service : FileService = Provide [ Context . file_service ]): return file_service . read ( self . filesystem_identifier , self . filename , self . serializer , ) load_file load_file ( file_service : FileService = Provide [ Context . file_service ], ) -> None Load file object from instantiated File. Source code in lume_services/files/file.py 129 130 131 132 133 134 @inject def load_file ( self , file_service : FileService = Provide [ Context . file_service ] ) -> None : \"\"\"Load file object from instantiated File.\"\"\" self . obj = self . read ( file_service = file_service ) jsonable_dict jsonable_dict () -> dict Source code in lume_services/files/file.py 136 137 def jsonable_dict ( self ) -> dict : return json . loads ( self . json ( by_alias = True ))","title":"File"},{"location":"api/files/files/#lume_services.files.file","text":"","title":"file"},{"location":"api/files/files/#lume_services.files.file-attributes","text":"","title":"Attributes"},{"location":"api/files/files/#lume_services.files.file.logger","text":"logger = logging . getLogger ( __name__ )","title":"logger"},{"location":"api/files/files/#lume_services.files.file.TextFile","text":"TextFile = File [ TextSerializer ]","title":"TextFile"},{"location":"api/files/files/#lume_services.files.file.HDF5File","text":"HDF5File = File [ HDF5Serializer ]","title":"HDF5File"},{"location":"api/files/files/#lume_services.files.file.ImageFile","text":"ImageFile = File [ ImageSerializer ]","title":"ImageFile"},{"location":"api/files/files/#lume_services.files.file.YAMLFile","text":"YAMLFile = File [ YAMLSerializer ]","title":"YAMLFile"},{"location":"api/files/files/#lume_services.files.file-classes","text":"","title":"Classes"},{"location":"api/files/files/#lume_services.files.file.File","text":"Bases: GenericModel , Generic [ ObjType ]","title":"File"},{"location":"api/files/files/#lume_services.files.file.File-attributes","text":"","title":"Attributes"},{"location":"api/files/files/#lume_services.files.file.File.filename","text":"filename : str","title":"filename"},{"location":"api/files/files/#lume_services.files.file.File.obj","text":"obj : Any = Field ( None , exclude = True )","title":"obj"},{"location":"api/files/files/#lume_services.files.file.File.loader","text":"loader : Optional [ ObjLoader [ ObjType ]]","title":"loader"},{"location":"api/files/files/#lume_services.files.file.File.serializer","text":"serializer : ObjType = Field ( exclude = True )","title":"serializer"},{"location":"api/files/files/#lume_services.files.file.File.filesystem_identifier","text":"filesystem_identifier : str = 'local'","title":"filesystem_identifier"},{"location":"api/files/files/#lume_services.files.file.File.file_type_string","text":"file_type_string : str","title":"file_type_string"},{"location":"api/files/files/#lume_services.files.file.File.load","text":"load : bool = Field ( False , exclude = True )","title":"load"},{"location":"api/files/files/#lume_services.files.file.File-functions","text":"","title":"Functions"},{"location":"api/files/files/#lume_services.files.file.File.validate_all","text":"validate_all ( values ) Source code in lume_services/files/file.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @root_validator ( pre = True ) def validate_all ( cls , values ): serializer_type = cls . __fields__ [ \"serializer\" ] . type_ # Compose loader utility if values . get ( \"loader\" ) is not None : loader_values = values [ \"loader\" ] loader = ObjLoader [ serializer_type ]( ** loader_values ) else : # maintain reference to original object loader_values = copy . copy ( values ) # if serializer in values, need to remove if \"serializer\" in loader_values : loader_values . pop ( \"serializer\" ) # if serializer_type in values, need to remove if \"serializer_type\" in loader_values : loader_values . pop ( \"serializer_type\" ) # if serializer_type in values, need to remove if \"filename\" in loader_values : loader_values . pop ( \"filename\" ) # if filesystem_identifier in values, need to remove if \"filesystem_identifier\" in loader_values : loader_values . pop ( \"filesystem_identifier\" ) # if obj in values, need to remove if \"obj\" in loader_values : loader_values . pop ( \"obj\" ) loader = ObjLoader [ serializer_type ]( ** loader_values ) values [ \"serializer_type\" ] = serializer_type values [ \"loader\" ] = loader values [ \"serializer\" ] = loader . load () values [ \"file_type_string\" ] = f \" { cls . __module__ } : { cls . __name__ } \" # update the class json encoders. Will only execute on initial type construction if serializer_type not in cls . __config__ . json_encoders : cls . __config__ . json_encoders [ serializer_type ] = cls . __config__ . json_encoders . pop ( ObjType ) return values","title":"validate_all()"},{"location":"api/files/files/#lume_services.files.file.File.write","text":"write ( obj = None , file_service : FileService = Provide [ Context . file_service ], create_dir = False , ) Source code in lume_services/files/file.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 @inject def write ( self , obj = None , file_service : FileService = Provide [ Context . file_service ], create_dir = False , ): if not obj : if not self . obj : raise ValueError ( \"Must provide object to write.\" ) file_service . write ( self . filesystem_identifier , self . filename , self . obj , self . serializer , create_dir = create_dir , ) else : self . obj = obj file_service . write ( self . filesystem_identifier , self . filename , obj , self . serializer , create_dir = create_dir , )","title":"write()"},{"location":"api/files/files/#lume_services.files.file.File.read","text":"read ( file_service : FileService = Provide [ Context . file_service ], ) Source code in lume_services/files/file.py 121 122 123 124 125 126 127 @inject def read ( self , file_service : FileService = Provide [ Context . file_service ]): return file_service . read ( self . filesystem_identifier , self . filename , self . serializer , )","title":"read()"},{"location":"api/files/files/#lume_services.files.file.File.load_file","text":"load_file ( file_service : FileService = Provide [ Context . file_service ], ) -> None Load file object from instantiated File. Source code in lume_services/files/file.py 129 130 131 132 133 134 @inject def load_file ( self , file_service : FileService = Provide [ Context . file_service ] ) -> None : \"\"\"Load file object from instantiated File.\"\"\" self . obj = self . read ( file_service = file_service )","title":"load_file()"},{"location":"api/files/files/#lume_services.files.file.File.jsonable_dict","text":"jsonable_dict () -> dict Source code in lume_services/files/file.py 136 137 def jsonable_dict ( self ) -> dict : return json . loads ( self . json ( by_alias = True ))","title":"jsonable_dict()"},{"location":"api/files/serializers/","text":"Serializers lume_services.files.serializers.image Classes ImageSerializer Bases: SerializerBase Pillow image serializer. Functions serialize serialize ( filename , image : Image ) Source code in lume_services/files/serializers/image.py 8 9 def serialize ( self , filename , image : Image ): image . save ( filename ) deserialize classmethod deserialize ( filename ) -> Image Source code in lume_services/files/serializers/image.py 11 12 13 14 @classmethod def deserialize ( cls , filename ) -> Image : return Image . open ( filename ) lume_services.files.serializers.text Classes TextSerializer Bases: SerializerBase Functions serialize serialize ( filename , text ) Source code in lume_services/files/serializers/text.py 5 6 7 8 def serialize ( self , filename , text ): with open ( filename , \"w\" ) as f : f . write ( text ) deserialize classmethod deserialize ( filename ) Source code in lume_services/files/serializers/text.py 10 11 12 13 14 15 16 17 18 @classmethod def deserialize ( cls , filename ): text = \"\" with open ( filename , \"r\" ) as f : text = f . read () return text lume_services.files.serializers.yaml Classes YAMLSerializer Bases: SerializerBase Functions serialize serialize ( filename , object : List [ dict ]) -> None Source code in lume_services/files/serializers/yaml.py 7 8 9 10 def serialize ( self , filename , object : List [ dict ]) -> None : with open ( filename , \"w\" ) as f : yaml . dump ( object , f ) deserialize classmethod deserialize ( filename : str ) -> List [ dict ] Source code in lume_services/files/serializers/yaml.py 12 13 14 15 16 17 18 19 20 21 22 23 24 @classmethod def deserialize ( cls , filename : str ) -> List [ dict ]: yaml_rep = None with open ( filename , \"r\" ) as f : try : yaml_rep = yaml . safe_load ( f ) except yaml . YAMLError as exc : print ( exc ) return yaml_rep","title":"Serializers"},{"location":"api/files/serializers/#serializers","text":"","title":"Serializers"},{"location":"api/files/serializers/#lume_services.files.serializers.image","text":"","title":"image"},{"location":"api/files/serializers/#lume_services.files.serializers.image-classes","text":"","title":"Classes"},{"location":"api/files/serializers/#lume_services.files.serializers.image.ImageSerializer","text":"Bases: SerializerBase Pillow image serializer.","title":"ImageSerializer"},{"location":"api/files/serializers/#lume_services.files.serializers.image.ImageSerializer-functions","text":"","title":"Functions"},{"location":"api/files/serializers/#lume_services.files.serializers.image.ImageSerializer.serialize","text":"serialize ( filename , image : Image ) Source code in lume_services/files/serializers/image.py 8 9 def serialize ( self , filename , image : Image ): image . save ( filename )","title":"serialize()"},{"location":"api/files/serializers/#lume_services.files.serializers.image.ImageSerializer.deserialize","text":"deserialize ( filename ) -> Image Source code in lume_services/files/serializers/image.py 11 12 13 14 @classmethod def deserialize ( cls , filename ) -> Image : return Image . open ( filename )","title":"deserialize()"},{"location":"api/files/serializers/#lume_services.files.serializers.text","text":"","title":"text"},{"location":"api/files/serializers/#lume_services.files.serializers.text-classes","text":"","title":"Classes"},{"location":"api/files/serializers/#lume_services.files.serializers.text.TextSerializer","text":"Bases: SerializerBase","title":"TextSerializer"},{"location":"api/files/serializers/#lume_services.files.serializers.text.TextSerializer-functions","text":"","title":"Functions"},{"location":"api/files/serializers/#lume_services.files.serializers.text.TextSerializer.serialize","text":"serialize ( filename , text ) Source code in lume_services/files/serializers/text.py 5 6 7 8 def serialize ( self , filename , text ): with open ( filename , \"w\" ) as f : f . write ( text )","title":"serialize()"},{"location":"api/files/serializers/#lume_services.files.serializers.text.TextSerializer.deserialize","text":"deserialize ( filename ) Source code in lume_services/files/serializers/text.py 10 11 12 13 14 15 16 17 18 @classmethod def deserialize ( cls , filename ): text = \"\" with open ( filename , \"r\" ) as f : text = f . read () return text","title":"deserialize()"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml","text":"","title":"yaml"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml-classes","text":"","title":"Classes"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml.YAMLSerializer","text":"Bases: SerializerBase","title":"YAMLSerializer"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml.YAMLSerializer-functions","text":"","title":"Functions"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml.YAMLSerializer.serialize","text":"serialize ( filename , object : List [ dict ]) -> None Source code in lume_services/files/serializers/yaml.py 7 8 9 10 def serialize ( self , filename , object : List [ dict ]) -> None : with open ( filename , \"w\" ) as f : yaml . dump ( object , f )","title":"serialize()"},{"location":"api/files/serializers/#lume_services.files.serializers.yaml.YAMLSerializer.deserialize","text":"deserialize ( filename : str ) -> List [ dict ] Source code in lume_services/files/serializers/yaml.py 12 13 14 15 16 17 18 19 20 21 22 23 24 @classmethod def deserialize ( cls , filename : str ) -> List [ dict ]: yaml_rep = None with open ( filename , \"r\" ) as f : try : yaml_rep = yaml . safe_load ( f ) except yaml . YAMLError as exc : print ( exc ) return yaml_rep","title":"deserialize()"},{"location":"api/files/utils/","text":"lume_services.files.utils Attributes Functions get_file_from_serializer_string get_file_from_serializer_string ( file_type_string : str ) Source code in lume_services/files/utils.py 13 14 15 16 17 18 19 20 21 22 23 def get_file_from_serializer_string ( file_type_string : str ): if not _FileSerializerTypeStringMap . get ( file_type_string ): raise ValueError ( \"File string not in file types. %s , %s \" , file_type_string , list ( _FileSerializerTypeStringMap . keys ()), ) else : return _FileSerializerTypeStringMap . get ( file_type_string )","title":"Utils"},{"location":"api/files/utils/#lume_services.files.utils","text":"","title":"utils"},{"location":"api/files/utils/#lume_services.files.utils-attributes","text":"","title":"Attributes"},{"location":"api/files/utils/#lume_services.files.utils-functions","text":"","title":"Functions"},{"location":"api/files/utils/#lume_services.files.utils.get_file_from_serializer_string","text":"get_file_from_serializer_string ( file_type_string : str ) Source code in lume_services/files/utils.py 13 14 15 16 17 18 19 20 21 22 23 def get_file_from_serializer_string ( file_type_string : str ): if not _FileSerializerTypeStringMap . get ( file_type_string ): raise ValueError ( \"File string not in file types. %s , %s \" , file_type_string , list ( _FileSerializerTypeStringMap . keys ()), ) else : return _FileSerializerTypeStringMap . get ( file_type_string )","title":"get_file_from_serializer_string()"},{"location":"api/models/models/","text":"","title":"Models"},{"location":"api/services/files/files/","text":"lume_services.services.files.service Classes FilesystemNotConfigured FilesystemNotConfigured ( filesystem_identifier : str , configured_filesystems : List [ str ], ) Bases: Exception Source code in lume_services/services/files/service.py 12 13 14 15 16 17 18 def __init__ ( self , filesystem_identifier : str , configured_filesystems : List [ str ]): self . filesystem_identifier = filesystem_identifier self . configured_filesystems = configured_filesystems self . message = f \"Filesystem { filesystem_identifier } not configured. \\ Available filesystems are: { ',' . join ( configured_filesystems ) } \" super () . __init__ ( self . message ) Attributes filesystem_identifier instance-attribute filesystem_identifier = filesystem_identifier configured_filesystems instance-attribute configured_filesystems = configured_filesystems message instance-attribute message = f \"Filesystem { filesystem_identifier } not configured. Available filesystems are: { , . join ( configured_filesystems ) } \" Functions FileService FileService ( filesystems : List [ Filesystem ]) Allows saving and retrieval to multiple file storage locations. Parameters: Name Type Description Default filesystems List [ Filesystem ] List of filesystems required Source code in lume_services/services/files/service.py 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , filesystems : List [ Filesystem ]): \"\"\" Args: filesystems (List[Filesystem]): List of filesystems \"\"\" self . _filesystems = { filesystem . identifier : filesystem for filesystem in filesystems } Functions dir_exists dir_exists ( filesystem_identifier : str , dir : str , create_dir : bool = True , ) -> bool Check that a directory exists in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required dir str Directory path required create_dir bool Whether to create directory in case not implemented True Returns: Type Description bool bool Source code in lume_services/services/files/service.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def dir_exists ( self , filesystem_identifier : str , dir : str , create_dir : bool = True ) -> bool : \"\"\"Check that a directory exists in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem dir (str): Directory path create_dir (bool): Whether to create directory in case not implemented Returns: bool \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . dir_exists ( dir , create_dir = create_dir ) file_exists file_exists ( filesystem_identifier : str , file : str ) -> bool Check that a file exists in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required Returns: Type Description bool bool Source code in lume_services/services/files/service.py 52 53 54 55 56 57 58 59 60 61 62 63 64 def file_exists ( self , filesystem_identifier : str , file : str ) -> bool : \"\"\"Check that a file exists in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem Returns: bool \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . file_exists ( file ) create_dir create_dir ( filesystem_identifier : str , dir : str ) -> None Create a directory in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required dir str Directory path required Source code in lume_services/services/files/service.py 66 67 68 69 70 71 72 73 74 75 def create_dir ( self , filesystem_identifier : str , dir : str ) -> None : \"\"\"Create a directory in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem dir (str): Directory path \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . create_dir ( dir ) read read ( filesystem_identifier : str , file : str , serializer : SerializerBase , ) -> Any Read file from a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required file str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/service.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def read ( self , filesystem_identifier : str , file : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem file (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) return filesystem . read ( file , serializer ) write write ( filesystem_identifier : str , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = True , ) Write a file to a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required filepath str Save path for file required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented True Source code in lume_services/services/files/service.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def write ( self , filesystem_identifier : str , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = True , ): \"\"\"Write a file to a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem filepath (str): Save path for file object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . write ( filepath , object , serializer , create_dir = create_dir ) get_mounted_filesystems get_mounted_filesystems () -> Dict [ str , MountedFilesystem ] Return mounted filesystems Returns: Type Description Dict [ str , MountedFilesystem ] Dict[str, MountedFilesystem] Source code in lume_services/services/files/service.py 135 136 137 138 139 140 141 142 143 144 145 146 def get_mounted_filesystems ( self ) -> Dict [ str , MountedFilesystem ]: \"\"\"Return mounted filesystems Returns: Dict[str, MountedFilesystem] \"\"\" return { filesystem_identifier : filesystem for filesystem_identifier , filesystem in self . _filesystems . items () if isinstance ( filesystem , ( MountedFilesystem ,)) }","title":"File Service"},{"location":"api/services/files/files/#lume_services.services.files.service","text":"","title":"service"},{"location":"api/services/files/files/#lume_services.services.files.service-classes","text":"","title":"Classes"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured","text":"FilesystemNotConfigured ( filesystem_identifier : str , configured_filesystems : List [ str ], ) Bases: Exception Source code in lume_services/services/files/service.py 12 13 14 15 16 17 18 def __init__ ( self , filesystem_identifier : str , configured_filesystems : List [ str ]): self . filesystem_identifier = filesystem_identifier self . configured_filesystems = configured_filesystems self . message = f \"Filesystem { filesystem_identifier } not configured. \\ Available filesystems are: { ',' . join ( configured_filesystems ) } \" super () . __init__ ( self . message )","title":"FilesystemNotConfigured"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured-attributes","text":"","title":"Attributes"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured.filesystem_identifier","text":"filesystem_identifier = filesystem_identifier","title":"filesystem_identifier"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured.configured_filesystems","text":"configured_filesystems = configured_filesystems","title":"configured_filesystems"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured.message","text":"message = f \"Filesystem { filesystem_identifier } not configured. Available filesystems are: { , . join ( configured_filesystems ) } \"","title":"message"},{"location":"api/services/files/files/#lume_services.services.files.service.FilesystemNotConfigured-functions","text":"","title":"Functions"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService","text":"FileService ( filesystems : List [ Filesystem ]) Allows saving and retrieval to multiple file storage locations. Parameters: Name Type Description Default filesystems List [ Filesystem ] List of filesystems required Source code in lume_services/services/files/service.py 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , filesystems : List [ Filesystem ]): \"\"\" Args: filesystems (List[Filesystem]): List of filesystems \"\"\" self . _filesystems = { filesystem . identifier : filesystem for filesystem in filesystems }","title":"FileService"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService-functions","text":"","title":"Functions"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.dir_exists","text":"dir_exists ( filesystem_identifier : str , dir : str , create_dir : bool = True , ) -> bool Check that a directory exists in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required dir str Directory path required create_dir bool Whether to create directory in case not implemented True Returns: Type Description bool bool Source code in lume_services/services/files/service.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def dir_exists ( self , filesystem_identifier : str , dir : str , create_dir : bool = True ) -> bool : \"\"\"Check that a directory exists in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem dir (str): Directory path create_dir (bool): Whether to create directory in case not implemented Returns: bool \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . dir_exists ( dir , create_dir = create_dir )","title":"dir_exists()"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.file_exists","text":"file_exists ( filesystem_identifier : str , file : str ) -> bool Check that a file exists in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required Returns: Type Description bool bool Source code in lume_services/services/files/service.py 52 53 54 55 56 57 58 59 60 61 62 63 64 def file_exists ( self , filesystem_identifier : str , file : str ) -> bool : \"\"\"Check that a file exists in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem Returns: bool \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . file_exists ( file )","title":"file_exists()"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.create_dir","text":"create_dir ( filesystem_identifier : str , dir : str ) -> None Create a directory in a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required dir str Directory path required Source code in lume_services/services/files/service.py 66 67 68 69 70 71 72 73 74 75 def create_dir ( self , filesystem_identifier : str , dir : str ) -> None : \"\"\"Create a directory in a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem dir (str): Directory path \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . create_dir ( dir )","title":"create_dir()"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.read","text":"read ( filesystem_identifier : str , file : str , serializer : SerializerBase , ) -> Any Read file from a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required file str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/service.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def read ( self , filesystem_identifier : str , file : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem file (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) return filesystem . read ( file , serializer )","title":"read()"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.write","text":"write ( filesystem_identifier : str , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = True , ) Write a file to a filesystem. Parameters: Name Type Description Default filesystem_identifier str String dentifier for filesystem required filepath str Save path for file required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented True Source code in lume_services/services/files/service.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def write ( self , filesystem_identifier : str , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = True , ): \"\"\"Write a file to a filesystem. Args: filesystem_identifier (str): String dentifier for filesystem filepath (str): Save path for file object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" filesystem = self . _get_filesystem ( filesystem_identifier ) filesystem . write ( filepath , object , serializer , create_dir = create_dir )","title":"write()"},{"location":"api/services/files/files/#lume_services.services.files.service.FileService.get_mounted_filesystems","text":"get_mounted_filesystems () -> Dict [ str , MountedFilesystem ] Return mounted filesystems Returns: Type Description Dict [ str , MountedFilesystem ] Dict[str, MountedFilesystem] Source code in lume_services/services/files/service.py 135 136 137 138 139 140 141 142 143 144 145 146 def get_mounted_filesystems ( self ) -> Dict [ str , MountedFilesystem ]: \"\"\"Return mounted filesystems Returns: Dict[str, MountedFilesystem] \"\"\" return { filesystem_identifier : filesystem for filesystem_identifier , filesystem in self . _filesystems . items () if isinstance ( filesystem , ( MountedFilesystem ,)) }","title":"get_mounted_filesystems()"},{"location":"api/services/files/filesystems/","text":"lume_services.services.files.filesystems.filesystem Classes Filesystem Bases: ABC , BaseModel Attributes identifier class-attribute identifier : str Functions dir_exists abstractmethod dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/filesystem.py 10 11 12 13 14 15 16 17 18 19 20 21 @abstractmethod def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" ... file_exists abstractmethod file_exists ( filepath : str ) -> bool Check that a file exists Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/filesystem.py 23 24 25 26 27 28 29 30 31 32 33 34 @abstractmethod def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists Args: filepath (str): Path to file Returns: bool \"\"\" ... create_dir abstractmethod create_dir ( dir : str ) -> None Create a directory on the filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/filesystem.py 36 37 38 39 40 41 42 43 44 @abstractmethod def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the filesystem. Args: dir (str): Directory path to create \"\"\" ... read abstractmethod read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the filesystem. Parameters: Name Type Description Default filepath str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/filesystems/filesystem.py 46 47 48 49 50 51 52 53 54 55 56 @abstractmethod def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the filesystem. Args: filepath (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" ... write abstractmethod write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/filesystem.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @abstractmethod def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" ... lume_services.services.files.filesystems.local Classes LocalFilesystem Bases: Filesystem Handler for local filesystem. Attributes identifier class-attribute identifier : str = 'local' Functions dir_exists dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists on the local filesystem. Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/local.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists on the local filesystem. Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" # use absolute path path = os . path . abspath ( dir ) if os . path . isdir ( path ): logger . info ( \"Found directory %s on local filesystem.\" , path ) return True # if creating... if create_dir : self . create_dir ( path ) return True else : logger . info ( \"Unable to find directory %s on local filesystem.\" , path ) return False file_exists file_exists ( filepath : str ) -> bool Check that a file exists on the local filesystem. Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/local.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists on the local filesystem. Args: filepath (str): Path to file Returns: bool \"\"\" path = os . path . abspath ( filepath ) if os . path . isfile ( path ): logger . info ( \"Found file %s on local filesystem.\" , path ) return True else : logger . info ( \"Unable to find file %s on local filesystem.\" , path ) return False create_dir create_dir ( dir : str ) -> None Create a directory on the local filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/local.py 60 61 62 63 64 65 66 67 68 69 70 71 def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the local filesystem. Args: dir (str): Directory path to create \"\"\" try : os . makedirs ( dir , exist_ok = False ) except Exception as e : logger . error ( \"Unable to create directory %s on local filesystem.\" , dir ) raise e read read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the local filesystem. Parameters: Name Type Description Default filepath str Path of file to read. required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class. required Source code in lume_services/services/files/filesystems/local.py 73 74 75 76 77 78 79 80 81 82 83 84 def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the local filesystem. Args: filepath (str): Path of file to read. serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class. \"\"\" path = os . path . abspath ( filepath ) content = serializer . deserialize ( path ) return content write write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the local filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/local.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the local filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" path = os . path . abspath ( filepath ) dir = os . path . dirname ( path ) if create_dir and not self . dir_exists ( dir ): self . create_dir ( dir ) serializer . serialize ( path , object ) lume_services.services.files.filesystems.mounted Classes PathNotInMount PathNotInMount ( filesystem_identifier : str , path : str , mount_path : str , mount_alias : str , ) Bases: Exception Source code in lume_services/services/files/filesystems/mounted.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def __init__ ( self , filesystem_identifier : str , path : str , mount_path : str , mount_alias : str ): self . filesystem_identifier = filesystem_identifier self . path = ( path ,) self . mount_path = mount_path self . mount_alias = mount_alias self . message = \"Path %s not in mount for mounted filesystem identifier: %s , \\ Mount path: %s , Mount alias: %s \" super () . __init__ ( self . message , self . path , self . filesystem_identifier , self . mount_path , self . mount_alias , ) Attributes filesystem_identifier instance-attribute filesystem_identifier = filesystem_identifier path instance-attribute path = ( path ) mount_path instance-attribute mount_path = mount_path mount_alias instance-attribute mount_alias = mount_alias message instance-attribute message = \"Path %s not in mount for mounted filesystem identifier: %s , Mount path: %s , Mount alias: %s \" Functions MountedFilesystem Bases: LocalFilesystem Handler for mounted filesystem. Modifies the LocalFilesystem to implements checks for mount path modifications. Container and container orchestration tools often allow the ability to provide an alias for a mounted directory. This handler accounts for the mount base and verifies that the file is within the path. Attributes identifier class-attribute identifier : str = 'mounted' mount_path class-attribute mount_path : str mount_alias class-attribute mount_alias : str mount_type class-attribute mount_type : _HostMountLiteral = 'DirectoryOrCreate' Functions validate_mount_path validate_mount_path ( v , values ) Source code in lume_services/services/files/filesystems/mounted.py 55 56 57 58 59 60 61 62 @validator ( \"mount_path\" , pre = True ) def validate_mount_path ( cls , v , values ): mount_type = values . get ( \"mount_type\" ) if mount_type == \"DirectoryOrCreate\" : os . mkdir ( v ) return v dir_exists dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists on the mounted filesystem. Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/mounted.py 64 65 66 67 68 69 70 71 72 73 74 75 76 def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists on the mounted filesystem. Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" dir = self . _check_mounted_path ( dir ) return super () . dir_exists ( dir , create_dir = create_dir ) file_exists file_exists ( filepath : str ) -> bool Check that a file exists on the mounted filesystem. Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/mounted.py 78 79 80 81 82 83 84 85 86 87 88 89 90 def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists on the mounted filesystem. Args: filepath (str): Path to file Returns: bool \"\"\" filepath = self . _check_mounted_path ( filepath ) return super () . file_exists ( filepath ) create_dir create_dir ( dir : str ) -> None Create a directory on the mounted filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/mounted.py 92 93 94 95 96 97 98 99 100 def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the mounted filesystem. Args: dir (str): Directory path to create \"\"\" dir = self . _check_mounted_path ( dir ) super () . create_dir ( dir ) read read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the mounted filesystem. Parameters: Name Type Description Default filepath str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/filesystems/mounted.py 102 103 104 105 106 107 108 109 110 111 112 def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the mounted filesystem. Args: filepath (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" filepath = self . _check_mounted_path ( filepath ) return super () . read ( filepath , serializer ) write write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the mounted filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/mounted.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the mounted filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" filepath = self . _check_mounted_path ( filepath ) super () . write ( filepath , object , serializer , create_dir = create_dir )","title":"Filesystems"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem","text":"","title":"filesystem"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem-classes","text":"","title":"Classes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem","text":"Bases: ABC , BaseModel","title":"Filesystem"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem-attributes","text":"","title":"Attributes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.identifier","text":"identifier : str","title":"identifier"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem-functions","text":"","title":"Functions"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.dir_exists","text":"dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/filesystem.py 10 11 12 13 14 15 16 17 18 19 20 21 @abstractmethod def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" ...","title":"dir_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.file_exists","text":"file_exists ( filepath : str ) -> bool Check that a file exists Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/filesystem.py 23 24 25 26 27 28 29 30 31 32 33 34 @abstractmethod def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists Args: filepath (str): Path to file Returns: bool \"\"\" ...","title":"file_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.create_dir","text":"create_dir ( dir : str ) -> None Create a directory on the filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/filesystem.py 36 37 38 39 40 41 42 43 44 @abstractmethod def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the filesystem. Args: dir (str): Directory path to create \"\"\" ...","title":"create_dir()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.read","text":"read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the filesystem. Parameters: Name Type Description Default filepath str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/filesystems/filesystem.py 46 47 48 49 50 51 52 53 54 55 56 @abstractmethod def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the filesystem. Args: filepath (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" ...","title":"read()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.filesystem.Filesystem.write","text":"write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/filesystem.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @abstractmethod def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" ...","title":"write()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local","text":"","title":"local"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local-classes","text":"","title":"Classes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem","text":"Bases: Filesystem Handler for local filesystem.","title":"LocalFilesystem"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem-attributes","text":"","title":"Attributes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.identifier","text":"identifier : str = 'local'","title":"identifier"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem-functions","text":"","title":"Functions"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.dir_exists","text":"dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists on the local filesystem. Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/local.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists on the local filesystem. Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" # use absolute path path = os . path . abspath ( dir ) if os . path . isdir ( path ): logger . info ( \"Found directory %s on local filesystem.\" , path ) return True # if creating... if create_dir : self . create_dir ( path ) return True else : logger . info ( \"Unable to find directory %s on local filesystem.\" , path ) return False","title":"dir_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.file_exists","text":"file_exists ( filepath : str ) -> bool Check that a file exists on the local filesystem. Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/local.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists on the local filesystem. Args: filepath (str): Path to file Returns: bool \"\"\" path = os . path . abspath ( filepath ) if os . path . isfile ( path ): logger . info ( \"Found file %s on local filesystem.\" , path ) return True else : logger . info ( \"Unable to find file %s on local filesystem.\" , path ) return False","title":"file_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.create_dir","text":"create_dir ( dir : str ) -> None Create a directory on the local filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/local.py 60 61 62 63 64 65 66 67 68 69 70 71 def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the local filesystem. Args: dir (str): Directory path to create \"\"\" try : os . makedirs ( dir , exist_ok = False ) except Exception as e : logger . error ( \"Unable to create directory %s on local filesystem.\" , dir ) raise e","title":"create_dir()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.read","text":"read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the local filesystem. Parameters: Name Type Description Default filepath str Path of file to read. required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class. required Source code in lume_services/services/files/filesystems/local.py 73 74 75 76 77 78 79 80 81 82 83 84 def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the local filesystem. Args: filepath (str): Path of file to read. serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class. \"\"\" path = os . path . abspath ( filepath ) content = serializer . deserialize ( path ) return content","title":"read()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.local.LocalFilesystem.write","text":"write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the local filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/local.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the local filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" path = os . path . abspath ( filepath ) dir = os . path . dirname ( path ) if create_dir and not self . dir_exists ( dir ): self . create_dir ( dir ) serializer . serialize ( path , object )","title":"write()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted","text":"","title":"mounted"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted-classes","text":"","title":"Classes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount","text":"PathNotInMount ( filesystem_identifier : str , path : str , mount_path : str , mount_alias : str , ) Bases: Exception Source code in lume_services/services/files/filesystems/mounted.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def __init__ ( self , filesystem_identifier : str , path : str , mount_path : str , mount_alias : str ): self . filesystem_identifier = filesystem_identifier self . path = ( path ,) self . mount_path = mount_path self . mount_alias = mount_alias self . message = \"Path %s not in mount for mounted filesystem identifier: %s , \\ Mount path: %s , Mount alias: %s \" super () . __init__ ( self . message , self . path , self . filesystem_identifier , self . mount_path , self . mount_alias , )","title":"PathNotInMount"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount-attributes","text":"","title":"Attributes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount.filesystem_identifier","text":"filesystem_identifier = filesystem_identifier","title":"filesystem_identifier"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount.path","text":"path = ( path )","title":"path"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount.mount_path","text":"mount_path = mount_path","title":"mount_path"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount.mount_alias","text":"mount_alias = mount_alias","title":"mount_alias"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount.message","text":"message = \"Path %s not in mount for mounted filesystem identifier: %s , Mount path: %s , Mount alias: %s \"","title":"message"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.PathNotInMount-functions","text":"","title":"Functions"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem","text":"Bases: LocalFilesystem Handler for mounted filesystem. Modifies the LocalFilesystem to implements checks for mount path modifications. Container and container orchestration tools often allow the ability to provide an alias for a mounted directory. This handler accounts for the mount base and verifies that the file is within the path.","title":"MountedFilesystem"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem-attributes","text":"","title":"Attributes"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.identifier","text":"identifier : str = 'mounted'","title":"identifier"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.mount_path","text":"mount_path : str","title":"mount_path"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.mount_alias","text":"mount_alias : str","title":"mount_alias"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.mount_type","text":"mount_type : _HostMountLiteral = 'DirectoryOrCreate'","title":"mount_type"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem-functions","text":"","title":"Functions"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.validate_mount_path","text":"validate_mount_path ( v , values ) Source code in lume_services/services/files/filesystems/mounted.py 55 56 57 58 59 60 61 62 @validator ( \"mount_path\" , pre = True ) def validate_mount_path ( cls , v , values ): mount_type = values . get ( \"mount_type\" ) if mount_type == \"DirectoryOrCreate\" : os . mkdir ( v ) return v","title":"validate_mount_path()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.dir_exists","text":"dir_exists ( dir : str , create_dir : bool = False ) -> bool Check that a directory exists on the mounted filesystem. Parameters: Name Type Description Default dir str Path of directory required create_dir bool Whether to create directory if it does not exist False Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/mounted.py 64 65 66 67 68 69 70 71 72 73 74 75 76 def dir_exists ( self , dir : str , create_dir : bool = False ) -> bool : \"\"\"Check that a directory exists on the mounted filesystem. Args: dir (str): Path of directory create_dir (bool): Whether to create directory if it does not exist Returns: bool \"\"\" dir = self . _check_mounted_path ( dir ) return super () . dir_exists ( dir , create_dir = create_dir )","title":"dir_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.file_exists","text":"file_exists ( filepath : str ) -> bool Check that a file exists on the mounted filesystem. Parameters: Name Type Description Default filepath str Path to file required Returns: Type Description bool bool Source code in lume_services/services/files/filesystems/mounted.py 78 79 80 81 82 83 84 85 86 87 88 89 90 def file_exists ( self , filepath : str ) -> bool : \"\"\"Check that a file exists on the mounted filesystem. Args: filepath (str): Path to file Returns: bool \"\"\" filepath = self . _check_mounted_path ( filepath ) return super () . file_exists ( filepath )","title":"file_exists()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.create_dir","text":"create_dir ( dir : str ) -> None Create a directory on the mounted filesystem. Parameters: Name Type Description Default dir str Directory path to create required Source code in lume_services/services/files/filesystems/mounted.py 92 93 94 95 96 97 98 99 100 def create_dir ( self , dir : str ) -> None : \"\"\"Create a directory on the mounted filesystem. Args: dir (str): Directory path to create \"\"\" dir = self . _check_mounted_path ( dir ) super () . create_dir ( dir )","title":"create_dir()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.read","text":"read ( filepath : str , serializer : SerializerBase ) -> Any Read file from the mounted filesystem. Parameters: Name Type Description Default filepath str Path of file to read required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required Source code in lume_services/services/files/filesystems/mounted.py 102 103 104 105 106 107 108 109 110 111 112 def read ( self , filepath : str , serializer : SerializerBase ) -> Any : \"\"\"Read file from the mounted filesystem. Args: filepath (str): Path of file to read serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class \"\"\" filepath = self . _check_mounted_path ( filepath ) return super () . read ( filepath , serializer )","title":"read()"},{"location":"api/services/files/filesystems/#lume_services.services.files.filesystems.mounted.MountedFilesystem.write","text":"write ( filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None Write a file to the mounted filesystem. Parameters: Name Type Description Default filepath str required object Any Object to serialize required serializer SerializerBase Implementation of lume-base SerializerBase abstract base class required create_dir bool Whether to create directory in case not implemented False Source code in lume_services/services/files/filesystems/mounted.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def write ( self , filepath : str , object : Any , serializer : SerializerBase , create_dir : bool = False , ) -> None : \"\"\"Write a file to the mounted filesystem. Args: filepath (str): object (Any): Object to serialize serializer (SerializerBase): Implementation of lume-base SerializerBase abstract base class create_dir (bool): Whether to create directory in case not implemented \"\"\" filepath = self . _check_mounted_path ( filepath ) super () . write ( filepath , object , serializer , create_dir = create_dir )","title":"write()"},{"location":"api/services/models/db/","text":"lume_services.services.models.db.db Classes ModelDBConfig Bases: BaseModel ModelDB ModelDB ( db_config : ModelDBConfig ) Bases: ABC Source code in lume_services/services/models/db/db.py 17 18 19 @abstractmethod def __init__ ( self , db_config : ModelDBConfig ): ... Functions execute abstractmethod execute ( statement : Executable ) Generic execution method for statements. Parameters: Name Type Description Default statement(Executable) An executable statement (select, insert...) required Source code in lume_services/services/models/db/db.py 21 22 23 24 25 26 27 28 @abstractmethod def execute ( self , statement : Executable ): \"\"\"Generic execution method for statements. Args: statement(Executable): An executable statement (select, insert...) \"\"\" ... select abstractmethod select ( statement : Select ) Method for executing selection statements. Parameters: Name Type Description Default statement Select Executable selection statement. required Source code in lume_services/services/models/db/db.py 30 31 32 33 34 35 36 37 38 @abstractmethod def select ( self , statement : Select ): \"\"\"Method for executing selection statements. Args: statement (Select): Executable selection statement. \"\"\" ... insert abstractmethod insert ( statement : Insert ) Method for executing insert statements. Parameters: Name Type Description Default statement Insert Executable insert statement. required Source code in lume_services/services/models/db/db.py 40 41 42 43 44 45 46 47 48 @abstractmethod def insert ( self , statement : Insert ): \"\"\"Method for executing insert statements. Args: statement (Insert): Executable insert statement. \"\"\" ... insert_many abstractmethod insert_many ( table_row_obj : List [ Insert ]) Method accepting list of Insert statements. This is distinguished from the base insert method because many services will use context managment for the management of their sessions. Parameters: Name Type Description Default List[Insert] List of executable insert statements. required Source code in lume_services/services/models/db/db.py 50 51 52 53 54 55 56 57 58 59 60 @abstractmethod def insert_many ( self , table_row_obj : List [ Insert ]): \"\"\"Method accepting list of Insert statements. This is distinguished from the base insert method because many services will use context managment for the management of their sessions. Args: List[Insert]: List of executable insert statements. \"\"\" ... from_config_init from_config_init ( * args , ** kwargs ) Convenience function for initializing config and db. Source code in lume_services/services/models/db/db.py 62 63 64 @abstractclassmethod def from_config_init ( cls , * args , ** kwargs ): \"\"\"Convenience function for initializing config and db.\"\"\" lume_services.services.models.db.mysql Classes ConnectionConfig Bases: BaseModel Configuration for creating sqlalchemy engine. Parameters: Name Type Description Default pool_size int Number of connections to maintain in the connection pool. Establishing connections is expensive and maintaining multiple connections in a pool allows for availability. required pool_pre_ping bool required Attributes pool_size class-attribute pool_size : Optional [ int ] pool_pre_ping class-attribute pool_pre_ping : bool = True MySQLModelDBConfig Bases: ModelDBConfig Configuration for MySQL connection. Parameters: Name Type Description Default host str required port str required user str required password SecretStr required database str required connection ConnectionConfig Configuration options for creating sqlalchemy engine. required Attributes host class-attribute host : str port class-attribute port : int user class-attribute user : str password class-attribute password : SecretStr = Field ( exclude = True ) database class-attribute database : str connection class-attribute connection : ConnectionConfig = ConnectionConfig () MySQLModelDB MySQLModelDB ( config : MySQLModelDBConfig ) Bases: ModelDB MySQL implementation of the DBService client, allowing for Model DB connections to MySQL model db. Initialize MySQL client service. Parameters: Name Type Description Default config MySQLModelDBConfig MySQL connection config required Source code in lume_services/services/models/db/mysql.py 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , config : MySQLModelDBConfig ): \"\"\"Initialize MySQL client service. Args: config (MySQLModelDBConfig): MySQL connection config \"\"\" self . config = config self . _create_engine () Attributes config instance-attribute config = config Functions connection connection () -> Connection Context manager for operations. Will clean up connections on exit of scope. Source code in lume_services/services/models/db/mysql.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @contextmanager def connection ( self ) -> Connection : \"\"\"Context manager for operations. Will clean up connections on exit of scope. \"\"\" self . _check_mp () # get connection cxn = self . _connection . get () if cxn is None : cxn = self . _connect () cleanup = True else : cleanup = False try : yield cxn finally : if cleanup : cxn = self . _connection . get () if cxn : cxn . close () self . _connection . set ( None ) session session () -> Session Establishes Session with active connection. Note: Setting expire_on_commit to False allows us to access objects after session closing. Source code in lume_services/services/models/db/mysql.py 145 146 147 148 149 150 151 152 153 154 155 156 157 def session ( self ) -> Session : \"\"\"Establishes Session with active connection. Note: Setting expire_on_commit to False allows us to access objects after session closing. \"\"\" logger . debug ( \"MySQLModelDB creating session.\" ) with self . connection (): session = self . _sessionmaker () logger . debug ( \"MySQLModelDB session created.\" ) session . expire_on_commit = False return session execute execute ( sql ) -> list Execute sql inside a managed session. Parameters: Name Type Description Default sql Execute a query required Results list: Results of query operation Source code in lume_services/services/models/db/mysql.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def execute ( self , sql ) -> list : \"\"\"Execute sql inside a managed session. Args: sql: Execute a query Results: list: Results of query operation \"\"\" logger . info ( \"MySQLModelDB executing: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) session . commit () logger . info ( \"MySQLModelDB executed: %s \" , str ( sql )) return res select select ( sql : Select ) -> list Execute sql query inside a managed session. Parameters: Name Type Description Default sql Select Execute a selection query required Results list: Results of selection operation Source code in lume_services/services/models/db/mysql.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def select ( self , sql : Select ) -> list : \"\"\"Execute sql query inside a managed session. Args: sql: Execute a selection query Results: list: Results of selection operation \"\"\" logger . info ( \"MySQLModelDB selecting: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) . scalars () . all () session . commit () return res insert insert ( sql : Insert ) Execute and insert operation inside a managed session. Parameters: Name Type Description Default sql Insert Sqlalchemy insert operation required Returns: Type Description Union[str, int]: primary key returned from insert operation Source code in lume_services/services/models/db/mysql.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def insert ( self , sql : Insert ): \"\"\"Execute and insert operation inside a managed session. Args: sql (Insert): Sqlalchemy insert operation Returns: Union[str, int]: primary key returned from insert operation \"\"\" logger . info ( \"MySQLModelDB inserting: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) session . commit () logger . info ( \"Sucessfully executed: %s \" , str ( sql )) return res . inserted_primary_key insert_many insert_many ( sql : List [ Insert ]) -> List [ Union [ str , int ]] Execute many inserts within a managed session. Parameters: Name Type Description Default sql List [ Insert ] Execute a sqlalchemy insert operation required Returns: Type Description List [ Union [ str , int ]] List[Union[str, int]]: List of primary keys returned from insert operation Source code in lume_services/services/models/db/mysql.py 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def insert_many ( self , sql : List [ Insert ]) -> List [ Union [ str , int ]]: \"\"\"Execute many inserts within a managed session. Args: sql (List[Insert]): Execute a sqlalchemy insert operation Returns: List[Union[str, int]]: List of primary keys returned from insert operation \"\"\" logger . info ( \"MySQLModelDB inserting many: %s \" , [ str ( statement ) for statement in sql ] ) with self . session () as session : results = [] for stmt in sql : res = session . execute ( stmt ) results . append ( res ) session . commit () logger . info ( \"Sucessfully executed: %s \" , [ str ( statement ) for statement in sql ]) return [ res . inserted_primary_key for res in results ] from_config_init classmethod from_config_init ( ** kwargs ) Initialize database handler from MySQLModelDBConfig kwargs. Source code in lume_services/services/models/db/mysql.py 244 245 246 247 248 @classmethod def from_config_init ( cls , ** kwargs ): \"\"\"Initialize database handler from MySQLModelDBConfig kwargs.\"\"\" config = MySQLModelDBConfig ( ** kwargs ) return cls ( config = config ) lume_services.services.models.db.schema Attributes Base module-attribute Base = declarative_base () Classes Model Bases: Base Attributes model_id class-attribute model_id = Column ( \"model_id\" , Integer , primary_key = True , autoincrement = True , ) created class-attribute created = Column ( \"created\" , DateTime ( timezone = True ), server_default = func . now (), ) author class-attribute author = Column ( 'author' , String ( 255 ), nullable = False ) laboratory class-attribute laboratory = Column ( \"laboratory\" , String ( 255 ), nullable = False ) facility class-attribute facility = Column ( 'facility' , String ( 255 ), nullable = False ) beampath class-attribute beampath = Column ( 'beampath' , String ( 255 ), nullable = False ) description class-attribute description = Column ( \"description\" , String ( 255 ), nullable = False ) deployment class-attribute deployment = relationship ( 'Deployment' , backref = 'model' ) Deployment Bases: Base Attributes deployment_id class-attribute deployment_id = Column ( \"deployment_id\" , Integer , primary_key = True , autoincrement = True , ) version class-attribute version = Column ( 'version' , String ( 255 ), nullable = False ) deploy_date class-attribute deploy_date = Column ( \"deploy_date\" , DateTime ( timezone = True ), server_default = func . now (), ) asset_dir class-attribute asset_dir = Column ( 'asset_dir' , String ( 255 ), nullable = True ) source class-attribute source = Column ( 'source' , String ( 255 ), nullable = True ) sha_256 class-attribute sha_256 = Column ( 'sha256' , String ( 255 ), nullable = False ) image class-attribute image = Column ( 'image' , String ( 255 ), nullable = True ) is_live class-attribute is_live = Column ( 'is_live' , Boolean , nullable = False ) model_id class-attribute model_id = Column ( \"model_id\" , ForeignKey ( \"model.model_id\" ), nullable = False , onupdate = \"cascade\" , ) flow class-attribute flow = relationship ( 'Flow' , backref = 'deployment' ) Project Bases: Base Attributes project_name class-attribute project_name = Column ( \"project_name\" , String ( 255 ), primary_key = True ) description class-attribute description = Column ( \"description\" , String ( 255 ), nullable = False ) flows class-attribute flows = relationship ( 'Flow' , backref = 'project' ) Flow Bases: Base Attributes flow_id class-attribute flow_id = Column ( \"flow_id\" , String ( 255 ), primary_key = True , nullable = False ) flow_name class-attribute flow_name = Column ( \"flow_name\" , String ( 255 ), nullable = False ) project_name class-attribute project_name = Column ( \"project_name\" , ForeignKey ( \"project.project_name\" ), nullable = False , onupdate = \"cascade\" , ) deployment_id class-attribute deployment_id = Column ( \"deployment_id\" , ForeignKey ( \"deployment.deployment_id\" ), nullable = False , onupdate = \"cascade\" , ) FlowOfFlows Bases: Base Attributes id class-attribute id = Column ( \"_id\" , Integer , primary_key = True , autoincrement = True ) parent_flow_id class-attribute parent_flow_id = Column ( \"parent_flow_id\" , ForeignKey ( \"flow.flow_id\" ), nullable = False , onupdate = \"cascade\" , ) flow_id class-attribute flow_id = Column ( \"flow_id\" , ForeignKey ( \"flow.flow_id\" ), nullable = False , onupdate = \"cascade\" , ) position class-attribute position = Column ( 'position' , Integer , nullable = False ) parent class-attribute parent = relationship ( \"Flow\" , foreign_keys = \"FlowOfFlows.parent_flow_id\" , backref = \"composing_flows\" , lazy = \"joined\" , ) flow class-attribute flow = relationship ( \"Flow\" , foreign_keys = \"FlowOfFlows.flow_id\" , lazy = \"joined\" , )","title":"Database"},{"location":"api/services/models/db/#lume_services.services.models.db.db","text":"","title":"db"},{"location":"api/services/models/db/#lume_services.services.models.db.db-classes","text":"","title":"Classes"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDBConfig","text":"Bases: BaseModel","title":"ModelDBConfig"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB","text":"ModelDB ( db_config : ModelDBConfig ) Bases: ABC Source code in lume_services/services/models/db/db.py 17 18 19 @abstractmethod def __init__ ( self , db_config : ModelDBConfig ): ...","title":"ModelDB"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB-functions","text":"","title":"Functions"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB.execute","text":"execute ( statement : Executable ) Generic execution method for statements. Parameters: Name Type Description Default statement(Executable) An executable statement (select, insert...) required Source code in lume_services/services/models/db/db.py 21 22 23 24 25 26 27 28 @abstractmethod def execute ( self , statement : Executable ): \"\"\"Generic execution method for statements. Args: statement(Executable): An executable statement (select, insert...) \"\"\" ...","title":"execute()"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB.select","text":"select ( statement : Select ) Method for executing selection statements. Parameters: Name Type Description Default statement Select Executable selection statement. required Source code in lume_services/services/models/db/db.py 30 31 32 33 34 35 36 37 38 @abstractmethod def select ( self , statement : Select ): \"\"\"Method for executing selection statements. Args: statement (Select): Executable selection statement. \"\"\" ...","title":"select()"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB.insert","text":"insert ( statement : Insert ) Method for executing insert statements. Parameters: Name Type Description Default statement Insert Executable insert statement. required Source code in lume_services/services/models/db/db.py 40 41 42 43 44 45 46 47 48 @abstractmethod def insert ( self , statement : Insert ): \"\"\"Method for executing insert statements. Args: statement (Insert): Executable insert statement. \"\"\" ...","title":"insert()"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB.insert_many","text":"insert_many ( table_row_obj : List [ Insert ]) Method accepting list of Insert statements. This is distinguished from the base insert method because many services will use context managment for the management of their sessions. Parameters: Name Type Description Default List[Insert] List of executable insert statements. required Source code in lume_services/services/models/db/db.py 50 51 52 53 54 55 56 57 58 59 60 @abstractmethod def insert_many ( self , table_row_obj : List [ Insert ]): \"\"\"Method accepting list of Insert statements. This is distinguished from the base insert method because many services will use context managment for the management of their sessions. Args: List[Insert]: List of executable insert statements. \"\"\" ...","title":"insert_many()"},{"location":"api/services/models/db/#lume_services.services.models.db.db.ModelDB.from_config_init","text":"from_config_init ( * args , ** kwargs ) Convenience function for initializing config and db. Source code in lume_services/services/models/db/db.py 62 63 64 @abstractclassmethod def from_config_init ( cls , * args , ** kwargs ): \"\"\"Convenience function for initializing config and db.\"\"\"","title":"from_config_init()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql","text":"","title":"mysql"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql-classes","text":"","title":"Classes"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.ConnectionConfig","text":"Bases: BaseModel Configuration for creating sqlalchemy engine. Parameters: Name Type Description Default pool_size int Number of connections to maintain in the connection pool. Establishing connections is expensive and maintaining multiple connections in a pool allows for availability. required pool_pre_ping bool required","title":"ConnectionConfig"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.ConnectionConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.ConnectionConfig.pool_size","text":"pool_size : Optional [ int ]","title":"pool_size"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.ConnectionConfig.pool_pre_ping","text":"pool_pre_ping : bool = True","title":"pool_pre_ping"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig","text":"Bases: ModelDBConfig Configuration for MySQL connection. Parameters: Name Type Description Default host str required port str required user str required password SecretStr required database str required connection ConnectionConfig Configuration options for creating sqlalchemy engine. required","title":"MySQLModelDBConfig"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.host","text":"host : str","title":"host"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.port","text":"port : int","title":"port"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.user","text":"user : str","title":"user"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.password","text":"password : SecretStr = Field ( exclude = True )","title":"password"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.database","text":"database : str","title":"database"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDBConfig.connection","text":"connection : ConnectionConfig = ConnectionConfig ()","title":"connection"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB","text":"MySQLModelDB ( config : MySQLModelDBConfig ) Bases: ModelDB MySQL implementation of the DBService client, allowing for Model DB connections to MySQL model db. Initialize MySQL client service. Parameters: Name Type Description Default config MySQLModelDBConfig MySQL connection config required Source code in lume_services/services/models/db/mysql.py 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , config : MySQLModelDBConfig ): \"\"\"Initialize MySQL client service. Args: config (MySQLModelDBConfig): MySQL connection config \"\"\" self . config = config self . _create_engine ()","title":"MySQLModelDB"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.config","text":"config = config","title":"config"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB-functions","text":"","title":"Functions"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.connection","text":"connection () -> Connection Context manager for operations. Will clean up connections on exit of scope. Source code in lume_services/services/models/db/mysql.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @contextmanager def connection ( self ) -> Connection : \"\"\"Context manager for operations. Will clean up connections on exit of scope. \"\"\" self . _check_mp () # get connection cxn = self . _connection . get () if cxn is None : cxn = self . _connect () cleanup = True else : cleanup = False try : yield cxn finally : if cleanup : cxn = self . _connection . get () if cxn : cxn . close () self . _connection . set ( None )","title":"connection()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.session","text":"session () -> Session Establishes Session with active connection. Note: Setting expire_on_commit to False allows us to access objects after session closing. Source code in lume_services/services/models/db/mysql.py 145 146 147 148 149 150 151 152 153 154 155 156 157 def session ( self ) -> Session : \"\"\"Establishes Session with active connection. Note: Setting expire_on_commit to False allows us to access objects after session closing. \"\"\" logger . debug ( \"MySQLModelDB creating session.\" ) with self . connection (): session = self . _sessionmaker () logger . debug ( \"MySQLModelDB session created.\" ) session . expire_on_commit = False return session","title":"session()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.execute","text":"execute ( sql ) -> list Execute sql inside a managed session. Parameters: Name Type Description Default sql Execute a query required Results list: Results of query operation Source code in lume_services/services/models/db/mysql.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def execute ( self , sql ) -> list : \"\"\"Execute sql inside a managed session. Args: sql: Execute a query Results: list: Results of query operation \"\"\" logger . info ( \"MySQLModelDB executing: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) session . commit () logger . info ( \"MySQLModelDB executed: %s \" , str ( sql )) return res","title":"execute()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.select","text":"select ( sql : Select ) -> list Execute sql query inside a managed session. Parameters: Name Type Description Default sql Select Execute a selection query required Results list: Results of selection operation Source code in lume_services/services/models/db/mysql.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def select ( self , sql : Select ) -> list : \"\"\"Execute sql query inside a managed session. Args: sql: Execute a selection query Results: list: Results of selection operation \"\"\" logger . info ( \"MySQLModelDB selecting: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) . scalars () . all () session . commit () return res","title":"select()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.insert","text":"insert ( sql : Insert ) Execute and insert operation inside a managed session. Parameters: Name Type Description Default sql Insert Sqlalchemy insert operation required Returns: Type Description Union[str, int]: primary key returned from insert operation Source code in lume_services/services/models/db/mysql.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def insert ( self , sql : Insert ): \"\"\"Execute and insert operation inside a managed session. Args: sql (Insert): Sqlalchemy insert operation Returns: Union[str, int]: primary key returned from insert operation \"\"\" logger . info ( \"MySQLModelDB inserting: %s \" , str ( sql )) with self . session () as session : res = session . execute ( sql ) session . commit () logger . info ( \"Sucessfully executed: %s \" , str ( sql )) return res . inserted_primary_key","title":"insert()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.insert_many","text":"insert_many ( sql : List [ Insert ]) -> List [ Union [ str , int ]] Execute many inserts within a managed session. Parameters: Name Type Description Default sql List [ Insert ] Execute a sqlalchemy insert operation required Returns: Type Description List [ Union [ str , int ]] List[Union[str, int]]: List of primary keys returned from insert operation Source code in lume_services/services/models/db/mysql.py 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def insert_many ( self , sql : List [ Insert ]) -> List [ Union [ str , int ]]: \"\"\"Execute many inserts within a managed session. Args: sql (List[Insert]): Execute a sqlalchemy insert operation Returns: List[Union[str, int]]: List of primary keys returned from insert operation \"\"\" logger . info ( \"MySQLModelDB inserting many: %s \" , [ str ( statement ) for statement in sql ] ) with self . session () as session : results = [] for stmt in sql : res = session . execute ( stmt ) results . append ( res ) session . commit () logger . info ( \"Sucessfully executed: %s \" , [ str ( statement ) for statement in sql ]) return [ res . inserted_primary_key for res in results ]","title":"insert_many()"},{"location":"api/services/models/db/#lume_services.services.models.db.mysql.MySQLModelDB.from_config_init","text":"from_config_init ( ** kwargs ) Initialize database handler from MySQLModelDBConfig kwargs. Source code in lume_services/services/models/db/mysql.py 244 245 246 247 248 @classmethod def from_config_init ( cls , ** kwargs ): \"\"\"Initialize database handler from MySQLModelDBConfig kwargs.\"\"\" config = MySQLModelDBConfig ( ** kwargs ) return cls ( config = config )","title":"from_config_init()"},{"location":"api/services/models/db/#lume_services.services.models.db.schema","text":"","title":"schema"},{"location":"api/services/models/db/#lume_services.services.models.db.schema-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Base","text":"Base = declarative_base ()","title":"Base"},{"location":"api/services/models/db/#lume_services.services.models.db.schema-classes","text":"","title":"Classes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model","text":"Bases: Base","title":"Model"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.model_id","text":"model_id = Column ( \"model_id\" , Integer , primary_key = True , autoincrement = True , )","title":"model_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.created","text":"created = Column ( \"created\" , DateTime ( timezone = True ), server_default = func . now (), )","title":"created"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.author","text":"author = Column ( 'author' , String ( 255 ), nullable = False )","title":"author"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.laboratory","text":"laboratory = Column ( \"laboratory\" , String ( 255 ), nullable = False )","title":"laboratory"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.facility","text":"facility = Column ( 'facility' , String ( 255 ), nullable = False )","title":"facility"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.beampath","text":"beampath = Column ( 'beampath' , String ( 255 ), nullable = False )","title":"beampath"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.description","text":"description = Column ( \"description\" , String ( 255 ), nullable = False )","title":"description"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Model.deployment","text":"deployment = relationship ( 'Deployment' , backref = 'model' )","title":"deployment"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment","text":"Bases: Base","title":"Deployment"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.deployment_id","text":"deployment_id = Column ( \"deployment_id\" , Integer , primary_key = True , autoincrement = True , )","title":"deployment_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.version","text":"version = Column ( 'version' , String ( 255 ), nullable = False )","title":"version"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.deploy_date","text":"deploy_date = Column ( \"deploy_date\" , DateTime ( timezone = True ), server_default = func . now (), )","title":"deploy_date"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.asset_dir","text":"asset_dir = Column ( 'asset_dir' , String ( 255 ), nullable = True )","title":"asset_dir"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.source","text":"source = Column ( 'source' , String ( 255 ), nullable = True )","title":"source"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.sha_256","text":"sha_256 = Column ( 'sha256' , String ( 255 ), nullable = False )","title":"sha_256"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.image","text":"image = Column ( 'image' , String ( 255 ), nullable = True )","title":"image"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.is_live","text":"is_live = Column ( 'is_live' , Boolean , nullable = False )","title":"is_live"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.model_id","text":"model_id = Column ( \"model_id\" , ForeignKey ( \"model.model_id\" ), nullable = False , onupdate = \"cascade\" , )","title":"model_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Deployment.flow","text":"flow = relationship ( 'Flow' , backref = 'deployment' )","title":"flow"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Project","text":"Bases: Base","title":"Project"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Project-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Project.project_name","text":"project_name = Column ( \"project_name\" , String ( 255 ), primary_key = True )","title":"project_name"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Project.description","text":"description = Column ( \"description\" , String ( 255 ), nullable = False )","title":"description"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Project.flows","text":"flows = relationship ( 'Flow' , backref = 'project' )","title":"flows"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow","text":"Bases: Base","title":"Flow"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow.flow_id","text":"flow_id = Column ( \"flow_id\" , String ( 255 ), primary_key = True , nullable = False )","title":"flow_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow.flow_name","text":"flow_name = Column ( \"flow_name\" , String ( 255 ), nullable = False )","title":"flow_name"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow.project_name","text":"project_name = Column ( \"project_name\" , ForeignKey ( \"project.project_name\" ), nullable = False , onupdate = \"cascade\" , )","title":"project_name"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.Flow.deployment_id","text":"deployment_id = Column ( \"deployment_id\" , ForeignKey ( \"deployment.deployment_id\" ), nullable = False , onupdate = \"cascade\" , )","title":"deployment_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows","text":"Bases: Base","title":"FlowOfFlows"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows-attributes","text":"","title":"Attributes"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.id","text":"id = Column ( \"_id\" , Integer , primary_key = True , autoincrement = True )","title":"id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.parent_flow_id","text":"parent_flow_id = Column ( \"parent_flow_id\" , ForeignKey ( \"flow.flow_id\" ), nullable = False , onupdate = \"cascade\" , )","title":"parent_flow_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.flow_id","text":"flow_id = Column ( \"flow_id\" , ForeignKey ( \"flow.flow_id\" ), nullable = False , onupdate = \"cascade\" , )","title":"flow_id"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.position","text":"position = Column ( 'position' , Integer , nullable = False )","title":"position"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.parent","text":"parent = relationship ( \"Flow\" , foreign_keys = \"FlowOfFlows.parent_flow_id\" , backref = \"composing_flows\" , lazy = \"joined\" , )","title":"parent"},{"location":"api/services/models/db/#lume_services.services.models.db.schema.FlowOfFlows.flow","text":"flow = relationship ( \"Flow\" , foreign_keys = \"FlowOfFlows.flow_id\" , lazy = \"joined\" , )","title":"flow"},{"location":"api/services/models/models/","text":"lume_services.services.models.service Attributes Classes ModelDBService ModelDBService ( model_db : ModelDB ) Source code in lume_services/services/models/service.py 28 29 30 def __init__ ( self , model_db : ModelDB ): self . _model_db = model_db self . _model_registry = {} Functions store_model store_model ( author : str , laboratory : str , facility : str , beampath : str , description : str , ) -> int Store a model. Returns: Name Type Description int int ID of inserted model Source code in lume_services/services/models/service.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @validate_kwargs_exist ( Model ) def store_model ( self , author : str , laboratory : str , facility : str , beampath : str , description : str , ) -> int : \"\"\"Store a model. Returns: int: ID of inserted model \"\"\" # store in db insert_stmt = insert ( Model ) . values ( author = author , laboratory = laboratory , facility = facility , beampath = beampath , description = description , ) result = self . _model_db . insert ( insert_stmt ) if len ( result ): return result [ 0 ] else : return None store_deployment store_deployment ( model_id : int , version : str , source : str , sha256 : str , image : str , is_live : bool = False , asset_dir = None , ) -> int Store a deployment. Parameters: Name Type Description Default model_id int Associated model id. required version str Version of model. required source str Source of deployment code. required sha256 str Hash of source required image str Container image to be used with this deployment. required is_live bool=False Whether deployment is live. False asset_dir str Directory for assets stored on filesystem. None Returns: Name Type Description int int ID of inserted deployment id Source code in lume_services/services/models/service.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def store_deployment ( self , model_id : int , version : str , source : str , sha256 : str , image : str , is_live : bool = False , asset_dir = None , ) -> int : \"\"\"Store a deployment. Args: model_id (int): Associated model id. version (str): Version of model. source (str): Source of deployment code. sha256 (str): Hash of source image (str): Container image to be used with this deployment. is_live (bool=False): Whether deployment is live. asset_dir (str): Directory for assets stored on filesystem. Returns: int: ID of inserted deployment id \"\"\" # store in db insert_stmt = insert ( Deployment ) . values ( model_id = model_id , version = version , source = source , sha256 = sha256 , image = image , is_live = is_live , asset_dir = asset_dir , ) result = self . _model_db . insert ( insert_stmt ) if len ( result ): return result [ 0 ] else : return None store_project store_project ( project_name : str , description : str ) -> str Store a project. Parameters: Name Type Description Default project_name str Name of project (as created in Prefect). required decription str Short description of project. required Returns: Name Type Description str str Inserted project name Source code in lume_services/services/models/service.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def store_project ( self , project_name : str , description : str ) -> str : \"\"\"Store a project. Args: project_name (str): Name of project (as created in Prefect). decription (str): Short description of project. Returns: str: Inserted project name \"\"\" insert_stmt = insert ( Project ) . values ( project_name = project_name , description = description ) # store in db result = self . _model_db . insert ( insert_stmt ) # Return inserted project name if len ( result ): return result [ 0 ] else : return None store_flow store_flow ( deployment_id : int , flow_id : str , flow_name : str , project_name : str , ) -> str Store a flow in the model database. Parameters: Name Type Description Default deployment_id int ID of deployment associated with the flow. required flow_id str ID of flow (generated by Prefect). required flow_name str Name of flow (same as used to register with Prefect). required project_name str Name of project (same as used to register with Prefect). required Returns: Name Type Description str str Inserted flow id Source code in lume_services/services/models/service.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def store_flow ( self , deployment_id : int , flow_id : str , flow_name : str , project_name : str ) -> str : \"\"\"Store a flow in the model database. Args: deployment_id (int): ID of deployment associated with the flow. flow_id (str): ID of flow (generated by Prefect). flow_name (str): Name of flow (same as used to register with Prefect). project_name (str): Name of project (same as used to register with Prefect). Returns: str: Inserted flow id \"\"\" insert_stmt = insert ( Flow ) . values ( flow_id = flow_id , deployment_id = deployment_id , flow_name = flow_name , project_name = project_name , ) results = self . _model_db . insert ( insert_stmt ) # flow_id is result of first insert if len ( results ): return results [ 0 ] else : return None get_model get_model ( ** kwargs ) -> Model Get a model from criteria Returns: Type Description Model Model Source code in lume_services/services/models/service.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @validate_kwargs_exist ( Model ) def get_model ( self , ** kwargs ) -> Model : \"\"\"Get a model from criteria Returns: Model \"\"\" # execute query query = select ( Model ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple models returned from query. get_model is returning the \\ first result with %s %s \" , \"model_id\" , result [ 0 ] . model_id , ) return result [ 0 ] else : raise ModelNotFoundError ( query ) get_deployment get_deployment ( ** kwargs ) -> Deployment Get a deployment based on criteria Returns: Type Description Deployment Deployment Source code in lume_services/services/models/service.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 @validate_kwargs_exist ( Deployment ) def get_deployment ( self , ** kwargs ) -> Deployment : \"\"\"Get a deployment based on criteria Returns: Deployment \"\"\" query = select ( Deployment ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple deployments returned from query. get_deployment is \\ returning the first result with %s %s \" , \"deployment_id\" , result [ 0 ] . deployment_id , ) return result [ 0 ] else : raise DeploymentNotFoundError ( query ) get_latest_deployment get_latest_deployment ( ** kwargs ) -> Deployment Get the latest deployment Returns: Type Description Deployment Deployment Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 @validate_kwargs_exist ( Deployment ) def get_latest_deployment ( self , ** kwargs ) -> Deployment : \"\"\"Get the latest deployment Returns: Deployment raises: ValueError: Passed kwarg not in Project schema \"\"\" query = ( select ( Deployment ) . filter_by ( ** kwargs ) . order_by ( desc ( Deployment . deploy_date )) ) result = self . _model_db . select ( query ) if len ( result ): return result [ 0 ] else : raise DeploymentNotFoundError ( query ) get_project get_project ( ** kwargs ) -> Project Get a single Project Returns: Type Description Project Project Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 @validate_kwargs_exist ( Project ) def get_project ( self , ** kwargs ) -> Project : \"\"\"Get a single Project Returns: Project raises: ValueError: Passed kwarg not in Project schema \"\"\" # execute query query = select ( Project ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple projects returned from query. get_project is returning \\ the first result with %s %s \" , \"name\" , result [ 0 ] . project_name , ) return result [ 0 ] else : raise ProjectNotFoundError ( query ) get_flow get_flow ( ** kwargs ) -> Flow Get a flow from criteria Returns: Name Type Description Flow Flow Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 @validate_kwargs_exist ( Flow ) def get_flow ( self , ** kwargs ) -> Flow : \"\"\"Get a flow from criteria Returns: Flow: raises: ValueError: Passed kwarg not in Project schema \"\"\" query = select ( Flow ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple flows returned from query. get_flow is returning the \\ first result with %s %s \" , \"flow_id\" , result [ 0 ] . flow_id , ) return result [ 0 ] else : raise FlowNotFoundError ( query ) get_flow_of_flows get_flow_of_flows ( ** kwargs ) -> Flow Get a flow from criteria Returns: Name Type Description FlowOfFlows Flow Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @validate_kwargs_exist ( FlowOfFlows ) def get_flow_of_flows ( self , ** kwargs ) -> Flow : \"\"\"Get a flow from criteria Returns: FlowOfFlows: raises: ValueError: Passed kwarg not in Project schema \"\"\" query = select ( FlowOfFlows ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): return [ res . flow for res in result ] else : raise FlowOfFlowsNotFoundError ( query ) apply_schema apply_schema () -> None Applies database schema to connected service. Source code in lume_services/services/models/service.py 319 320 321 322 def apply_schema ( self ) -> None : \"\"\"Applies database schema to connected service.\"\"\" Base . metadata . create_all ( self . _model_db . engine ) Functions","title":"Model Database Service"},{"location":"api/services/models/models/#lume_services.services.models.service","text":"","title":"service"},{"location":"api/services/models/models/#lume_services.services.models.service-attributes","text":"","title":"Attributes"},{"location":"api/services/models/models/#lume_services.services.models.service-classes","text":"","title":"Classes"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService","text":"ModelDBService ( model_db : ModelDB ) Source code in lume_services/services/models/service.py 28 29 30 def __init__ ( self , model_db : ModelDB ): self . _model_db = model_db self . _model_registry = {}","title":"ModelDBService"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService-functions","text":"","title":"Functions"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.store_model","text":"store_model ( author : str , laboratory : str , facility : str , beampath : str , description : str , ) -> int Store a model. Returns: Name Type Description int int ID of inserted model Source code in lume_services/services/models/service.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @validate_kwargs_exist ( Model ) def store_model ( self , author : str , laboratory : str , facility : str , beampath : str , description : str , ) -> int : \"\"\"Store a model. Returns: int: ID of inserted model \"\"\" # store in db insert_stmt = insert ( Model ) . values ( author = author , laboratory = laboratory , facility = facility , beampath = beampath , description = description , ) result = self . _model_db . insert ( insert_stmt ) if len ( result ): return result [ 0 ] else : return None","title":"store_model()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.store_deployment","text":"store_deployment ( model_id : int , version : str , source : str , sha256 : str , image : str , is_live : bool = False , asset_dir = None , ) -> int Store a deployment. Parameters: Name Type Description Default model_id int Associated model id. required version str Version of model. required source str Source of deployment code. required sha256 str Hash of source required image str Container image to be used with this deployment. required is_live bool=False Whether deployment is live. False asset_dir str Directory for assets stored on filesystem. None Returns: Name Type Description int int ID of inserted deployment id Source code in lume_services/services/models/service.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def store_deployment ( self , model_id : int , version : str , source : str , sha256 : str , image : str , is_live : bool = False , asset_dir = None , ) -> int : \"\"\"Store a deployment. Args: model_id (int): Associated model id. version (str): Version of model. source (str): Source of deployment code. sha256 (str): Hash of source image (str): Container image to be used with this deployment. is_live (bool=False): Whether deployment is live. asset_dir (str): Directory for assets stored on filesystem. Returns: int: ID of inserted deployment id \"\"\" # store in db insert_stmt = insert ( Deployment ) . values ( model_id = model_id , version = version , source = source , sha256 = sha256 , image = image , is_live = is_live , asset_dir = asset_dir , ) result = self . _model_db . insert ( insert_stmt ) if len ( result ): return result [ 0 ] else : return None","title":"store_deployment()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.store_project","text":"store_project ( project_name : str , description : str ) -> str Store a project. Parameters: Name Type Description Default project_name str Name of project (as created in Prefect). required decription str Short description of project. required Returns: Name Type Description str str Inserted project name Source code in lume_services/services/models/service.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def store_project ( self , project_name : str , description : str ) -> str : \"\"\"Store a project. Args: project_name (str): Name of project (as created in Prefect). decription (str): Short description of project. Returns: str: Inserted project name \"\"\" insert_stmt = insert ( Project ) . values ( project_name = project_name , description = description ) # store in db result = self . _model_db . insert ( insert_stmt ) # Return inserted project name if len ( result ): return result [ 0 ] else : return None","title":"store_project()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.store_flow","text":"store_flow ( deployment_id : int , flow_id : str , flow_name : str , project_name : str , ) -> str Store a flow in the model database. Parameters: Name Type Description Default deployment_id int ID of deployment associated with the flow. required flow_id str ID of flow (generated by Prefect). required flow_name str Name of flow (same as used to register with Prefect). required project_name str Name of project (same as used to register with Prefect). required Returns: Name Type Description str str Inserted flow id Source code in lume_services/services/models/service.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def store_flow ( self , deployment_id : int , flow_id : str , flow_name : str , project_name : str ) -> str : \"\"\"Store a flow in the model database. Args: deployment_id (int): ID of deployment associated with the flow. flow_id (str): ID of flow (generated by Prefect). flow_name (str): Name of flow (same as used to register with Prefect). project_name (str): Name of project (same as used to register with Prefect). Returns: str: Inserted flow id \"\"\" insert_stmt = insert ( Flow ) . values ( flow_id = flow_id , deployment_id = deployment_id , flow_name = flow_name , project_name = project_name , ) results = self . _model_db . insert ( insert_stmt ) # flow_id is result of first insert if len ( results ): return results [ 0 ] else : return None","title":"store_flow()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_model","text":"get_model ( ** kwargs ) -> Model Get a model from criteria Returns: Type Description Model Model Source code in lume_services/services/models/service.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @validate_kwargs_exist ( Model ) def get_model ( self , ** kwargs ) -> Model : \"\"\"Get a model from criteria Returns: Model \"\"\" # execute query query = select ( Model ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple models returned from query. get_model is returning the \\ first result with %s %s \" , \"model_id\" , result [ 0 ] . model_id , ) return result [ 0 ] else : raise ModelNotFoundError ( query )","title":"get_model()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_deployment","text":"get_deployment ( ** kwargs ) -> Deployment Get a deployment based on criteria Returns: Type Description Deployment Deployment Source code in lume_services/services/models/service.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 @validate_kwargs_exist ( Deployment ) def get_deployment ( self , ** kwargs ) -> Deployment : \"\"\"Get a deployment based on criteria Returns: Deployment \"\"\" query = select ( Deployment ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple deployments returned from query. get_deployment is \\ returning the first result with %s %s \" , \"deployment_id\" , result [ 0 ] . deployment_id , ) return result [ 0 ] else : raise DeploymentNotFoundError ( query )","title":"get_deployment()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_latest_deployment","text":"get_latest_deployment ( ** kwargs ) -> Deployment Get the latest deployment Returns: Type Description Deployment Deployment Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 @validate_kwargs_exist ( Deployment ) def get_latest_deployment ( self , ** kwargs ) -> Deployment : \"\"\"Get the latest deployment Returns: Deployment raises: ValueError: Passed kwarg not in Project schema \"\"\" query = ( select ( Deployment ) . filter_by ( ** kwargs ) . order_by ( desc ( Deployment . deploy_date )) ) result = self . _model_db . select ( query ) if len ( result ): return result [ 0 ] else : raise DeploymentNotFoundError ( query )","title":"get_latest_deployment()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_project","text":"get_project ( ** kwargs ) -> Project Get a single Project Returns: Type Description Project Project Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 @validate_kwargs_exist ( Project ) def get_project ( self , ** kwargs ) -> Project : \"\"\"Get a single Project Returns: Project raises: ValueError: Passed kwarg not in Project schema \"\"\" # execute query query = select ( Project ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple projects returned from query. get_project is returning \\ the first result with %s %s \" , \"name\" , result [ 0 ] . project_name , ) return result [ 0 ] else : raise ProjectNotFoundError ( query )","title":"get_project()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_flow","text":"get_flow ( ** kwargs ) -> Flow Get a flow from criteria Returns: Name Type Description Flow Flow Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 @validate_kwargs_exist ( Flow ) def get_flow ( self , ** kwargs ) -> Flow : \"\"\"Get a flow from criteria Returns: Flow: raises: ValueError: Passed kwarg not in Project schema \"\"\" query = select ( Flow ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): if len ( result ) > 1 : # formatted this way to eventually move towards interpolated schema logger . warning ( \"Multiple flows returned from query. get_flow is returning the \\ first result with %s %s \" , \"flow_id\" , result [ 0 ] . flow_id , ) return result [ 0 ] else : raise FlowNotFoundError ( query )","title":"get_flow()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.get_flow_of_flows","text":"get_flow_of_flows ( ** kwargs ) -> Flow Get a flow from criteria Returns: Name Type Description FlowOfFlows Flow Raises: Type Description ValueError Passed kwarg not in Project schema Source code in lume_services/services/models/service.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @validate_kwargs_exist ( FlowOfFlows ) def get_flow_of_flows ( self , ** kwargs ) -> Flow : \"\"\"Get a flow from criteria Returns: FlowOfFlows: raises: ValueError: Passed kwarg not in Project schema \"\"\" query = select ( FlowOfFlows ) . filter_by ( ** kwargs ) result = self . _model_db . select ( query ) if len ( result ): return [ res . flow for res in result ] else : raise FlowOfFlowsNotFoundError ( query )","title":"get_flow_of_flows()"},{"location":"api/services/models/models/#lume_services.services.models.service.ModelDBService.apply_schema","text":"apply_schema () -> None Applies database schema to connected service. Source code in lume_services/services/models/service.py 319 320 321 322 def apply_schema ( self ) -> None : \"\"\"Applies database schema to connected service.\"\"\" Base . metadata . create_all ( self . _model_db . engine )","title":"apply_schema()"},{"location":"api/services/models/models/#lume_services.services.models.service-functions","text":"","title":"Functions"},{"location":"api/services/results/db/","text":"lume_services.services.results.db Classes ResultsDBConfig Bases: BaseModel ResultsDB ResultsDB ( db_config : ResultsDBConfig ) Bases: ABC Implementation of the database. Source code in lume_services/services/results/db.py 19 20 21 @abstractmethod def __init__ ( self , db_config : ResultsDBConfig ): ... Functions insert_one abstractmethod insert_one ( item : dict , ** kwargs ) -> str Insert document into the database. Parameters: Name Type Description Default item dict Dictionary representation of item required Returns: Name Type Description str str Inserted item id Source code in lume_services/services/results/db.py 23 24 25 26 27 28 29 30 31 32 33 @abstractmethod def insert_one ( self , item : dict , ** kwargs ) -> str : \"\"\"Insert document into the database. Args: item (dict): Dictionary representation of item Returns: str: Inserted item id \"\"\" insert_many abstractmethod insert_many ( items : List [ dict ], ** kwargs ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default items List [ dict ] List of dictionary representations of items required Returns: Type Description List [ str ] List[str]: List of interted ids Source code in lume_services/services/results/db.py 35 36 37 38 39 40 41 42 43 44 45 @abstractmethod def insert_many ( self , items : List [ dict ], ** kwargs ) -> List [ str ]: \"\"\"Insert many documents into the database. Args: items (List[dict]): List of dictionary representations of items Returns: List[str]: List of interted ids \"\"\" find abstractmethod find ( * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default query dict fields to query on required fields List [ str ] List of fields to return if any None **kwargs dict DB implementation specific fields {} Returns: Type Description List [ dict ] List[dict]: List of dict reps of found items. Source code in lume_services/services/results/db.py 47 48 49 50 51 52 53 54 55 56 57 58 59 @abstractmethod def find ( self , * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: query (dict): fields to query on fields (List[str]): List of fields to return if any **kwargs (dict): DB implementation specific fields Returns: List[dict]: List of dict reps of found items. \"\"\" find_all abstractmethod find_all ( ** kwargs ) -> List [ dict ] Find all documents for a collection Returns: Type Description List [ dict ] List[dict]: List of result items represented as dict. Source code in lume_services/services/results/db.py 61 62 63 64 65 66 67 @abstractmethod def find_all ( self , ** kwargs ) -> List [ dict ]: \"\"\"Find all documents for a collection Returns: List[dict]: List of result items represented as dict. \"\"\" configure abstractmethod configure ( ** kwargs ) -> None Configure the results db service. Source code in lume_services/services/results/db.py 69 70 71 @abstractmethod def configure ( self , ** kwargs ) -> None : \"\"\"Configure the results db service.\"\"\" lume_services.services.results.mongodb Classes MongodbResultsDBConfig Bases: ResultsDBConfig Configuration for connecting to Mongodb using the PyMongo driver. Attr database (Optional[str]): Database name used for storing results. host (str): Host name of mongodb service. username (str): Username string. password (SecretStr): Password stored as a Pydantic secret string. https://pydantic-docs.helpmanual.io/usage/types/#secret-types port (int): Host port of mongodb service endpoint. authMechanism (): Auth mechanism supported by PyMongo driver. See https://pymongo.readthedocs.io/en/stable/api/pymongo/database.html#pymongo.auth.MECHANISMS. options (dict): Dictionary of additional connection options for MongoClient. https://pymongo.readthedocs.io/en/stable/api/pymongo/mongo_client.html#pymongo.mongo_client.MongoClient Attributes database class-attribute database : Optional [ str ] = Field ( exclude = True ) username class-attribute username : str host class-attribute host : str password class-attribute password : SecretStr = Field ( exclude = True ) port class-attribute port : int authMechanism class-attribute authMechanism : str = 'DEFAULT' options class-attribute options : dict = Field ({}, exclude = True ) Classes Config Attributes allow_population_by_field_name class-attribute allow_population_by_field_name = True MongodbCollection Bases: BaseModel Attributes database class-attribute database : str name class-attribute name : str indices class-attribute indices : dict MongodbResultsDB MongodbResultsDB ( db_config : MongodbResultsDBConfig , connect : bool = True ) Bases: ResultsDB Source code in lume_services/services/results/mongodb.py 62 63 64 65 66 67 68 69 70 def __init__ ( self , db_config : MongodbResultsDBConfig , connect : bool = True ): self . config = db_config # track pid to make multiprocessing safe self . _pid = os . getpid () self . _client = ContextVar ( \"client\" , default = None ) self . _collections = ContextVar ( \"collections\" , default = {}) if connect : self . _connect () Attributes config instance-attribute config = db_config Functions disconnect disconnect () Disconnect mongodb connection. Source code in lume_services/services/results/mongodb.py 120 121 122 def disconnect ( self ): \"\"\"Disconnect mongodb connection.\"\"\" self . _disconnect () client client () -> MongoClient Context manager for mongoclient. Will check for multiprocessing and restart accordingly. Source code in lume_services/services/results/mongodb.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 @contextmanager def client ( self ) -> MongoClient : \"\"\"Context manager for mongoclient. Will check for multiprocessing and restart accordingly. \"\"\" self . _check_mp () # get connection client = self . _client . get () if client is None : client = self . _connect () cleanup = True else : cleanup = False try : yield client finally : if cleanup : client = self . _client . get () if client : self . _disconnect () insert_one insert_one ( collection : str , ** kwargs ) -> str Insert one document into the database. Parameters: Name Type Description Default collection str Name of collection for saving document required **kwargs Kwargs contain representation of document {} Returns: Name Type Description str str saved document id Source code in lume_services/services/results/mongodb.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def insert_one ( self , collection : str , ** kwargs ) -> str : \"\"\"Insert one document into the database. Args: collection (str): Name of collection for saving document **kwargs: Kwargs contain representation of document Returns: str: saved document id \"\"\" with self . client () as client : db = client [ self . config . database ] inserted_id = db [ collection ] . insert_one ( kwargs ) . inserted_id return inserted_id insert_many insert_many ( collection : str , items : List [ dict ] ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default collection str Document type to query required items List [ dict ] List of dictionary reps of documents to save to database required Returns: Type Description List [ str ] List[str]: List of saved document ids. Source code in lume_services/services/results/mongodb.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def insert_many ( self , collection : str , items : List [ dict ]) -> List [ str ]: \"\"\"Insert many documents into the database. Args: collection (str): Document type to query items (List[dict]): List of dictionary reps of documents to save to database Returns: List[str]: List of saved document ids. \"\"\" with self . client () as client : db = client [ self . config . database ] inserted_ids = db [ collection ] . insert_many ( items ) . inserted_ids return [ inserted_id . str for inserted_id in inserted_ids ] find find ( collection : str , query : dict = None , fields : List [ str ] = None , ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default collection str Document type to query required query dict Query in dictionary form mapping fields to values None fields List [ str ] List of fields for filtering result None Returns: Type Description List [ dict ] List[dict]: List of of saved document ids. Source code in lume_services/services/results/mongodb.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def find ( self , collection : str , query : dict = None , fields : List [ str ] = None ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: collection (str): Document type to query query (dict): Query in dictionary form mapping fields to values fields (List[str]): List of fields for filtering result Returns: List[dict]: List of of saved document ids. \"\"\" with self . client () as client : db = client [ self . config . database ] if fields is None : results = db [ collection ] . find ( query ) else : results = db [ collection ] . find ( query , projection = fields ) return list ( results ) find_all find_all ( collection : str ) -> List [ dict ] Find all documents for a collection Parameters: Name Type Description Default collection str Collection name to query required Returns: Type Description List [ dict ] List[dict]: List of result documents. Source code in lume_services/services/results/mongodb.py 211 212 213 214 215 216 217 218 219 220 221 def find_all ( self , collection : str ) -> List [ dict ]: \"\"\"Find all documents for a collection Args: collection (str): Collection name to query Returns: List[dict]: List of result documents. \"\"\" return self . find ( collection = collection ) configure configure ( collections : Dict [ str , List [ str ]]) -> None Configure the results database from collections and their indices. Parameters: Name Type Description Default collections Dict [ str , List [ str ]] Dictionary mapping collection to index rep. required Source code in lume_services/services/results/mongodb.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def configure ( self , collections : Dict [ str , List [ str ]]) -> None : \"\"\"Configure the results database from collections and their indices. Args: collections (Dict[str, List[str]]): Dictionary mapping collection to index rep. \"\"\" with self . client () as client : db = client [ self . config . database ] for collection_name , index in collections . items (): formatted_index = [( idx , DESCENDING ) for idx in index ] db [ collection_name ] . create_index ( formatted_index , unique = True ) for collection_name in collections : index_info = db [ collection_name ] . index_information () collections [ collection_name ] = MongodbCollection ( database = self . config . database , name = collection_name , indices = index_info ) self . _collections . set ( collections )","title":"Database"},{"location":"api/services/results/db/#lume_services.services.results.db","text":"","title":"db"},{"location":"api/services/results/db/#lume_services.services.results.db-classes","text":"","title":"Classes"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDBConfig","text":"Bases: BaseModel","title":"ResultsDBConfig"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB","text":"ResultsDB ( db_config : ResultsDBConfig ) Bases: ABC Implementation of the database. Source code in lume_services/services/results/db.py 19 20 21 @abstractmethod def __init__ ( self , db_config : ResultsDBConfig ): ...","title":"ResultsDB"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB-functions","text":"","title":"Functions"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB.insert_one","text":"insert_one ( item : dict , ** kwargs ) -> str Insert document into the database. Parameters: Name Type Description Default item dict Dictionary representation of item required Returns: Name Type Description str str Inserted item id Source code in lume_services/services/results/db.py 23 24 25 26 27 28 29 30 31 32 33 @abstractmethod def insert_one ( self , item : dict , ** kwargs ) -> str : \"\"\"Insert document into the database. Args: item (dict): Dictionary representation of item Returns: str: Inserted item id \"\"\"","title":"insert_one()"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB.insert_many","text":"insert_many ( items : List [ dict ], ** kwargs ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default items List [ dict ] List of dictionary representations of items required Returns: Type Description List [ str ] List[str]: List of interted ids Source code in lume_services/services/results/db.py 35 36 37 38 39 40 41 42 43 44 45 @abstractmethod def insert_many ( self , items : List [ dict ], ** kwargs ) -> List [ str ]: \"\"\"Insert many documents into the database. Args: items (List[dict]): List of dictionary representations of items Returns: List[str]: List of interted ids \"\"\"","title":"insert_many()"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB.find","text":"find ( * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default query dict fields to query on required fields List [ str ] List of fields to return if any None **kwargs dict DB implementation specific fields {} Returns: Type Description List [ dict ] List[dict]: List of dict reps of found items. Source code in lume_services/services/results/db.py 47 48 49 50 51 52 53 54 55 56 57 58 59 @abstractmethod def find ( self , * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: query (dict): fields to query on fields (List[str]): List of fields to return if any **kwargs (dict): DB implementation specific fields Returns: List[dict]: List of dict reps of found items. \"\"\"","title":"find()"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB.find_all","text":"find_all ( ** kwargs ) -> List [ dict ] Find all documents for a collection Returns: Type Description List [ dict ] List[dict]: List of result items represented as dict. Source code in lume_services/services/results/db.py 61 62 63 64 65 66 67 @abstractmethod def find_all ( self , ** kwargs ) -> List [ dict ]: \"\"\"Find all documents for a collection Returns: List[dict]: List of result items represented as dict. \"\"\"","title":"find_all()"},{"location":"api/services/results/db/#lume_services.services.results.db.ResultsDB.configure","text":"configure ( ** kwargs ) -> None Configure the results db service. Source code in lume_services/services/results/db.py 69 70 71 @abstractmethod def configure ( self , ** kwargs ) -> None : \"\"\"Configure the results db service.\"\"\"","title":"configure()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb","text":"","title":"mongodb"},{"location":"api/services/results/db/#lume_services.services.results.mongodb-classes","text":"","title":"Classes"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig","text":"Bases: ResultsDBConfig Configuration for connecting to Mongodb using the PyMongo driver. Attr database (Optional[str]): Database name used for storing results. host (str): Host name of mongodb service. username (str): Username string. password (SecretStr): Password stored as a Pydantic secret string. https://pydantic-docs.helpmanual.io/usage/types/#secret-types port (int): Host port of mongodb service endpoint. authMechanism (): Auth mechanism supported by PyMongo driver. See https://pymongo.readthedocs.io/en/stable/api/pymongo/database.html#pymongo.auth.MECHANISMS. options (dict): Dictionary of additional connection options for MongoClient. https://pymongo.readthedocs.io/en/stable/api/pymongo/mongo_client.html#pymongo.mongo_client.MongoClient","title":"MongodbResultsDBConfig"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.database","text":"database : Optional [ str ] = Field ( exclude = True )","title":"database"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.username","text":"username : str","title":"username"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.host","text":"host : str","title":"host"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.password","text":"password : SecretStr = Field ( exclude = True )","title":"password"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.port","text":"port : int","title":"port"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.authMechanism","text":"authMechanism : str = 'DEFAULT'","title":"authMechanism"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.options","text":"options : dict = Field ({}, exclude = True )","title":"options"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig-classes","text":"","title":"Classes"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDBConfig.Config","text":"Attributes allow_population_by_field_name class-attribute allow_population_by_field_name = True","title":"Config"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbCollection","text":"Bases: BaseModel","title":"MongodbCollection"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbCollection-attributes","text":"","title":"Attributes"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbCollection.database","text":"database : str","title":"database"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbCollection.name","text":"name : str","title":"name"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbCollection.indices","text":"indices : dict","title":"indices"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB","text":"MongodbResultsDB ( db_config : MongodbResultsDBConfig , connect : bool = True ) Bases: ResultsDB Source code in lume_services/services/results/mongodb.py 62 63 64 65 66 67 68 69 70 def __init__ ( self , db_config : MongodbResultsDBConfig , connect : bool = True ): self . config = db_config # track pid to make multiprocessing safe self . _pid = os . getpid () self . _client = ContextVar ( \"client\" , default = None ) self . _collections = ContextVar ( \"collections\" , default = {}) if connect : self . _connect ()","title":"MongodbResultsDB"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB-attributes","text":"","title":"Attributes"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.config","text":"config = db_config","title":"config"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB-functions","text":"","title":"Functions"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.disconnect","text":"disconnect () Disconnect mongodb connection. Source code in lume_services/services/results/mongodb.py 120 121 122 def disconnect ( self ): \"\"\"Disconnect mongodb connection.\"\"\" self . _disconnect ()","title":"disconnect()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.client","text":"client () -> MongoClient Context manager for mongoclient. Will check for multiprocessing and restart accordingly. Source code in lume_services/services/results/mongodb.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 @contextmanager def client ( self ) -> MongoClient : \"\"\"Context manager for mongoclient. Will check for multiprocessing and restart accordingly. \"\"\" self . _check_mp () # get connection client = self . _client . get () if client is None : client = self . _connect () cleanup = True else : cleanup = False try : yield client finally : if cleanup : client = self . _client . get () if client : self . _disconnect ()","title":"client()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.insert_one","text":"insert_one ( collection : str , ** kwargs ) -> str Insert one document into the database. Parameters: Name Type Description Default collection str Name of collection for saving document required **kwargs Kwargs contain representation of document {} Returns: Name Type Description str str saved document id Source code in lume_services/services/results/mongodb.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def insert_one ( self , collection : str , ** kwargs ) -> str : \"\"\"Insert one document into the database. Args: collection (str): Name of collection for saving document **kwargs: Kwargs contain representation of document Returns: str: saved document id \"\"\" with self . client () as client : db = client [ self . config . database ] inserted_id = db [ collection ] . insert_one ( kwargs ) . inserted_id return inserted_id","title":"insert_one()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.insert_many","text":"insert_many ( collection : str , items : List [ dict ] ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default collection str Document type to query required items List [ dict ] List of dictionary reps of documents to save to database required Returns: Type Description List [ str ] List[str]: List of saved document ids. Source code in lume_services/services/results/mongodb.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def insert_many ( self , collection : str , items : List [ dict ]) -> List [ str ]: \"\"\"Insert many documents into the database. Args: collection (str): Document type to query items (List[dict]): List of dictionary reps of documents to save to database Returns: List[str]: List of saved document ids. \"\"\" with self . client () as client : db = client [ self . config . database ] inserted_ids = db [ collection ] . insert_many ( items ) . inserted_ids return [ inserted_id . str for inserted_id in inserted_ids ]","title":"insert_many()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.find","text":"find ( collection : str , query : dict = None , fields : List [ str ] = None , ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default collection str Document type to query required query dict Query in dictionary form mapping fields to values None fields List [ str ] List of fields for filtering result None Returns: Type Description List [ dict ] List[dict]: List of of saved document ids. Source code in lume_services/services/results/mongodb.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def find ( self , collection : str , query : dict = None , fields : List [ str ] = None ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: collection (str): Document type to query query (dict): Query in dictionary form mapping fields to values fields (List[str]): List of fields for filtering result Returns: List[dict]: List of of saved document ids. \"\"\" with self . client () as client : db = client [ self . config . database ] if fields is None : results = db [ collection ] . find ( query ) else : results = db [ collection ] . find ( query , projection = fields ) return list ( results )","title":"find()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.find_all","text":"find_all ( collection : str ) -> List [ dict ] Find all documents for a collection Parameters: Name Type Description Default collection str Collection name to query required Returns: Type Description List [ dict ] List[dict]: List of result documents. Source code in lume_services/services/results/mongodb.py 211 212 213 214 215 216 217 218 219 220 221 def find_all ( self , collection : str ) -> List [ dict ]: \"\"\"Find all documents for a collection Args: collection (str): Collection name to query Returns: List[dict]: List of result documents. \"\"\" return self . find ( collection = collection )","title":"find_all()"},{"location":"api/services/results/db/#lume_services.services.results.mongodb.MongodbResultsDB.configure","text":"configure ( collections : Dict [ str , List [ str ]]) -> None Configure the results database from collections and their indices. Parameters: Name Type Description Default collections Dict [ str , List [ str ]] Dictionary mapping collection to index rep. required Source code in lume_services/services/results/mongodb.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def configure ( self , collections : Dict [ str , List [ str ]]) -> None : \"\"\"Configure the results database from collections and their indices. Args: collections (Dict[str, List[str]]): Dictionary mapping collection to index rep. \"\"\" with self . client () as client : db = client [ self . config . database ] for collection_name , index in collections . items (): formatted_index = [( idx , DESCENDING ) for idx in index ] db [ collection_name ] . create_index ( formatted_index , unique = True ) for collection_name in collections : index_info = db [ collection_name ] . index_information () collections [ collection_name ] = MongodbCollection ( database = self . config . database , name = collection_name , indices = index_info ) self . _collections . set ( collections )","title":"configure()"},{"location":"api/services/results/results/","text":"lume_services.services.results.service Classes ResultsDBService ResultsDBService ( results_db : ResultsDB ) Results database for use with NoSQL database service Initialize Results DB Service interface Parameters: Name Type Description Default results_db DBService DB Connection service required Source code in lume_services/services/results/service.py 16 17 18 19 20 21 def __init__ ( self , results_db : ResultsDB ): \"\"\"Initialize Results DB Service interface Args: results_db (DBService): DB Connection service \"\"\" self . _results_db = results_db Functions insert_one insert_one ( item : dict , ** kwargs ) -> str Store model data. Parameters: Name Type Description Default model_type str Must correspond to models listed in model_docs enum provided during construction. required **kwargs Initialization arguments for document construction covering minimal data required by model. {} Returns: Name Type Description bool str Success of storage operation Source code in lume_services/services/results/service.py 23 24 25 26 27 28 29 30 31 32 33 34 def insert_one ( self , item : dict , ** kwargs ) -> str : \"\"\"Store model data. Args: model_type (str): Must correspond to models listed in model_docs enum provided during construction. **kwargs: Initialization arguments for document construction covering minimal data required by model. Returns: bool: Success of storage operation \"\"\" return self . _results_db . insert_one ( ** item , ** kwargs ) insert_many insert_many ( items : List [ dict ], ** kwargs ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default items List [ dict ] List of dictionary representations of items required Returns: Type Description List [ str ] List[str]: List of interted ids Source code in lume_services/services/results/service.py 36 37 38 39 40 41 42 43 44 45 46 def insert_many ( self , items : List [ dict ], ** kwargs ) -> List [ str ]: \"\"\"Insert many documents into the database. Args: items (List[dict]): List of dictionary representations of items Returns: List[str]: List of interted ids \"\"\" return self . _results_db . insert_many ( items , ** kwargs ) find find ( * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default query dict fields to query on required fields List [ str ] List of fields to return if any None **kwargs dict DB implementation specific fields {} Returns: Type Description List [ dict ] List[dict]: List of dict reps of found items. Source code in lume_services/services/results/service.py 48 49 50 51 52 53 54 55 56 57 58 59 60 def find ( self , * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: query (dict): fields to query on fields (List[str]): List of fields to return if any **kwargs (dict): DB implementation specific fields Returns: List[dict]: List of dict reps of found items. \"\"\" return self . _results_db . find ( query = query , fields = fields , ** kwargs ) find_all find_all ( ** kwargs ) -> List [ dict ] Find all documents for a collection Returns: Type Description List [ dict ] List[dict]: List of result items represented as dict. Source code in lume_services/services/results/service.py 62 63 64 65 66 67 68 def find_all ( self , ** kwargs ) -> List [ dict ]: \"\"\"Find all documents for a collection Returns: List[dict]: List of result items represented as dict. \"\"\" return self . _results_db . find_all ( ** kwargs ) load_dataframe load_dataframe ( * , query = {}, fields : List [ str ] = None , ** kwargs ) -> pd . DataFrame Load dataframe from result database query. Parameters: Name Type Description Default query dict Field values for constructing query {} fields List [ str ] Subset of fields to return None **kwargs dict DB implementation specific fields {} Returns: Type Description pd . DataFrame pd.DataFrame Source code in lume_services/services/results/service.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def load_dataframe ( self , * , query = {}, fields : List [ str ] = None , ** kwargs ) -> pd . DataFrame : \"\"\"Load dataframe from result database query. Args: query (dict): Field values for constructing query fields List[str]: Subset of fields to return **kwargs (dict): DB implementation specific fields Returns: pd.DataFrame \"\"\" # flattens results and returns dataframe results = self . find ( query = query , fields = fields , ** kwargs ) flattened = [ flatten_dict ( res ) for res in results ] df = pd . DataFrame ( flattened ) # Load DataFrame # df[\"date\"] = pd.to_datetime(df[\"pv_collection_isotime\"]) # df[\"_id\"] = df[\"_id\"].astype(str) return df Functions","title":"Results Database Service"},{"location":"api/services/results/results/#lume_services.services.results.service","text":"","title":"service"},{"location":"api/services/results/results/#lume_services.services.results.service-classes","text":"","title":"Classes"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService","text":"ResultsDBService ( results_db : ResultsDB ) Results database for use with NoSQL database service Initialize Results DB Service interface Parameters: Name Type Description Default results_db DBService DB Connection service required Source code in lume_services/services/results/service.py 16 17 18 19 20 21 def __init__ ( self , results_db : ResultsDB ): \"\"\"Initialize Results DB Service interface Args: results_db (DBService): DB Connection service \"\"\" self . _results_db = results_db","title":"ResultsDBService"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService-functions","text":"","title":"Functions"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService.insert_one","text":"insert_one ( item : dict , ** kwargs ) -> str Store model data. Parameters: Name Type Description Default model_type str Must correspond to models listed in model_docs enum provided during construction. required **kwargs Initialization arguments for document construction covering minimal data required by model. {} Returns: Name Type Description bool str Success of storage operation Source code in lume_services/services/results/service.py 23 24 25 26 27 28 29 30 31 32 33 34 def insert_one ( self , item : dict , ** kwargs ) -> str : \"\"\"Store model data. Args: model_type (str): Must correspond to models listed in model_docs enum provided during construction. **kwargs: Initialization arguments for document construction covering minimal data required by model. Returns: bool: Success of storage operation \"\"\" return self . _results_db . insert_one ( ** item , ** kwargs )","title":"insert_one()"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService.insert_many","text":"insert_many ( items : List [ dict ], ** kwargs ) -> List [ str ] Insert many documents into the database. Parameters: Name Type Description Default items List [ dict ] List of dictionary representations of items required Returns: Type Description List [ str ] List[str]: List of interted ids Source code in lume_services/services/results/service.py 36 37 38 39 40 41 42 43 44 45 46 def insert_many ( self , items : List [ dict ], ** kwargs ) -> List [ str ]: \"\"\"Insert many documents into the database. Args: items (List[dict]): List of dictionary representations of items Returns: List[str]: List of interted ids \"\"\" return self . _results_db . insert_many ( items , ** kwargs )","title":"insert_many()"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService.find","text":"find ( * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ] Find a document based on a query. Parameters: Name Type Description Default query dict fields to query on required fields List [ str ] List of fields to return if any None **kwargs dict DB implementation specific fields {} Returns: Type Description List [ dict ] List[dict]: List of dict reps of found items. Source code in lume_services/services/results/service.py 48 49 50 51 52 53 54 55 56 57 58 59 60 def find ( self , * , query : dict , fields : List [ str ] = None , ** kwargs ) -> List [ dict ]: \"\"\"Find a document based on a query. Args: query (dict): fields to query on fields (List[str]): List of fields to return if any **kwargs (dict): DB implementation specific fields Returns: List[dict]: List of dict reps of found items. \"\"\" return self . _results_db . find ( query = query , fields = fields , ** kwargs )","title":"find()"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService.find_all","text":"find_all ( ** kwargs ) -> List [ dict ] Find all documents for a collection Returns: Type Description List [ dict ] List[dict]: List of result items represented as dict. Source code in lume_services/services/results/service.py 62 63 64 65 66 67 68 def find_all ( self , ** kwargs ) -> List [ dict ]: \"\"\"Find all documents for a collection Returns: List[dict]: List of result items represented as dict. \"\"\" return self . _results_db . find_all ( ** kwargs )","title":"find_all()"},{"location":"api/services/results/results/#lume_services.services.results.service.ResultsDBService.load_dataframe","text":"load_dataframe ( * , query = {}, fields : List [ str ] = None , ** kwargs ) -> pd . DataFrame Load dataframe from result database query. Parameters: Name Type Description Default query dict Field values for constructing query {} fields List [ str ] Subset of fields to return None **kwargs dict DB implementation specific fields {} Returns: Type Description pd . DataFrame pd.DataFrame Source code in lume_services/services/results/service.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def load_dataframe ( self , * , query = {}, fields : List [ str ] = None , ** kwargs ) -> pd . DataFrame : \"\"\"Load dataframe from result database query. Args: query (dict): Field values for constructing query fields List[str]: Subset of fields to return **kwargs (dict): DB implementation specific fields Returns: pd.DataFrame \"\"\" # flattens results and returns dataframe results = self . find ( query = query , fields = fields , ** kwargs ) flattened = [ flatten_dict ( res ) for res in results ] df = pd . DataFrame ( flattened ) # Load DataFrame # df[\"date\"] = pd.to_datetime(df[\"pv_collection_isotime\"]) # df[\"_id\"] = df[\"_id\"].astype(str) return df","title":"load_dataframe()"},{"location":"api/services/results/results/#lume_services.services.results.service-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/","text":"lume_services.services.scheduling.backends.backend Classes RunConfig Bases: BaseModel , ABC Pydantic representation of Prefect UniversalRunConfig: https://docs.prefect.io/api/latest/run_configs.html#universalrun Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job Attributes labels class-attribute labels : List [ str ] = [ 'lume-services' ] env class-attribute env : Optional [ dict ] Functions build abstractmethod build () -> PrefectRunConfig Method for converting object to Prefect RunConfig type. Returns: Type Description PrefectRunConfig PrefectRunConfig Source code in lume_services/services/scheduling/backends/backend.py 24 25 26 27 28 29 30 31 32 @abstractmethod def build ( self ) -> PrefectRunConfig : \"\"\"Method for converting object to Prefect RunConfig type. Returns: PrefectRunConfig \"\"\" ... Backend Bases: BaseModel , ABC Abstract base class for Prefect backends. Backends handle Prefect interactions including running of flows, result handling, and flow registration with server backends. Functions create_project abstractmethod create_project ( project_name : str ) -> None Create a Prefect project. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Source code in lume_services/services/scheduling/backends/backend.py 42 43 44 45 46 47 48 49 50 51 @abstractmethod def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Backend implementations without server connecton should raise errors when this method is called. Args: project_name (str): Create a named Prefect project. \"\"\" ... register_flow abstractmethod register_flow ( flow : Flow , project_name : str , image : Optional [ str ] ) -> str Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow Flow Prefect flow to register. required project_name str Name of project to register flow to. required image str Name of Docker image to run flow inside. required Returns: Name Type Description str str ID of registered flow. Source code in lume_services/services/scheduling/backends/backend.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @abstractmethod def register_flow ( self , flow : Flow , project_name : str , image : Optional [ str ], ) -> str : \"\"\"Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Args: flow (Flow): Prefect flow to register. project_name (str): Name of project to register flow to. image (str): Name of Docker image to run flow inside. Returns: str: ID of registered flow. \"\"\" ... load_flow abstractmethod load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Source code in lume_services/services/scheduling/backends/backend.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" \"\"\" ... run abstractmethod run ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ] Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Type Description Union [ str , None] Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: Type Description pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/backend.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @abstractmethod def run ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ]: \"\"\"Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" ... run_and_return abstractmethod run_and_return ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Name Type Description Any Any Result of flow run. Raises: Type Description lume_services . errors . EmptyResultError No result is associated with the flow. pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/backend.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 @abstractmethod def run_and_return ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any : \"\"\"Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Any: Result of flow run. Raises: lume_services.errors.EmptyResultError: No result is associated with the flow. pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" ... lume_services.services.scheduling.backends.local Classes LocalRunConfig Bases: RunConfig Local run configuration. If no directory is found at the filepath passed as working_dir, an error will be raised. Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ Dict [ str , str ]] Dictionary of environment variables to use for run working_dir Optional [ str ] Working directory Attributes env class-attribute env : Optional [ Dict [ str , str ]] working_dir class-attribute working_dir : Optional [ str ] = str ( os . getcwd ()) Functions validate validate ( v ) Pydantic validator checking working directory existence Source code in lume_services/services/scheduling/backends/local.py 38 39 40 41 42 43 44 @validator ( \"working_dir\" , pre = True ) def validate ( cls , v ): \"\"\"Pydantic validator checking working directory existence\"\"\" if not os . path . isdir ( v ): raise FileNotFoundError ( \"No directory found at %s \" , v ) return v build build () -> LocalRun Method for converting to Prefect RunConfig type LocalRun. Returns: Type Description LocalRun LocalRun Source code in lume_services/services/scheduling/backends/local.py 46 47 48 49 50 51 52 53 def build ( self ) -> LocalRun : \"\"\"Method for converting to Prefect RunConfig type LocalRun. Returns: LocalRun \"\"\" return LocalRun ( ** self . dict ( exclude_none = True )) LocalBackend Bases: Backend Backend used for local execution. This backend will raise errors on any function calls requiring registration with the Prefect server. Attributes: Name Type Description run_config Optional [ LocalRunConfig ] Default configuration object for a given run. Functions run run ( data : Dict [ str , Any ], run_config : LocalRunConfig = None , * , flow : Flow , ** kwargs ) -> None Run flow execution. Does not return result. Parameters: Name Type Description Default labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work. required env Optional [ dict ] Additional environment variables to set on the job required data Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value. required run_config Optional [ LocalRunConfig ] LocalRunConfig object to configure flow fun. None flow Flow Prefect flow to execute. required **kwargs Keyword arguments to intantiate the LocalRunConfig. {} Raises: Type Description pydantic . ValidationError Error validating run configuration. Source code in lume_services/services/scheduling/backends/local.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def run ( self , data : Dict [ str , Any ], run_config : LocalRunConfig = None , * , flow : Flow , ** kwargs ) -> None : \"\"\"Run flow execution. Does not return result. Args: labels (Optional[List[str]]): an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work. env (Optional[dict]): Additional environment variables to set on the job data (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value. run_config (Optional[LocalRunConfig]): LocalRunConfig object to configure flow fun. flow (Flow): Prefect flow to execute. **kwargs: Keyword arguments to intantiate the LocalRunConfig. Raises: pydantic.ValidationError: Error validating run configuration. \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to LocalBackend.run. Flow \\ will execute using passed run_config.\" ) if run_config is None : run_config = LocalRunConfig ( ** kwargs ) # convert to Prefect LocalRun prefect_run_config = run_config . build () # apply run config flow . run_config = prefect_run_config flow . run ( parameters = data ) run_and_return run_and_return ( data : Dict [ str , Any ], run_config : LocalRunConfig = None , task_name : str = None , * , flow : Flow , ** kwargs ) -> Any Run flow execution and return result. Parameters: Name Type Description Default data Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value. required run_config Optional [ LocalRunConfig ] LocalRunConfig object to configure flow fun. None task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. None flow Flow Prefect flow to execute. required **kwargs Keyword arguments to intantiate the LocalRunConfig. {} Raises: Type Description pydantic . ValidationError Error validating run configuration. EmptyResultError No result is associated with the flow. TaskNotCompletedError Result reference task was not completed. TaskNotInFlowError Provided task slug not in flow. Source code in lume_services/services/scheduling/backends/local.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def run_and_return ( self , data : Dict [ str , Any ], run_config : LocalRunConfig = None , task_name : str = None , * , flow : Flow , ** kwargs ) -> Any : \"\"\"Run flow execution and return result. Args: data (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value. run_config (Optional[LocalRunConfig]): LocalRunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. flow (Flow): Prefect flow to execute. **kwargs: Keyword arguments to intantiate the LocalRunConfig. Raises: pydantic.ValidationError: Error validating run configuration. EmptyResultError: No result is associated with the flow. TaskNotCompletedError: Result reference task was not completed. TaskNotInFlowError: Provided task slug not in flow. \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to LocalBackend.run. Flow \\ will execute using passed run_config.\" ) if run_config is None : run_config = LocalRunConfig ( ** kwargs ) # convert to Prefect LocalRun prefect_run_config = run_config . build () # apply run config flow . run_config = prefect_run_config try : flow_run = flow . run ( parameters = data ) if flow_run . is_failed (): logger . exception ( flow_run . message ) raise FlowFailedError ( flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" , exception_message = flow_run . message , ) except Exception as e : logger . exception ( e . message ) raise FlowFailedError ( flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" , exception_message = e . message , ) result = flow_run . result if result is None : raise EmptyResultError task_to_slug_map = { task : slug for task , slug in flow . slugs . items ()} # slug_to_task_map = {slug: task for task, slug in flow.slugs.items()} # account for task slug if task_name is not None : # get tasks tasks = flow . get_tasks ( name = task_name ) if not len ( tasks ): raise TaskNotInFlowError ( flow_name = flow . name , project_name = \"local\" , task_name = task_name ) results = [] for task in tasks : slug = task_to_slug_map . get ( task ) state = result [ task ] if not state . is_successful (): raise TaskNotCompletedError ( slug , flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" ) res = state . result if res is None : raise EmptyResultError ( \"local_flow\" , \"local_flow_run\" , slug ) results . append ( state . result ) if len ( tasks ) == 1 : return results [ 0 ] else : return results # else return dict of task slug to value else : return { slug : result [ task ] . result for task , slug in task_to_slug_map . items () } create_project create_project ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to register_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 214 215 216 217 218 219 220 221 222 223 def create_project ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to register_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError () register_flow register_flow ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to register_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 225 226 227 228 229 230 231 232 233 234 235 def register_flow ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to register_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError () load_flow load_flow ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to load_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 237 238 239 240 241 242 243 244 245 246 def load_flow ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to load_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError () lume_services.services.scheduling.backends.server Classes PrefectAgentConfig Bases: BaseModel Attributes host class-attribute host : str = 'http://localhost' host_port class-attribute host_port : str = '5000' PrefectServerConfig Bases: BaseModel Attributes tag class-attribute tag : str = 'core-1.2.4' host class-attribute host : str = 'http://localhost' host_port class-attribute host_port : str = '4200' host_ip class-attribute host_ip : str = '127.0.0.1' PrefectUIConfig Bases: BaseModel Attributes host class-attribute host : str = 'http://localhost' host_port class-attribute host_port : str = '8080' host_ip class-attribute host_ip : str = '127.0.0.1' apollo_url class-attribute apollo_url : str = 'http://localhost:4200/graphql' PrefectTelemetryConfig Bases: BaseModel Attributes enabled class-attribute enabled : bool = True PrefectConfig Bases: BaseModel Attributes server class-attribute server : PrefectServerConfig = PrefectServerConfig () ui class-attribute ui : PrefectUIConfig = PrefectUIConfig () telemetry class-attribute telemetry : PrefectTelemetryConfig = PrefectTelemetryConfig () agent class-attribute agent : PrefectAgentConfig = PrefectAgentConfig () home_dir class-attribute home_dir : str = '~/.prefect' debug class-attribute debug : bool = False backend class-attribute backend : Literal [ 'server' , 'cloud' ] = 'server' Functions apply apply () Source code in lume_services/services/scheduling/backends/server.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def apply ( self ): prefect_config . update ( home_dir = self . home_dir , debug = self . debug , backend = self . backend ) # must set endpoint because referenced by client prefect_config . server . update ( endpoint = f \" { self . server . host } : { self . server . host_port } \" , ** self . server . dict () ) prefect_config . server . ui . update ( ** self . ui . dict ()) prefect_config . server . telemetry . update ( ** self . telemetry . dict ()) # client requires api set prefect_config . cloud . update ( api = f \" { self . server . host } : { self . server . host_port } \" ) save_backend ( self . backend ) return prefect_config ServerBackend Bases: Backend Abstract backend used for connecting to a Prefect server. Prefect manages its own contexts for the purpose of registering flow objects etc. This introduced issues with management of clients, namely that even after setting the prefect configuration in the PrefectConfig.apply method, the original cloud context was still being used to construct the client. For this reason, all clients are constructed inside a context constructed from the backend configuration. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. default_image str Default image used for registering flow storage. Attributes config class-attribute config : PrefectConfig default_image class-attribute default_image : str = Field ( None , alias = 'image' ) Functions run_config_type run_config_type () -> PrefectRunConfig Abstract property that must return the Prefect RunConfig type pertinent to the Backend implementation. Source code in lume_services/services/scheduling/backends/server.py 101 102 103 104 105 106 107 @abstractproperty def run_config_type ( self ) -> PrefectRunConfig : \"\"\"Abstract property that must return the Prefect RunConfig type pertinent to the Backend implementation. \"\"\" ... create_project create_project ( project_name : str ) -> None Create a Prefect project. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 109 110 111 112 113 114 115 116 117 118 119 120 121 def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Args: project_name (str): Create a named Prefect project. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" with prefect . context ( config = self . config . apply ()): client = Client () client . create_project ( project_name = project_name ) register_flow register_flow ( flow : Flow , project_name : str , image : str = None , labels : List [ str ] = None , idempotency_key : str = None , version_group_id : str = None , build : bool = True , no_url : bool = False , set_schedule_active : bool = True , ) -> str Register a flow with Prefect. Parameters: Name Type Description Default flow Flow Prefect flow to register required project_name str Name of project to register flow to required image str Name of Docker image to run flow inside. If not specified, this will use the default image packaged with this repository. None build bool Whether the flows storage should be built prior to serialization. By default lume-services flows use the same image for execution with additional packages passed for installation configured at runtime. True labels Optional [ List [ str ]] A list of labels to add to this Flow. None idempotency_key Optional [ str ] a key that, if matching the most recent registration call for this flow group, will prevent the creation of another flow version and return the existing flow id instead. None version_group_id Optional [ str ] The UUID version group ID to use for versioning this Flow in Cloud. If not provided, the version group ID associated with this Flow's project and name will be used. None no_url Optional [ bool ] If True, the stdout from this function will not contain the URL link to the newly-registered flow in the UI False set_schedule_active Optional [ bool ] If False, will set the schedule to inactive in the database to prevent auto-scheduling runs (if the Flow has a schedule) True Returns: Name Type Description str str ID of registered flow Notes prefect registration idempotency key omitted and version group... Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def register_flow ( self , flow : Flow , project_name : str , image : str = None , labels : List [ str ] = None , idempotency_key : str = None , version_group_id : str = None , build : bool = True , no_url : bool = False , set_schedule_active : bool = True , ) -> str : \"\"\"Register a flow with Prefect. Args: flow (Flow): Prefect flow to register project_name (str): Name of project to register flow to image (str): Name of Docker image to run flow inside. If not specified, this will use the default image packaged with this repository. build (bool): Whether the flows storage should be built prior to serialization. By default lume-services flows use the same image for execution with additional packages passed for installation configured at runtime. labels (Optional[List[str]]): A list of labels to add to this Flow. idempotency_key (Optional[str]): a key that, if matching the most recent registration call for this flow group, will prevent the creation of another flow version and return the existing flow id instead. version_group_id (Optional[str]): The UUID version group ID to use for versioning this Flow in Cloud. If not provided, the version group ID associated with this Flow's project and name will be used. no_url (Optional[bool]): If True, the stdout from this function will not contain the URL link to the newly-registered flow in the UI set_schedule_active (Optional[bool]): If False, will set the schedule to inactive in the database to prevent auto-scheduling runs (if the Flow has a schedule) Returns: str: ID of registered flow Notes: prefect registration idempotency key omitted and version group... Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" if not image : image = self . default_image # configure run config for backend run_config = self . run_config_type ( image = image ) flow . run_config = run_config . build () if labels is not None : logger . info ( \"Flow run config is not empty. Clearing existing labels and assigning \\ new.\" ) flow . run_config . labels = set ( labels ) flow . run_config . image_tag = image with prefect . context ( config = self . config . apply ()): flow_id = flow . register ( project_name = project_name , build = build , set_schedule_active = set_schedule_active , version_group_id = version_group_id , no_url = no_url , idempotency_key = idempotency_key , ) return flow_id load_flow load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" flow_view = FlowView . from_flow_name ( flow_name , project_name = project_name , last_updated = True ) with prefect . context ( config = self . config . apply ()): flow_view = FlowView . from_flow_name ( flow_name , project_name = project_name , last_updated = True ) return { \"flow_id\" : flow_view . flow_id , \"flow\" : flow_view . flow } run run ( parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , * , flow_id : str , ** kwargs ) -> str Create a flow run for a flow. Parameters: Name Type Description Default flow_id str Flow identifier required parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value None run_config Optional [ RunConfig ] RunConfig object to configure flow fun. None **kwargs Keyword arguments to intantiate the RunConfig. {} Returns: Name Type Description str str ID of flow run Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/server.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def run ( self , parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , * , flow_id : str , ** kwargs , ) -> str : \"\"\"Create a flow run for a flow. Args: flow_id (str): Flow identifier parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments to intantiate the RunConfig. Returns: str: ID of flow run Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to Backend.run. Flow \\ will execute using passed run_config.\" ) # convert LUME-services run config to appropriate Prefect RunConfig object if run_config is None : run_config = self . run_config_type ( ** kwargs ) prefect_run_config = run_config . build () with prefect . context ( config = self . config . apply ()): client = Client () flow_run_id = client . create_flow_run ( flow_id = flow_id , parameters = parameters , run_config = prefect_run_config ) return flow_run_id run_and_return run_and_return ( parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , task_name : str = None , * , flow_id : str , timeout : timedelta = timedelta ( minutes = 1 ), cancel_on_timeout : bool = True , ** kwargs ) Create a flow run for a flow and return the result. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value None run_config Optional [ RunConfig ] RunConfig object to configure flow fun. None task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. None flow_id str ID of flow to run. required timeout timedelta Time before stopping flow execution. timedelta(minutes=1) cancel_on_timeout bool Whether to cancel execution on timeout error. True **kwargs Keyword arguments to intantiate the RunConfig. {} Raises: Type Description EmptyResultError No result is associated with the flow. TaskNotCompletedError Result reference task was not completed. RuntimeError Flow did not complete within given timeout. prefect . errors . ClientError if the GraphQL query is bad for any reason docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. TaskNotInFlowError Provided task slug not in flow. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/server.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def run_and_return ( self , parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , task_name : str = None , * , flow_id : str , timeout : timedelta = timedelta ( minutes = 1 ), cancel_on_timeout : bool = True , ** kwargs , ): \"\"\"Create a flow run for a flow and return the result. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. flow_id (str): ID of flow to run. timeout (timedelta): Time before stopping flow execution. cancel_on_timeout (bool): Whether to cancel execution on timeout error. **kwargs: Keyword arguments to intantiate the RunConfig. Raises: EmptyResultError: No result is associated with the flow. TaskNotCompletedError: Result reference task was not completed. RuntimeError: Flow did not complete within given timeout. prefect.errors.ClientError: if the GraphQL query is bad for any reason docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. TaskNotInFlowError: Provided task slug not in flow. ValueError: Value error on flow run \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to Backend.run. Flow \\ will execute using passed run_config.\" ) # convert LUME-services run config to appropriate Prefect RunConfig object if run_config is None : run_config = self . run_config_type ( ** kwargs ) prefect_run_config = run_config . build () logger . info ( \"Creating Prefect flow run for %s with parameters %s and run_config %s \" , flow_id , parameters , run_config . json (), ) with prefect . context ( config = self . config . apply ()): client = Client () flow_run_id = client . create_flow_run ( flow_id = flow_id , parameters = parameters , run_config = prefect_run_config ) flow_view = FlowView . from_flow_id ( flow_id ) # watch flow run and stream logs until timeout try : for log in watch_flow_run ( flow_run_id , stream_states = True , stream_logs = True , max_duration = timeout , ): logger . info ( log ) except RuntimeError as err : if cancel_on_timeout : client . cancel_flow_run ( flow_run_id = flow_run_id ) raise err logger . debug ( \"Watched flow completed.\" ) flow_run = FlowRunView . from_flow_run_id ( flow_run_id ) # check state if flow_run . state . is_failed (): logger . exception ( flow_run . state . message ) raise FlowFailedError ( flow_id = flow_run . flow_id , flow_run_id = flow_run . flow_run_id , exception_message = flow_run . state . message , ) task_runs = flow_run . get_all_task_runs () # populate tasks results = {} for task_run in task_runs : slug = task_run . task_slug if not task_run . state . is_successful (): raise TaskNotCompletedError ( slug , flow_id , flow_run_id ) try : res = task_run . get_result () # location is not set, no result except ValueError : res = None results [ slug ] = res # get task run if task_name is not None : # filter tasks based on name task_runs = { slug : res for slug , res in results . items () if task_name in slug } logger . debug ( task_runs ) if not len ( task_runs ): raise TaskNotInFlowError ( flow_name = flow_view . name , project_name = flow_view . project_name , task_name = task_name , ) if len ( task_runs ) == 1 : res = list ( task_runs . values ())[ 0 ] if res is None : raise EmptyResultError ( flow_id , flow_run_id , slug ) return res else : return task_runs # assume flow result, return all results else : return results lume_services.services.scheduling.backends.docker Classes DockerRunConfig Bases: RunConfig Pydantic representation of a Docker Prefect run configuration: https://docs.prefect.io/api/latest/run_configs.html#dockerrun Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job image str Tag of image in which flow should run. host_config Optional [ Dict [ str , Any ]] Dictionary representing runtime args to be passed to Docker agent. Full documentation of args can be found here: https://docker-py.readthedocs.io/en/stable/api.html#docker.api.container.ContainerApiMixin.create_host_config ports Optional [ List [ int ]] An list of ports numbers to expose on container. Attributes image class-attribute image : str host_config class-attribute host_config : Dict [ str , Any ] = None ports class-attribute ports : Optional [ List [ int ]] Functions validate_host_config validate_host_config ( v ) Composes a model for the Docker host configuration and applies any passed values. Source code in lume_services/services/scheduling/backends/docker.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @validator ( \"host_config\" , pre = True ) def validate_host_config ( cls , v ): \"\"\"Composes a model for the Docker host configuration and applies any passed values. \"\"\" if isinstance ( v , ( dict ,)): # test host config composition using api version try : HostConfig ( version = docker_api_version (), ** v ) except Exception as e : logger . exception ( e ) raise e return v build build () -> DockerRun Method for converting to Prefect RunConfig type DockerRun. Returns: Type Description DockerRun DockerRun Source code in lume_services/services/scheduling/backends/docker.py 54 55 56 57 58 59 60 61 def build ( self ) -> DockerRun : \"\"\"Method for converting to Prefect RunConfig type DockerRun. Returns: DockerRun \"\"\" return DockerRun ( ** self . dict ( exclude_none = True )) DockerBackend Bases: ServerBackend Implementation of Backend used for interacting with prefect deployed in cluster of Docker containers, as with docker-compose. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. _client Client Prefect client connection created on instantiation. _run_config_type type Type used to compose Prefect run configuration. Functions run_config_type property run_config_type () Source code in lume_services/services/scheduling/backends/docker.py 78 79 80 @property def run_config_type ( self ): return self . _run_config_type Functions lume_services.services.scheduling.backends.kubernetes Attributes KUBERNETES_REQUEST_SUFFIXES module-attribute KUBERNETES_REQUEST_SUFFIXES = [ \"EB\" , \"PB\" , \"TB\" , \"GB\" , \"MB\" , \"kB\" , \"EiB\" , \"PiB\" , \"TiB\" , \"GiB\" , \"MiB\" , \"KiB\" , ] Classes KubernetesRunConfig Bases: RunConfig Pydantic representation of args to: https://docs.prefect.io/api/latest/run_configs.html#kubernetesrun https://kubernetes.io/docs/concepts/configuration/overview/#container-images Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job image Optional [ str ] The image to use. Can also be specified via job template. job_template_path Optional [ str ] Path to a job template to use. If a local path (no file scheme, or a file/local scheme), the job template will be loaded on initialization and stored on the KubernetesRun object as the job_template field. Otherwise the job template will be loaded at runtime on the agent. Supported runtime file schemes include (s3, gcs, and agent (for paths local to the runtime agent)). job_template Optional [ str ] An in-memory job template to use. cpu_limit Union [ float , str ] The CPU limit to use for the job cpu_request Union [ float , str ] The CPU request to use for the job memory_limit Optional [ str ] The memory limit to use for the job memory_request Optional [ str ] The memory request to use for the job service_account_name Optional [ str ] A service account name to use for this job. If present, overrides any service account configured on the agent or in the job template. image_pull_secrets Optional [ list ] A list of image pull secrets to use for this job. If present, overrides any image pull secrets configured on the agent or in the job template. image_pull_policy Optional [ str ] The imagePullPolicy to use for the job. Attributes image class-attribute image : Optional [ str ] image_pull_secrets class-attribute image_pull_secrets : Optional [ List [ str ]] job_template class-attribute job_template : Optional [ dict ] job_template_path class-attribute job_template_path : Optional [ str ] service_account_name class-attribute service_account_name : Optional [ str ] image_pull_policy class-attribute image_pull_policy : Literal [ \"Always\" , \"IfNotPresent\" , \"Never\" ] = \"IfNotPresent\" cpu_limit class-attribute cpu_limit : Union [ float , str ] = 1.0 cpu_request class-attribute cpu_request : Union [ float , str ] = 0.5 memory_limit class-attribute memory_limit : Union [ str , int ] = None memory_request class-attribute memory_request : Union [ str , int ] = None Functions validate_memory validate_memory ( v ) Validate w.r.t. Kubernetes resource formats: int, fixed-point number using quantity suffixes: E, P, T, G, M, k or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki Source code in lume_services/services/scheduling/backends/kubernetes.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @validator ( \"memory_limit\" , \"memory_request\" ) def validate_memory ( cls , v ): \"\"\"Validate w.r.t. Kubernetes resource formats: int, fixed-point number using quantity suffixes: E, P, T, G, M, k or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki \"\"\" if isinstance ( v , ( int ,)): return v elif isinstance ( v , ( str ,)): acceptable = False # check substrings inclusions = [ substring for substring in KUBERNETES_REQUEST_SUFFIXES if substring in v ] if len ( inclusions ): for inclusion in inclusions : try : stripped = v . replace ( inclusion , \"\" ) _ = int ( stripped ) acceptable = True except ValueError : pass if not acceptable : logger . error ( \"Kubernetes resource request invalid: %s \" , v ) raise ValueError ( f \"Kubernetes resource request invalid: { v } \" ) else : raise ValueError ( \"Must provide string or int to request\" ) return v build build () -> KubernetesRun Method for converting to Prefect RunConfig type KubernetesRun. Returns: Type Description KubernetesRun KubernetesRun Source code in lume_services/services/scheduling/backends/kubernetes.py 115 116 117 118 119 120 121 122 123 124 125 126 def build ( self ) -> KubernetesRun : \"\"\"Method for converting to Prefect RunConfig type KubernetesRun. Returns: KubernetesRun \"\"\" # if job template and job template path missing, use packaged template if self . job_template is None and self . job_template_path is None : self . job_template = KUBERNETES_JOB_TEMPLATE return KubernetesRun ( ** self . dict ( exclude_none = True )) KubernetesBackend Bases: ServerBackend Implementation of Backend used for interacting with Prefect deployed in K8 cluster. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. _client Client Prefect client connection created on instantiation. _run_config_type type Type used to compose run configuration. Functions run_config_type property run_config_type () Source code in lume_services/services/scheduling/backends/kubernetes.py 143 144 145 @property def run_config_type ( self ): return self . _run_config_type","title":"Backends"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend","text":"","title":"backend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig","text":"Bases: BaseModel , ABC Pydantic representation of Prefect UniversalRunConfig: https://docs.prefect.io/api/latest/run_configs.html#universalrun Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job","title":"RunConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig.labels","text":"labels : List [ str ] = [ 'lume-services' ]","title":"labels"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig.env","text":"env : Optional [ dict ]","title":"env"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.RunConfig.build","text":"build () -> PrefectRunConfig Method for converting object to Prefect RunConfig type. Returns: Type Description PrefectRunConfig PrefectRunConfig Source code in lume_services/services/scheduling/backends/backend.py 24 25 26 27 28 29 30 31 32 @abstractmethod def build ( self ) -> PrefectRunConfig : \"\"\"Method for converting object to Prefect RunConfig type. Returns: PrefectRunConfig \"\"\" ...","title":"build()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend","text":"Bases: BaseModel , ABC Abstract base class for Prefect backends. Backends handle Prefect interactions including running of flows, result handling, and flow registration with server backends.","title":"Backend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend.create_project","text":"create_project ( project_name : str ) -> None Create a Prefect project. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Source code in lume_services/services/scheduling/backends/backend.py 42 43 44 45 46 47 48 49 50 51 @abstractmethod def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Backend implementations without server connecton should raise errors when this method is called. Args: project_name (str): Create a named Prefect project. \"\"\" ...","title":"create_project()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend.register_flow","text":"register_flow ( flow : Flow , project_name : str , image : Optional [ str ] ) -> str Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow Flow Prefect flow to register. required project_name str Name of project to register flow to. required image str Name of Docker image to run flow inside. required Returns: Name Type Description str str ID of registered flow. Source code in lume_services/services/scheduling/backends/backend.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @abstractmethod def register_flow ( self , flow : Flow , project_name : str , image : Optional [ str ], ) -> str : \"\"\"Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Args: flow (Flow): Prefect flow to register. project_name (str): Name of project to register flow to. image (str): Name of Docker image to run flow inside. Returns: str: ID of registered flow. \"\"\" ...","title":"register_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend.load_flow","text":"load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Source code in lume_services/services/scheduling/backends/backend.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" \"\"\" ...","title":"load_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend.run","text":"run ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ] Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Type Description Union [ str , None] Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: Type Description pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/backend.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @abstractmethod def run ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ]: \"\"\"Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" ...","title":"run()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.backend.Backend.run_and_return","text":"run_and_return ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Name Type Description Any Any Result of flow run. Raises: Type Description lume_services . errors . EmptyResultError No result is associated with the flow. pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/backend.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 @abstractmethod def run_and_return ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any : \"\"\"Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Any: Result of flow run. Raises: lume_services.errors.EmptyResultError: No result is associated with the flow. pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" ...","title":"run_and_return()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local","text":"","title":"local"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig","text":"Bases: RunConfig Local run configuration. If no directory is found at the filepath passed as working_dir, an error will be raised. Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ Dict [ str , str ]] Dictionary of environment variables to use for run working_dir Optional [ str ] Working directory","title":"LocalRunConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig.env","text":"env : Optional [ Dict [ str , str ]]","title":"env"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig.working_dir","text":"working_dir : Optional [ str ] = str ( os . getcwd ())","title":"working_dir"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig.validate","text":"validate ( v ) Pydantic validator checking working directory existence Source code in lume_services/services/scheduling/backends/local.py 38 39 40 41 42 43 44 @validator ( \"working_dir\" , pre = True ) def validate ( cls , v ): \"\"\"Pydantic validator checking working directory existence\"\"\" if not os . path . isdir ( v ): raise FileNotFoundError ( \"No directory found at %s \" , v ) return v","title":"validate()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalRunConfig.build","text":"build () -> LocalRun Method for converting to Prefect RunConfig type LocalRun. Returns: Type Description LocalRun LocalRun Source code in lume_services/services/scheduling/backends/local.py 46 47 48 49 50 51 52 53 def build ( self ) -> LocalRun : \"\"\"Method for converting to Prefect RunConfig type LocalRun. Returns: LocalRun \"\"\" return LocalRun ( ** self . dict ( exclude_none = True ))","title":"build()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend","text":"Bases: Backend Backend used for local execution. This backend will raise errors on any function calls requiring registration with the Prefect server. Attributes: Name Type Description run_config Optional [ LocalRunConfig ] Default configuration object for a given run.","title":"LocalBackend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend.run","text":"run ( data : Dict [ str , Any ], run_config : LocalRunConfig = None , * , flow : Flow , ** kwargs ) -> None Run flow execution. Does not return result. Parameters: Name Type Description Default labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work. required env Optional [ dict ] Additional environment variables to set on the job required data Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value. required run_config Optional [ LocalRunConfig ] LocalRunConfig object to configure flow fun. None flow Flow Prefect flow to execute. required **kwargs Keyword arguments to intantiate the LocalRunConfig. {} Raises: Type Description pydantic . ValidationError Error validating run configuration. Source code in lume_services/services/scheduling/backends/local.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def run ( self , data : Dict [ str , Any ], run_config : LocalRunConfig = None , * , flow : Flow , ** kwargs ) -> None : \"\"\"Run flow execution. Does not return result. Args: labels (Optional[List[str]]): an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work. env (Optional[dict]): Additional environment variables to set on the job data (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value. run_config (Optional[LocalRunConfig]): LocalRunConfig object to configure flow fun. flow (Flow): Prefect flow to execute. **kwargs: Keyword arguments to intantiate the LocalRunConfig. Raises: pydantic.ValidationError: Error validating run configuration. \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to LocalBackend.run. Flow \\ will execute using passed run_config.\" ) if run_config is None : run_config = LocalRunConfig ( ** kwargs ) # convert to Prefect LocalRun prefect_run_config = run_config . build () # apply run config flow . run_config = prefect_run_config flow . run ( parameters = data )","title":"run()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend.run_and_return","text":"run_and_return ( data : Dict [ str , Any ], run_config : LocalRunConfig = None , task_name : str = None , * , flow : Flow , ** kwargs ) -> Any Run flow execution and return result. Parameters: Name Type Description Default data Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value. required run_config Optional [ LocalRunConfig ] LocalRunConfig object to configure flow fun. None task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. None flow Flow Prefect flow to execute. required **kwargs Keyword arguments to intantiate the LocalRunConfig. {} Raises: Type Description pydantic . ValidationError Error validating run configuration. EmptyResultError No result is associated with the flow. TaskNotCompletedError Result reference task was not completed. TaskNotInFlowError Provided task slug not in flow. Source code in lume_services/services/scheduling/backends/local.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def run_and_return ( self , data : Dict [ str , Any ], run_config : LocalRunConfig = None , task_name : str = None , * , flow : Flow , ** kwargs ) -> Any : \"\"\"Run flow execution and return result. Args: data (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value. run_config (Optional[LocalRunConfig]): LocalRunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. flow (Flow): Prefect flow to execute. **kwargs: Keyword arguments to intantiate the LocalRunConfig. Raises: pydantic.ValidationError: Error validating run configuration. EmptyResultError: No result is associated with the flow. TaskNotCompletedError: Result reference task was not completed. TaskNotInFlowError: Provided task slug not in flow. \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to LocalBackend.run. Flow \\ will execute using passed run_config.\" ) if run_config is None : run_config = LocalRunConfig ( ** kwargs ) # convert to Prefect LocalRun prefect_run_config = run_config . build () # apply run config flow . run_config = prefect_run_config try : flow_run = flow . run ( parameters = data ) if flow_run . is_failed (): logger . exception ( flow_run . message ) raise FlowFailedError ( flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" , exception_message = flow_run . message , ) except Exception as e : logger . exception ( e . message ) raise FlowFailedError ( flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" , exception_message = e . message , ) result = flow_run . result if result is None : raise EmptyResultError task_to_slug_map = { task : slug for task , slug in flow . slugs . items ()} # slug_to_task_map = {slug: task for task, slug in flow.slugs.items()} # account for task slug if task_name is not None : # get tasks tasks = flow . get_tasks ( name = task_name ) if not len ( tasks ): raise TaskNotInFlowError ( flow_name = flow . name , project_name = \"local\" , task_name = task_name ) results = [] for task in tasks : slug = task_to_slug_map . get ( task ) state = result [ task ] if not state . is_successful (): raise TaskNotCompletedError ( slug , flow_id = \"local_flow\" , flow_run_id = \"local_flow_run\" ) res = state . result if res is None : raise EmptyResultError ( \"local_flow\" , \"local_flow_run\" , slug ) results . append ( state . result ) if len ( tasks ) == 1 : return results [ 0 ] else : return results # else return dict of task slug to value else : return { slug : result [ task ] . result for task , slug in task_to_slug_map . items () }","title":"run_and_return()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend.create_project","text":"create_project ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to register_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 214 215 216 217 218 219 220 221 222 223 def create_project ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to register_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError ()","title":"create_project()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend.register_flow","text":"register_flow ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to register_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 225 226 227 228 229 230 231 232 233 234 235 def register_flow ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to register_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError ()","title":"register_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.local.LocalBackend.load_flow","text":"load_flow ( * args , ** kwargs ) -> None Raise LocalBackendError for calls to load_flow server-type method. Raises: Type Description LocalBackendError Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. Source code in lume_services/services/scheduling/backends/local.py 237 238 239 240 241 242 243 244 245 246 def load_flow ( self , * args , ** kwargs ) -> None : \"\"\"Raise LocalBackendError for calls to load_flow server-type method. Raises: LocalBackendError: Indicates that a server-backend operation has been executed against the LocalBackend. Server-backend operations include flow registration and remote execution. \"\"\" raise LocalBackendError ()","title":"load_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server","text":"","title":"server"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectAgentConfig","text":"Bases: BaseModel","title":"PrefectAgentConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectAgentConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectAgentConfig.host","text":"host : str = 'http://localhost'","title":"host"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectAgentConfig.host_port","text":"host_port : str = '5000'","title":"host_port"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig","text":"Bases: BaseModel","title":"PrefectServerConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig.tag","text":"tag : str = 'core-1.2.4'","title":"tag"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig.host","text":"host : str = 'http://localhost'","title":"host"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig.host_port","text":"host_port : str = '4200'","title":"host_port"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectServerConfig.host_ip","text":"host_ip : str = '127.0.0.1'","title":"host_ip"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig","text":"Bases: BaseModel","title":"PrefectUIConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig.host","text":"host : str = 'http://localhost'","title":"host"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig.host_port","text":"host_port : str = '8080'","title":"host_port"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig.host_ip","text":"host_ip : str = '127.0.0.1'","title":"host_ip"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectUIConfig.apollo_url","text":"apollo_url : str = 'http://localhost:4200/graphql'","title":"apollo_url"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectTelemetryConfig","text":"Bases: BaseModel","title":"PrefectTelemetryConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectTelemetryConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectTelemetryConfig.enabled","text":"enabled : bool = True","title":"enabled"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig","text":"Bases: BaseModel","title":"PrefectConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.server","text":"server : PrefectServerConfig = PrefectServerConfig ()","title":"server"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.ui","text":"ui : PrefectUIConfig = PrefectUIConfig ()","title":"ui"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.telemetry","text":"telemetry : PrefectTelemetryConfig = PrefectTelemetryConfig ()","title":"telemetry"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.agent","text":"agent : PrefectAgentConfig = PrefectAgentConfig ()","title":"agent"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.home_dir","text":"home_dir : str = '~/.prefect'","title":"home_dir"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.debug","text":"debug : bool = False","title":"debug"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.backend","text":"backend : Literal [ 'server' , 'cloud' ] = 'server'","title":"backend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.PrefectConfig.apply","text":"apply () Source code in lume_services/services/scheduling/backends/server.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def apply ( self ): prefect_config . update ( home_dir = self . home_dir , debug = self . debug , backend = self . backend ) # must set endpoint because referenced by client prefect_config . server . update ( endpoint = f \" { self . server . host } : { self . server . host_port } \" , ** self . server . dict () ) prefect_config . server . ui . update ( ** self . ui . dict ()) prefect_config . server . telemetry . update ( ** self . telemetry . dict ()) # client requires api set prefect_config . cloud . update ( api = f \" { self . server . host } : { self . server . host_port } \" ) save_backend ( self . backend ) return prefect_config","title":"apply()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend","text":"Bases: Backend Abstract backend used for connecting to a Prefect server. Prefect manages its own contexts for the purpose of registering flow objects etc. This introduced issues with management of clients, namely that even after setting the prefect configuration in the PrefectConfig.apply method, the original cloud context was still being used to construct the client. For this reason, all clients are constructed inside a context constructed from the backend configuration. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. default_image str Default image used for registering flow storage.","title":"ServerBackend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.config","text":"config : PrefectConfig","title":"config"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.default_image","text":"default_image : str = Field ( None , alias = 'image' )","title":"default_image"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.run_config_type","text":"run_config_type () -> PrefectRunConfig Abstract property that must return the Prefect RunConfig type pertinent to the Backend implementation. Source code in lume_services/services/scheduling/backends/server.py 101 102 103 104 105 106 107 @abstractproperty def run_config_type ( self ) -> PrefectRunConfig : \"\"\"Abstract property that must return the Prefect RunConfig type pertinent to the Backend implementation. \"\"\" ...","title":"run_config_type()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.create_project","text":"create_project ( project_name : str ) -> None Create a Prefect project. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 109 110 111 112 113 114 115 116 117 118 119 120 121 def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Args: project_name (str): Create a named Prefect project. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" with prefect . context ( config = self . config . apply ()): client = Client () client . create_project ( project_name = project_name )","title":"create_project()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.register_flow","text":"register_flow ( flow : Flow , project_name : str , image : str = None , labels : List [ str ] = None , idempotency_key : str = None , version_group_id : str = None , build : bool = True , no_url : bool = False , set_schedule_active : bool = True , ) -> str Register a flow with Prefect. Parameters: Name Type Description Default flow Flow Prefect flow to register required project_name str Name of project to register flow to required image str Name of Docker image to run flow inside. If not specified, this will use the default image packaged with this repository. None build bool Whether the flows storage should be built prior to serialization. By default lume-services flows use the same image for execution with additional packages passed for installation configured at runtime. True labels Optional [ List [ str ]] A list of labels to add to this Flow. None idempotency_key Optional [ str ] a key that, if matching the most recent registration call for this flow group, will prevent the creation of another flow version and return the existing flow id instead. None version_group_id Optional [ str ] The UUID version group ID to use for versioning this Flow in Cloud. If not provided, the version group ID associated with this Flow's project and name will be used. None no_url Optional [ bool ] If True, the stdout from this function will not contain the URL link to the newly-registered flow in the UI False set_schedule_active Optional [ bool ] If False, will set the schedule to inactive in the database to prevent auto-scheduling runs (if the Flow has a schedule) True Returns: Name Type Description str str ID of registered flow Notes prefect registration idempotency key omitted and version group... Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def register_flow ( self , flow : Flow , project_name : str , image : str = None , labels : List [ str ] = None , idempotency_key : str = None , version_group_id : str = None , build : bool = True , no_url : bool = False , set_schedule_active : bool = True , ) -> str : \"\"\"Register a flow with Prefect. Args: flow (Flow): Prefect flow to register project_name (str): Name of project to register flow to image (str): Name of Docker image to run flow inside. If not specified, this will use the default image packaged with this repository. build (bool): Whether the flows storage should be built prior to serialization. By default lume-services flows use the same image for execution with additional packages passed for installation configured at runtime. labels (Optional[List[str]]): A list of labels to add to this Flow. idempotency_key (Optional[str]): a key that, if matching the most recent registration call for this flow group, will prevent the creation of another flow version and return the existing flow id instead. version_group_id (Optional[str]): The UUID version group ID to use for versioning this Flow in Cloud. If not provided, the version group ID associated with this Flow's project and name will be used. no_url (Optional[bool]): If True, the stdout from this function will not contain the URL link to the newly-registered flow in the UI set_schedule_active (Optional[bool]): If False, will set the schedule to inactive in the database to prevent auto-scheduling runs (if the Flow has a schedule) Returns: str: ID of registered flow Notes: prefect registration idempotency key omitted and version group... Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" if not image : image = self . default_image # configure run config for backend run_config = self . run_config_type ( image = image ) flow . run_config = run_config . build () if labels is not None : logger . info ( \"Flow run config is not empty. Clearing existing labels and assigning \\ new.\" ) flow . run_config . labels = set ( labels ) flow . run_config . image_tag = image with prefect . context ( config = self . config . apply ()): flow_id = flow . register ( project_name = project_name , build = build , set_schedule_active = set_schedule_active , version_group_id = version_group_id , no_url = no_url , idempotency_key = idempotency_key , ) return flow_id","title":"register_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.load_flow","text":"load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason Source code in lume_services/services/scheduling/backends/server.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason \"\"\" flow_view = FlowView . from_flow_name ( flow_name , project_name = project_name , last_updated = True ) with prefect . context ( config = self . config . apply ()): flow_view = FlowView . from_flow_name ( flow_name , project_name = project_name , last_updated = True ) return { \"flow_id\" : flow_view . flow_id , \"flow\" : flow_view . flow }","title":"load_flow()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.run","text":"run ( parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , * , flow_id : str , ** kwargs ) -> str Create a flow run for a flow. Parameters: Name Type Description Default flow_id str Flow identifier required parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value None run_config Optional [ RunConfig ] RunConfig object to configure flow fun. None **kwargs Keyword arguments to intantiate the RunConfig. {} Returns: Name Type Description str str ID of flow run Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/server.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def run ( self , parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , * , flow_id : str , ** kwargs , ) -> str : \"\"\"Create a flow run for a flow. Args: flow_id (str): Flow identifier parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments to intantiate the RunConfig. Returns: str: ID of flow run Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. ValueError: Value error on flow run \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to Backend.run. Flow \\ will execute using passed run_config.\" ) # convert LUME-services run config to appropriate Prefect RunConfig object if run_config is None : run_config = self . run_config_type ( ** kwargs ) prefect_run_config = run_config . build () with prefect . context ( config = self . config . apply ()): client = Client () flow_run_id = client . create_flow_run ( flow_id = flow_id , parameters = parameters , run_config = prefect_run_config ) return flow_run_id","title":"run()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.server.ServerBackend.run_and_return","text":"run_and_return ( parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , task_name : str = None , * , flow_id : str , timeout : timedelta = timedelta ( minutes = 1 ), cancel_on_timeout : bool = True , ** kwargs ) Create a flow run for a flow and return the result. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value None run_config Optional [ RunConfig ] RunConfig object to configure flow fun. None task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. None flow_id str ID of flow to run. required timeout timedelta Time before stopping flow execution. timedelta(minutes=1) cancel_on_timeout bool Whether to cancel execution on timeout error. True **kwargs Keyword arguments to intantiate the RunConfig. {} Raises: Type Description EmptyResultError No result is associated with the flow. TaskNotCompletedError Result reference task was not completed. RuntimeError Flow did not complete within given timeout. prefect . errors . ClientError if the GraphQL query is bad for any reason docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. TaskNotInFlowError Provided task slug not in flow. ValueError Value error on flow run Source code in lume_services/services/scheduling/backends/server.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def run_and_return ( self , parameters : Dict [ str , Any ] = None , run_config : RunConfig = None , task_name : str = None , * , flow_id : str , timeout : timedelta = timedelta ( minutes = 1 ), cancel_on_timeout : bool = True , ** kwargs , ): \"\"\"Create a flow run for a flow and return the result. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. flow_id (str): ID of flow to run. timeout (timedelta): Time before stopping flow execution. cancel_on_timeout (bool): Whether to cancel execution on timeout error. **kwargs: Keyword arguments to intantiate the RunConfig. Raises: EmptyResultError: No result is associated with the flow. TaskNotCompletedError: Result reference task was not completed. RuntimeError: Flow did not complete within given timeout. prefect.errors.ClientError: if the GraphQL query is bad for any reason docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. TaskNotInFlowError: Provided task slug not in flow. ValueError: Value error on flow run \"\"\" if run_config is not None and len ( kwargs ): warnings . warn ( \"Both run_config and kwargs passed to Backend.run. Flow \\ will execute using passed run_config.\" ) # convert LUME-services run config to appropriate Prefect RunConfig object if run_config is None : run_config = self . run_config_type ( ** kwargs ) prefect_run_config = run_config . build () logger . info ( \"Creating Prefect flow run for %s with parameters %s and run_config %s \" , flow_id , parameters , run_config . json (), ) with prefect . context ( config = self . config . apply ()): client = Client () flow_run_id = client . create_flow_run ( flow_id = flow_id , parameters = parameters , run_config = prefect_run_config ) flow_view = FlowView . from_flow_id ( flow_id ) # watch flow run and stream logs until timeout try : for log in watch_flow_run ( flow_run_id , stream_states = True , stream_logs = True , max_duration = timeout , ): logger . info ( log ) except RuntimeError as err : if cancel_on_timeout : client . cancel_flow_run ( flow_run_id = flow_run_id ) raise err logger . debug ( \"Watched flow completed.\" ) flow_run = FlowRunView . from_flow_run_id ( flow_run_id ) # check state if flow_run . state . is_failed (): logger . exception ( flow_run . state . message ) raise FlowFailedError ( flow_id = flow_run . flow_id , flow_run_id = flow_run . flow_run_id , exception_message = flow_run . state . message , ) task_runs = flow_run . get_all_task_runs () # populate tasks results = {} for task_run in task_runs : slug = task_run . task_slug if not task_run . state . is_successful (): raise TaskNotCompletedError ( slug , flow_id , flow_run_id ) try : res = task_run . get_result () # location is not set, no result except ValueError : res = None results [ slug ] = res # get task run if task_name is not None : # filter tasks based on name task_runs = { slug : res for slug , res in results . items () if task_name in slug } logger . debug ( task_runs ) if not len ( task_runs ): raise TaskNotInFlowError ( flow_name = flow_view . name , project_name = flow_view . project_name , task_name = task_name , ) if len ( task_runs ) == 1 : res = list ( task_runs . values ())[ 0 ] if res is None : raise EmptyResultError ( flow_id , flow_run_id , slug ) return res else : return task_runs # assume flow result, return all results else : return results","title":"run_and_return()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker","text":"","title":"docker"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig","text":"Bases: RunConfig Pydantic representation of a Docker Prefect run configuration: https://docs.prefect.io/api/latest/run_configs.html#dockerrun Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job image str Tag of image in which flow should run. host_config Optional [ Dict [ str , Any ]] Dictionary representing runtime args to be passed to Docker agent. Full documentation of args can be found here: https://docker-py.readthedocs.io/en/stable/api.html#docker.api.container.ContainerApiMixin.create_host_config ports Optional [ List [ int ]] An list of ports numbers to expose on container.","title":"DockerRunConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig.image","text":"image : str","title":"image"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig.host_config","text":"host_config : Dict [ str , Any ] = None","title":"host_config"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig.ports","text":"ports : Optional [ List [ int ]]","title":"ports"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig.validate_host_config","text":"validate_host_config ( v ) Composes a model for the Docker host configuration and applies any passed values. Source code in lume_services/services/scheduling/backends/docker.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @validator ( \"host_config\" , pre = True ) def validate_host_config ( cls , v ): \"\"\"Composes a model for the Docker host configuration and applies any passed values. \"\"\" if isinstance ( v , ( dict ,)): # test host config composition using api version try : HostConfig ( version = docker_api_version (), ** v ) except Exception as e : logger . exception ( e ) raise e return v","title":"validate_host_config()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerRunConfig.build","text":"build () -> DockerRun Method for converting to Prefect RunConfig type DockerRun. Returns: Type Description DockerRun DockerRun Source code in lume_services/services/scheduling/backends/docker.py 54 55 56 57 58 59 60 61 def build ( self ) -> DockerRun : \"\"\"Method for converting to Prefect RunConfig type DockerRun. Returns: DockerRun \"\"\" return DockerRun ( ** self . dict ( exclude_none = True ))","title":"build()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerBackend","text":"Bases: ServerBackend Implementation of Backend used for interacting with prefect deployed in cluster of Docker containers, as with docker-compose. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. _client Client Prefect client connection created on instantiation. _run_config_type type Type used to compose Prefect run configuration.","title":"DockerBackend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerBackend-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker.DockerBackend.run_config_type","text":"run_config_type () Source code in lume_services/services/scheduling/backends/docker.py 78 79 80 @property def run_config_type ( self ): return self . _run_config_type","title":"run_config_type()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.docker-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes","text":"","title":"kubernetes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KUBERNETES_REQUEST_SUFFIXES","text":"KUBERNETES_REQUEST_SUFFIXES = [ \"EB\" , \"PB\" , \"TB\" , \"GB\" , \"MB\" , \"kB\" , \"EiB\" , \"PiB\" , \"TiB\" , \"GiB\" , \"MiB\" , \"KiB\" , ]","title":"KUBERNETES_REQUEST_SUFFIXES"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig","text":"Bases: RunConfig Pydantic representation of args to: https://docs.prefect.io/api/latest/run_configs.html#kubernetesrun https://kubernetes.io/docs/concepts/configuration/overview/#container-images Attributes: Name Type Description labels Optional [ List [ str ]] an list of labels to apply to this run config. Labels are string identifiers used by Prefect Agents for selecting valid flow runs when polling for work env Optional [ dict ] Additional environment variables to set on the job image Optional [ str ] The image to use. Can also be specified via job template. job_template_path Optional [ str ] Path to a job template to use. If a local path (no file scheme, or a file/local scheme), the job template will be loaded on initialization and stored on the KubernetesRun object as the job_template field. Otherwise the job template will be loaded at runtime on the agent. Supported runtime file schemes include (s3, gcs, and agent (for paths local to the runtime agent)). job_template Optional [ str ] An in-memory job template to use. cpu_limit Union [ float , str ] The CPU limit to use for the job cpu_request Union [ float , str ] The CPU request to use for the job memory_limit Optional [ str ] The memory limit to use for the job memory_request Optional [ str ] The memory request to use for the job service_account_name Optional [ str ] A service account name to use for this job. If present, overrides any service account configured on the agent or in the job template. image_pull_secrets Optional [ list ] A list of image pull secrets to use for this job. If present, overrides any image pull secrets configured on the agent or in the job template. image_pull_policy Optional [ str ] The imagePullPolicy to use for the job.","title":"KubernetesRunConfig"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.image","text":"image : Optional [ str ]","title":"image"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.image_pull_secrets","text":"image_pull_secrets : Optional [ List [ str ]]","title":"image_pull_secrets"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.job_template","text":"job_template : Optional [ dict ]","title":"job_template"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.job_template_path","text":"job_template_path : Optional [ str ]","title":"job_template_path"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.service_account_name","text":"service_account_name : Optional [ str ]","title":"service_account_name"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.image_pull_policy","text":"image_pull_policy : Literal [ \"Always\" , \"IfNotPresent\" , \"Never\" ] = \"IfNotPresent\"","title":"image_pull_policy"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.cpu_limit","text":"cpu_limit : Union [ float , str ] = 1.0","title":"cpu_limit"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.cpu_request","text":"cpu_request : Union [ float , str ] = 0.5","title":"cpu_request"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.memory_limit","text":"memory_limit : Union [ str , int ] = None","title":"memory_limit"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.memory_request","text":"memory_request : Union [ str , int ] = None","title":"memory_request"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.validate_memory","text":"validate_memory ( v ) Validate w.r.t. Kubernetes resource formats: int, fixed-point number using quantity suffixes: E, P, T, G, M, k or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki Source code in lume_services/services/scheduling/backends/kubernetes.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @validator ( \"memory_limit\" , \"memory_request\" ) def validate_memory ( cls , v ): \"\"\"Validate w.r.t. Kubernetes resource formats: int, fixed-point number using quantity suffixes: E, P, T, G, M, k or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki \"\"\" if isinstance ( v , ( int ,)): return v elif isinstance ( v , ( str ,)): acceptable = False # check substrings inclusions = [ substring for substring in KUBERNETES_REQUEST_SUFFIXES if substring in v ] if len ( inclusions ): for inclusion in inclusions : try : stripped = v . replace ( inclusion , \"\" ) _ = int ( stripped ) acceptable = True except ValueError : pass if not acceptable : logger . error ( \"Kubernetes resource request invalid: %s \" , v ) raise ValueError ( f \"Kubernetes resource request invalid: { v } \" ) else : raise ValueError ( \"Must provide string or int to request\" ) return v","title":"validate_memory()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesRunConfig.build","text":"build () -> KubernetesRun Method for converting to Prefect RunConfig type KubernetesRun. Returns: Type Description KubernetesRun KubernetesRun Source code in lume_services/services/scheduling/backends/kubernetes.py 115 116 117 118 119 120 121 122 123 124 125 126 def build ( self ) -> KubernetesRun : \"\"\"Method for converting to Prefect RunConfig type KubernetesRun. Returns: KubernetesRun \"\"\" # if job template and job template path missing, use packaged template if self . job_template is None and self . job_template_path is None : self . job_template = KUBERNETES_JOB_TEMPLATE return KubernetesRun ( ** self . dict ( exclude_none = True ))","title":"build()"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesBackend","text":"Bases: ServerBackend Implementation of Backend used for interacting with Prefect deployed in K8 cluster. Attributes: Name Type Description config PrefectConfig Instantiated PrefectConfig object describing connection to Prefect server. _client Client Prefect client connection created on instantiation. _run_config_type type Type used to compose run configuration.","title":"KubernetesBackend"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesBackend-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/backends/#lume_services.services.scheduling.backends.kubernetes.KubernetesBackend.run_config_type","text":"run_config_type () Source code in lume_services/services/scheduling/backends/kubernetes.py 143 144 145 @property def run_config_type ( self ): return self . _run_config_type","title":"run_config_type()"},{"location":"api/services/scheduling/scheduling/","text":"lume_services.services.scheduling.service Classes SchedulingService SchedulingService ( backend : Backend ) Scheduler handling job submission with Prefect. Initialize PrefectScheduler using configuration Parameters: Name Type Description Default backend Backend Scheduling service client configuration required Source code in lume_services/services/scheduling/service.py 19 20 21 22 23 24 25 26 27 def __init__ ( self , backend : Backend ): \"\"\"Initialize PrefectScheduler using configuration Args: backend (Backend): Scheduling service client configuration \"\"\" self . backend = backend Attributes backend instance-attribute backend = backend Functions create_project create_project ( project_name : str ) -> None Create a Prefect project. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 29 30 31 32 33 34 35 36 37 38 39 40 41 def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Args: project_name (str): Create a named Prefect project. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" self . backend . create_project ( project_name = project_name ) register_flow register_flow ( flow : Flow , project_name : str , image : Optional [ str ], labels : Optional [ List [ str ]], ) -> str Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow Flow Prefect flow to register. required project_name str Name of project to register flow to. required image str Name of Docker image to run flow inside. required Returns: Name Type Description str str ID of registered flow. Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def register_flow ( self , flow : Flow , project_name : str , image : Optional [ str ], labels : Optional [ List [ str ]], ) -> str : \"\"\"Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Args: flow (Flow): Prefect flow to register. project_name (str): Name of project to register flow to. image (str): Name of Docker image to run flow inside. Returns: str: ID of registered flow. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" return self . backend . register_flow ( flow , project_name , image , labels = labels ) load_flow load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" return self . backend . load_flow ( flow_name , project_name ) run run ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ] Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Type Description Union [ str , None] Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: Type Description docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. prefect . errors . ClientError if the GraphQL query is bad for any reason ValueError Value error on flow run Source code in lume_services/services/scheduling/service.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ]: \"\"\"Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. prefect.errors.ClientError: if the GraphQL query is bad for any reason ValueError: Value error on flow run \"\"\" return self . backend . run ( parameters , run_config , ** kwargs ) run_and_return run_and_return ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Name Type Description Any Any Result of flow run. Raises: Type Description lume_services . errors . EmptyResultError No result is associated with the flow. docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . TaskNotInFlowError Task slug does not exist in flow. lume_services . errors . TaskNotCompletedError Result reference task was not completed. RuntimeError Flow did not complete within given timeout. ValueError Value error on flow run Source code in lume_services/services/scheduling/service.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def run_and_return ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any : \"\"\"Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Any: Result of flow run. Raises: lume_services.errors.EmptyResultError: No result is associated with the flow. docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.TaskNotInFlowError: Task slug does not exist in flow. lume_services.errors.TaskNotCompletedError: Result reference task was not completed. RuntimeError: Flow did not complete within given timeout. ValueError: Value error on flow run \"\"\" return self . backend . run_and_return ( parameters , run_config , task_name , ** kwargs )","title":"Scheduling Service"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service","text":"","title":"service"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service-classes","text":"","title":"Classes"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService","text":"SchedulingService ( backend : Backend ) Scheduler handling job submission with Prefect. Initialize PrefectScheduler using configuration Parameters: Name Type Description Default backend Backend Scheduling service client configuration required Source code in lume_services/services/scheduling/service.py 19 20 21 22 23 24 25 26 27 def __init__ ( self , backend : Backend ): \"\"\"Initialize PrefectScheduler using configuration Args: backend (Backend): Scheduling service client configuration \"\"\" self . backend = backend","title":"SchedulingService"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService-attributes","text":"","title":"Attributes"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.backend","text":"backend = backend","title":"backend"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService-functions","text":"","title":"Functions"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.create_project","text":"create_project ( project_name : str ) -> None Create a Prefect project. Parameters: Name Type Description Default project_name str Create a named Prefect project. required Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 29 30 31 32 33 34 35 36 37 38 39 40 41 def create_project ( self , project_name : str ) -> None : \"\"\"Create a Prefect project. Args: project_name (str): Create a named Prefect project. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" self . backend . create_project ( project_name = project_name )","title":"create_project()"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.register_flow","text":"register_flow ( flow : Flow , project_name : str , image : Optional [ str ], labels : Optional [ List [ str ]], ) -> str Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow Flow Prefect flow to register. required project_name str Name of project to register flow to. required image str Name of Docker image to run flow inside. required Returns: Name Type Description str str ID of registered flow. Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def register_flow ( self , flow : Flow , project_name : str , image : Optional [ str ], labels : Optional [ List [ str ]], ) -> str : \"\"\"Register a flow with Prefect. Backend implementations without server connecton should raise errors when this method is called. Args: flow (Flow): Prefect flow to register. project_name (str): Name of project to register flow to. image (str): Name of Docker image to run flow inside. Returns: str: ID of registered flow. Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" return self . backend . register_flow ( flow , project_name , image , labels = labels )","title":"register_flow()"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.load_flow","text":"load_flow ( flow_name : str , project_name : str ) -> dict Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Parameters: Name Type Description Default flow_name str Name of flow. required project_name str Name of project flow is registered with. required Returns: Name Type Description dict dict Dictionary with keys \"flow_id\" and \"flow\" Raises: Type Description prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . LocalBackendError Using local run configuration, no server backend methods permitted. Source code in lume_services/services/scheduling/service.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def load_flow ( self , flow_name : str , project_name : str ) -> dict : \"\"\"Load a Prefect flow object. Backend implementations without server connecton should raise errors when this method is called. Args: flow_name (str): Name of flow. project_name (str): Name of project flow is registered with. Returns: dict: Dictionary with keys \"flow_id\" and \"flow\" Raises: prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.LocalBackendError: Using local run configuration, no server backend methods permitted. \"\"\" return self . backend . load_flow ( flow_name , project_name )","title":"load_flow()"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.run","text":"run ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ] Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Type Description Union [ str , None] Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: Type Description docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. prefect . errors . ClientError if the GraphQL query is bad for any reason ValueError Value error on flow run Source code in lume_services/services/scheduling/service.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], ** kwargs ) -> Union [ str , None ]: \"\"\"Run a flow. Does not return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Union[str, None]: Return run_id in case of server backend, None in the case of local execution. Raises: docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. prefect.errors.ClientError: if the GraphQL query is bad for any reason ValueError: Value error on flow run \"\"\" return self . backend . run ( parameters , run_config , ** kwargs )","title":"run()"},{"location":"api/services/scheduling/scheduling/#lume_services.services.scheduling.service.SchedulingService.run_and_return","text":"run_and_return ( parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Parameters: Name Type Description Default parameters Optional [ Dict [ str , Any ]] Dictionary mapping flow parameter name to value required run_config Optional [ RunConfig ] RunConfig object to configure flow fun. required task_name Optional [ str ] Name of task to return result. If no task slug is passed, will return the flow result. required **kwargs Keyword arguments for RunConfig init and backend-specific execution. {} Returns: Name Type Description Any Any Result of flow run. Raises: Type Description lume_services . errors . EmptyResultError No result is associated with the flow. docker . errors . DockerException Run configuration error for docker api. pydantic . ValidationError Error validating run configuration. prefect . errors . ClientError if the GraphQL query is bad for any reason lume_services . errors . TaskNotInFlowError Task slug does not exist in flow. lume_services . errors . TaskNotCompletedError Result reference task was not completed. RuntimeError Flow did not complete within given timeout. ValueError Value error on flow run Source code in lume_services/services/scheduling/service.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def run_and_return ( self , parameters : Optional [ Dict [ str , Any ]], run_config : Optional [ RunConfig ], task_name : Optional [ str ], ** kwargs ) -> Any : \"\"\"Run a flow and return result. Implementations should cover instantiation of run_config from kwargs as well as backend-specific kwargs. Args: parameters (Optional[Dict[str, Any]]): Dictionary mapping flow parameter name to value run_config (Optional[RunConfig]): RunConfig object to configure flow fun. task_name (Optional[str]): Name of task to return result. If no task slug is passed, will return the flow result. **kwargs: Keyword arguments for RunConfig init and backend-specific execution. Returns: Any: Result of flow run. Raises: lume_services.errors.EmptyResultError: No result is associated with the flow. docker.errors.DockerException: Run configuration error for docker api. pydantic.ValidationError: Error validating run configuration. prefect.errors.ClientError: if the GraphQL query is bad for any reason lume_services.errors.TaskNotInFlowError: Task slug does not exist in flow. lume_services.errors.TaskNotCompletedError: Result reference task was not completed. RuntimeError: Flow did not complete within given timeout. ValueError: Value error on flow run \"\"\" return self . backend . run_and_return ( parameters , run_config , task_name , ** kwargs )","title":"run_and_return()"},{"location":"developer/cluster/","text":"Cluster architecture Docker Kubernetes","title":"Cluster Architecture"},{"location":"developer/cluster/#cluster-architecture","text":"","title":"Cluster architecture"},{"location":"developer/cluster/#docker","text":"","title":"Docker"},{"location":"developer/cluster/#kubernetes","text":"","title":"Kubernetes"},{"location":"developer/configuration/","text":"Pydantic Pydantic docker secrets: https://pydantic-docs.helpmanual.io/usage/settings/ Secret strings used for passwords","title":"Configuration"},{"location":"developer/configuration/#pydantic","text":"","title":"Pydantic"},{"location":"developer/configuration/#pydantic-docker-secrets","text":"https://pydantic-docs.helpmanual.io/usage/settings/ Secret strings used for passwords","title":"Pydantic docker secrets:"},{"location":"developer/docker_image/","text":"Docker Image The lume-services repository is packaged with a Dockerfile for composing the image used to execute individual workflows. The file was modeled after that packaged with Prefect with the addition of conda for environment resolution and already-installed lume-services . When a job is submitted to the scheduling service, the agent creates a container using this image and executes a workflow using a module path (all flows are required to use module storage ). The image allows for environment specification via two environment variables, EXTRA_CONDA_PACKAGES and EXTRA_PIP_PACKAGES , provided as comma-separated strings (see environment.sh ). Environment resolution for isolated jobs Because jobs may be submitted for execution in isolated environments, LUME-services provides an additional environment resolution tool that allows users to prepare a channel with resolved dependencies. Channels can be configured as either a server-based resource or as a mounted filesystem. Insert diagram of requirement flow here","title":"Docker Image"},{"location":"developer/docker_image/#docker-image","text":"The lume-services repository is packaged with a Dockerfile for composing the image used to execute individual workflows. The file was modeled after that packaged with Prefect with the addition of conda for environment resolution and already-installed lume-services . When a job is submitted to the scheduling service, the agent creates a container using this image and executes a workflow using a module path (all flows are required to use module storage ). The image allows for environment specification via two environment variables, EXTRA_CONDA_PACKAGES and EXTRA_PIP_PACKAGES , provided as comma-separated strings (see environment.sh ).","title":"Docker Image"},{"location":"developer/docker_image/#environment-resolution-for-isolated-jobs","text":"Because jobs may be submitted for execution in isolated environments, LUME-services provides an additional environment resolution tool that allows users to prepare a channel with resolved dependencies. Channels can be configured as either a server-based resource or as a mounted filesystem. Insert diagram of requirement flow here","title":"Environment resolution for isolated jobs"},{"location":"developer/documentation/","text":"Documentation Documentation for this project MkDocs For documentation, we use mkdocs to automatically generate our GitHub documentation using the mkdocs.yml packaged in the root of the project directory. docs/api contains the API documentation compiled from docstrings. This doesn't happen automatically -add page to hierarchy in mkdocs.yml Auto generated diagrams: - schema - class diagrams... - Plugins We use the mkdocstrings plugin for building the [API documentation]((../api). This introspects the docstrings on each of our python objects and assembles documentation based on the typed arguments, attributes, returns, etc. Badges This repo uses https://shields.io/ for creating badges packaged with the documentation. Most of these are automatically inferred from repo metadata with the exception of the coverage badge. The coverage badge is generated in the coverage job in the .github/workflows/test.yml workflow. The coverage job formats the coverage report an creates a comment on the commit being tested. That comment is then used by the last step to dynamically format the badge by storing a json representation of badge data in a Github gist . In order for this to happen, the repository secret PYTEST_COVERAGE_COMMENT points to a personal auth token. The maintainer can create a new gist and update the PYTEST_COVERAGE_COMMENT to a new auth string . The comment is created by the subaction: https://github.com/marketplace/actions/python-coverage-comment The dynamic badge is formatted by the subaction: https://github.com/marketplace/actions/dynamic-badges","title":"Documentation"},{"location":"developer/documentation/#documentation","text":"Documentation for this project","title":"Documentation"},{"location":"developer/documentation/#mkdocs","text":"For documentation, we use mkdocs to automatically generate our GitHub documentation using the mkdocs.yml packaged in the root of the project directory. docs/api contains the API documentation compiled from docstrings. This doesn't happen automatically -add page to hierarchy in mkdocs.yml Auto generated diagrams: - schema - class diagrams... -","title":"MkDocs"},{"location":"developer/documentation/#plugins","text":"We use the mkdocstrings plugin for building the [API documentation]((../api). This introspects the docstrings on each of our python objects and assembles documentation based on the typed arguments, attributes, returns, etc.","title":"Plugins"},{"location":"developer/documentation/#badges","text":"This repo uses https://shields.io/ for creating badges packaged with the documentation. Most of these are automatically inferred from repo metadata with the exception of the coverage badge. The coverage badge is generated in the coverage job in the .github/workflows/test.yml workflow. The coverage job formats the coverage report an creates a comment on the commit being tested. That comment is then used by the last step to dynamically format the badge by storing a json representation of badge data in a Github gist . In order for this to happen, the repository secret PYTEST_COVERAGE_COMMENT points to a personal auth token. The maintainer can create a new gist and update the PYTEST_COVERAGE_COMMENT to a new auth string . The comment is created by the subaction: https://github.com/marketplace/actions/python-coverage-comment The dynamic badge is formatted by the subaction: https://github.com/marketplace/actions/dynamic-badges","title":"Badges"},{"location":"developer/setup/","text":"The repository is packaged using pre-commit hooks for code format consistency. pre-commit install requirements pymdown-extensions>9.4 and Pygments>=2.12 are pinned in docs-requirements.txt because of a compatability bug between pymdown-extensions and earlier versions of Pygments (issue here ).","title":"Setup"},{"location":"developer/setup/#requirements","text":"pymdown-extensions>9.4 and Pygments>=2.12 are pinned in docs-requirements.txt because of a compatability bug between pymdown-extensions and earlier versions of Pygments (issue here ).","title":"requirements"},{"location":"developer/testing/","text":"Testing LUME-services tests are an attempt to capture the networking behavior of the server-based services. The development evironment described in Configuration The pytest.ini file at the root of the repository describes the port-forwarding behavior passed to the docker-compose file packaged here {target=_blank}. Tests Create subprocess for agent All services spun up using docker compose Env variables.... Notes Using docker-compose every time you execute tests is extremely costly. These could be refactored to optionally use persistent resources. GitHub action The GitHub action packaged with this repository creates automatic coverage reports and generates the badge on the README","title":"Testing"},{"location":"developer/testing/#testing","text":"LUME-services tests are an attempt to capture the networking behavior of the server-based services. The development evironment described in","title":"Testing"},{"location":"developer/testing/#configuration","text":"The pytest.ini file at the root of the repository describes the port-forwarding behavior passed to the docker-compose file packaged here {target=_blank}.","title":"Configuration"},{"location":"developer/testing/#tests","text":"Create subprocess for agent All services spun up using docker compose Env variables....","title":"Tests"},{"location":"developer/testing/#notes","text":"Using docker-compose every time you execute tests is extremely costly. These could be refactored to optionally use persistent resources.","title":"Notes"},{"location":"developer/testing/#github-action","text":"The GitHub action packaged with this repository creates automatic coverage reports and generates the badge on the README","title":"GitHub action"},{"location":"developer/todo/","text":"TODO: Repo setup TODO: Docs for injection and container Remove tests in pip installation, move to directory base Docs! Set up all loggers Done: Versioneer Action for testing package install & running pytests Tests for injection and container 7/5 Environment variables with extensible prefix 7/5 License should be passed or something generic. SLAC license shouldn't be in LUME 4/12 Add versioneer config. Versioneer install needs to happen on init. 4/12 Transition from pytest-mysql to remove pip dependency 4/15 Basics of injection and container 4/15 Action for building docs Automatically generate diagram from .sql schema? 5/6s Move any services in init files to a service.py Fix prefect context bug during pytest Template TODO: - [ ] CLI tool - [ ] Instructions for templating tool and configuration - [ ] Templated README - [ ] Handling of input/output variables at outset - [ ] Drop required defaults for lume-model variables - [ ] Check functionality of all - [ ] Docs - Done: - [x] Action for testing package install & running pytests - [x] Upload docker image to repo artifacts 5/3 - [x] Docker build action for templated repos 4/12 Databases TODO: Test database failure cases Rename base classes for DBService Dashboard image field in mongodb for impact Docs Done: Initial tests for mysql model db Abstraction of database schema and auth config from query execution Add flow_to_deployments into db Change model_versions to deployments in schema Make mongodb multiprocessing safe Add uniqueness to results Fix test connection with mysql in-package plugin. \"Connection refused\" 4/13 Backlog TODO: Implement/plan for logging infrastructure Synchronous snapshot service (-> SLAC-services) HPC interface Slurm interface Output service (-> LUME-EPICS?) Done: Finish util testing Scheduler TODO: Test flow of flows composition Add mapped parameters to database? Add requirements table Kubernetes backend tests How do we handle submission of environment variables to the scheduler? For example, how do we communicate the aliasing of services in a docker-compose app? Docs Environment solving for containerized jobs Done: Refactor scheduler 7/13 Create prefect flow image 6/26 Remove redundant flow storage during build in pytest 7/6 Pin docker-py version 7/15 Constrain KubernetesBackend image pull policy to existing options Drop prefect subfolder 6/24 Create docker backend 6/27 Tesing infrastructure for prefect w/ docker compose 6/27 Result tasks Add scheduler to context Drop all but apollo from config 8/3 Improve service wait_until_responsive checks and move into docker 8/9 Misc TODO: Separate template into own repo and use git submodule Could abstract docker compose versions Use environment variable fixture in tests instead of modifying env Done: Rename file.systems to file.filesystems and all files names service.py Move fixtures from conftest to designated files under tests/fixtures Change LUME-model SurrogateModel to BaseModel for generalizability Files TODO: File locks Done: Implement local file handler 5/2 Implement mounted filesystem handler 5/2 Models TODO: Create model interface with injected services Add utility for loading flow objects Preprocessing structure Registration of preprocessing flows","title":"TODO"},{"location":"developer/todo/#todo","text":"","title":"TODO:"},{"location":"developer/todo/#repo-setup","text":"TODO: Docs for injection and container Remove tests in pip installation, move to directory base Docs! Set up all loggers Done: Versioneer Action for testing package install & running pytests Tests for injection and container 7/5 Environment variables with extensible prefix 7/5 License should be passed or something generic. SLAC license shouldn't be in LUME 4/12 Add versioneer config. Versioneer install needs to happen on init. 4/12 Transition from pytest-mysql to remove pip dependency 4/15 Basics of injection and container 4/15 Action for building docs Automatically generate diagram from .sql schema? 5/6s Move any services in init files to a service.py Fix prefect context bug during pytest","title":"Repo setup"},{"location":"developer/todo/#template","text":"TODO: - [ ] CLI tool - [ ] Instructions for templating tool and configuration - [ ] Templated README - [ ] Handling of input/output variables at outset - [ ] Drop required defaults for lume-model variables - [ ] Check functionality of all - [ ] Docs - Done: - [x] Action for testing package install & running pytests - [x] Upload docker image to repo artifacts 5/3 - [x] Docker build action for templated repos 4/12","title":"Template"},{"location":"developer/todo/#databases","text":"TODO: Test database failure cases Rename base classes for DBService Dashboard image field in mongodb for impact Docs Done: Initial tests for mysql model db Abstraction of database schema and auth config from query execution Add flow_to_deployments into db Change model_versions to deployments in schema Make mongodb multiprocessing safe Add uniqueness to results Fix test connection with mysql in-package plugin. \"Connection refused\" 4/13","title":"Databases"},{"location":"developer/todo/#backlog","text":"TODO: Implement/plan for logging infrastructure Synchronous snapshot service (-> SLAC-services) HPC interface Slurm interface Output service (-> LUME-EPICS?) Done: Finish util testing","title":"Backlog"},{"location":"developer/todo/#scheduler","text":"TODO: Test flow of flows composition Add mapped parameters to database? Add requirements table Kubernetes backend tests How do we handle submission of environment variables to the scheduler? For example, how do we communicate the aliasing of services in a docker-compose app? Docs Environment solving for containerized jobs Done: Refactor scheduler 7/13 Create prefect flow image 6/26 Remove redundant flow storage during build in pytest 7/6 Pin docker-py version 7/15 Constrain KubernetesBackend image pull policy to existing options Drop prefect subfolder 6/24 Create docker backend 6/27 Tesing infrastructure for prefect w/ docker compose 6/27 Result tasks Add scheduler to context Drop all but apollo from config 8/3 Improve service wait_until_responsive checks and move into docker 8/9","title":"Scheduler"},{"location":"developer/todo/#misc","text":"TODO: Separate template into own repo and use git submodule Could abstract docker compose versions Use environment variable fixture in tests instead of modifying env Done: Rename file.systems to file.filesystems and all files names service.py Move fixtures from conftest to designated files under tests/fixtures Change LUME-model SurrogateModel to BaseModel for generalizability","title":"Misc"},{"location":"developer/todo/#files","text":"TODO: File locks Done: Implement local file handler 5/2 Implement mounted filesystem handler 5/2","title":"Files"},{"location":"developer/todo/#models","text":"TODO: Create model interface with injected services Add utility for loading flow objects Preprocessing structure Registration of preprocessing flows","title":"Models"},{"location":"developer/services/file/","text":"File Service","title":"File"},{"location":"developer/services/file/#file-service","text":"","title":"File Service"},{"location":"developer/services/models/","text":"Models The model database stores references to registered flows Conda channel The conda channel must be updated to provide the packages ahead of time https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html","title":"Models"},{"location":"developer/services/models/#models","text":"The model database stores references to registered flows","title":"Models"},{"location":"developer/services/models/#conda-channel","text":"The conda channel must be updated to provide the packages ahead of time https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html","title":"Conda channel"},{"location":"developer/services/results/","text":"","title":"Results"},{"location":"developer/services/scheduling/","text":"Scheduling Service Prefect using Prefect version 1.2.X The Prefect server is composed of sub-services ... Agents run externally to the Prefect server and manage job submissions in different contexts. In order to register an agent with Prefect, you must first create a tenant... serialization... Flow level parameters must be json serializable Flows Prefect 1.0 does not support running of subflows directly within a flow so we can't construct flows like: with Flow(\"flow-a\") as flow_a: a() b() with Flow(\"parent-flow\") as flow: c() flow_a.run(executor=LocalDaskExecutor()) flow.run(executor=LocalDaskExecutor()) Instead and unfortunately, flow-of-flow composition requires registration of the flow with a project on the Prefect server and query of tasks by result. Prefect 2.0 will support subflow registration. with Flow(\"local-results1\") as flow: x = Parameter(\"x\") y = check(x) downstream_task(y) flow.register(project_name=\"test-res\") with Flow(\"parent\") as flow2: three = return_3() flow_run = create_flow_run(flow_name=\"local-results1\", parameters={\"x\": three}) flow_wait = wait_for_flow_run(flow_run, raise_final_state=True) root_task_res = get_task_run_result(flow_run, \"downstream_task-1\") downstream_res = get_task_run_result(flow_run, \"test-slug\") The schema in lume_services.services.scheduling.schema.flow_of_flows_schema.py defines the flow of flow configuration compose method on the FlowOfFlows object organizes flows New parameters are created using the scheme {flow_name}-{param_name} Tasks load_db_result vs LoadDBResult Db results assumes one save per flow Allows multiple file results Docker Image The docker image packaged with this repository is designed to provide a base image with ... docker build --build-arg LUME_SERVICES_REPOSITORY=$LUME_SERVICES_REPOSITORY --build-arg PREFECT_VERSION=$PREFECT_VERSION --build-arg LUME_SERVICES_VERSION=$LUME_SERVICES_VERSION --target dev -t test-agent-dev -f prefect-agent-docker/Dockerfile . docker build --build-arg LUME_SERVICES_REPOSITORY=$LUME_SERVICES_REPOSITORY --build-arg PREFECT_VERSION=$PREFECT_VERSION --build-arg LUME_SERVICES_VERSION=$LUME_SERVICES_VERSION --target dev -t test-dev-prefect -f prefect-agent-docker/Dockerfile . docker run -v /var/run/docker.sock:/var/run/docker.sock -it test-agent-dev At runtime, the container accepts two additional environment variables: EXTRA_CONDA_PACKAGES and EXTRA_PIP_PACKAGES . These environment variables may be used to ENV EXTRA_CONDA_PACKAGES ENV EXTRA_PIP_PACKAGES=\"\" Serialization","title":"Scheduling"},{"location":"developer/services/scheduling/#scheduling-service","text":"","title":"Scheduling Service"},{"location":"developer/services/scheduling/#prefect","text":"using Prefect version 1.2.X The Prefect server is composed of sub-services ... Agents run externally to the Prefect server and manage job submissions in different contexts. In order to register an agent with Prefect, you must first create a tenant...","title":"Prefect"},{"location":"developer/services/scheduling/#serialization","text":"Flow level parameters must be json serializable","title":"serialization..."},{"location":"developer/services/scheduling/#flows","text":"Prefect 1.0 does not support running of subflows directly within a flow so we can't construct flows like: with Flow(\"flow-a\") as flow_a: a() b() with Flow(\"parent-flow\") as flow: c() flow_a.run(executor=LocalDaskExecutor()) flow.run(executor=LocalDaskExecutor()) Instead and unfortunately, flow-of-flow composition requires registration of the flow with a project on the Prefect server and query of tasks by result. Prefect 2.0 will support subflow registration. with Flow(\"local-results1\") as flow: x = Parameter(\"x\") y = check(x) downstream_task(y) flow.register(project_name=\"test-res\") with Flow(\"parent\") as flow2: three = return_3() flow_run = create_flow_run(flow_name=\"local-results1\", parameters={\"x\": three}) flow_wait = wait_for_flow_run(flow_run, raise_final_state=True) root_task_res = get_task_run_result(flow_run, \"downstream_task-1\") downstream_res = get_task_run_result(flow_run, \"test-slug\") The schema in lume_services.services.scheduling.schema.flow_of_flows_schema.py defines the flow of flow configuration compose method on the FlowOfFlows object organizes flows New parameters are created using the scheme {flow_name}-{param_name}","title":"Flows"},{"location":"developer/services/scheduling/#tasks","text":"load_db_result vs LoadDBResult Db results assumes one save per flow Allows multiple file results","title":"Tasks"},{"location":"developer/services/scheduling/#docker-image","text":"The docker image packaged with this repository is designed to provide a base image with ... docker build --build-arg LUME_SERVICES_REPOSITORY=$LUME_SERVICES_REPOSITORY --build-arg PREFECT_VERSION=$PREFECT_VERSION --build-arg LUME_SERVICES_VERSION=$LUME_SERVICES_VERSION --target dev -t test-agent-dev -f prefect-agent-docker/Dockerfile . docker build --build-arg LUME_SERVICES_REPOSITORY=$LUME_SERVICES_REPOSITORY --build-arg PREFECT_VERSION=$PREFECT_VERSION --build-arg LUME_SERVICES_VERSION=$LUME_SERVICES_VERSION --target dev -t test-dev-prefect -f prefect-agent-docker/Dockerfile . docker run -v /var/run/docker.sock:/var/run/docker.sock -it test-agent-dev At runtime, the container accepts two additional environment variables: EXTRA_CONDA_PACKAGES and EXTRA_PIP_PACKAGES . These environment variables may be used to ENV EXTRA_CONDA_PACKAGES ENV EXTRA_PIP_PACKAGES=\"\"","title":"Docker Image"},{"location":"developer/services/scheduling/#serialization_1","text":"","title":"Serialization"},{"location":"services/files/","text":"File service The file service is intented to provide an abstraction to filesystem read/writes allowing for the the implementation of interfaces to remote or mounted resources. The file service can be configured to interface with multiple Filesystem resources. LUME-serices is packaged with LocalFilesystem and MountedFilesystem implementations, however, the Filesystem interface defined in lume_services.services.files.filesystems.filesystem can be used to implement any number of custom interfaces including remote cloud services. Filesystems Filesystems may be defined in a .ini file and provided at runtime [local] identifier=local [mounted] identifier=workdir mount_alias=\"/workdir\" mount_path=\"%(workdir)s\" Mount types: # types associated with mounting host filesystem to kubernetes # https://kubernetes.io/docs/concepts/storage/volumes/#hostpath directory = \"Directory\" # directory must exist at given path directory_or_create = ( \"DirectoryOrCreate\" # if directory does not exist, directory created ) file = \"File\" # file must exist at path file_or_create = \"FileOrCreate\" # will create file if does not exist # socket = \"Socket\" # Unix socket must exist at given path # char_device = \"CharDevice\" # Character device must exist at given path # block_device = \"BlockDevice\" # block device must exist at given path","title":"File Service"},{"location":"services/files/#file-service","text":"The file service is intented to provide an abstraction to filesystem read/writes allowing for the the implementation of interfaces to remote or mounted resources. The file service can be configured to interface with multiple Filesystem resources. LUME-serices is packaged with LocalFilesystem and MountedFilesystem implementations, however, the Filesystem interface defined in lume_services.services.files.filesystems.filesystem can be used to implement any number of custom interfaces including remote cloud services.","title":"File service"},{"location":"services/files/#filesystems","text":"Filesystems may be defined in a .ini file and provided at runtime [local] identifier=local [mounted] identifier=workdir mount_alias=\"/workdir\" mount_path=\"%(workdir)s\" Mount types: # types associated with mounting host filesystem to kubernetes # https://kubernetes.io/docs/concepts/storage/volumes/#hostpath directory = \"Directory\" # directory must exist at given path directory_or_create = ( \"DirectoryOrCreate\" # if directory does not exist, directory created ) file = \"File\" # file must exist at path file_or_create = \"FileOrCreate\" # will create file if does not exist # socket = \"Socket\" # Unix socket must exist at given path # char_device = \"CharDevice\" # Character device must exist at given path # block_device = \"BlockDevice\" # block device must exist at given path","title":"Filesystems"},{"location":"services/hpc/","text":"HPC service The HPC service packaged here defines an interface for interacting with HPC compute tools...","title":"HPC Service"},{"location":"services/hpc/#hpc-service","text":"The HPC service packaged here defines an interface for interacting with HPC compute tools...","title":"HPC service"},{"location":"services/models/","text":"Environment resolution","title":"Modeling Service"},{"location":"services/models/#environment-resolution","text":"","title":"Environment resolution"},{"location":"services/results/","text":"Results database service Model documents Model documents define the schema for a model's stored results Files Results Database Entries Results objects provide an easy interface with ... PrefectResults stored in Prefect Core's server Generic Impact Custom Subclasses of the generic Result must define the model_type as a pydantic field with the alias collection . class CustomResult(Result): \"\"\"Extends Result base and implements model specific attributes\"\"\" model_type: str = Field(\"MyCustomModel\", alias=\"collection\") LUME-services is packaged with seveal pre-configured model results: Impact , Generic The model categories Development In the event that a different result storage scheme would like to be used the steps are as followed: 1. Subclass result - 2. Creation of database service - Implementation of ResultsDB class in lume_services.services.results.db . - Methods should manage connections (multiprocessing and thread-safe) & translate above custom document representations to database from lume_services.services.results.db import ResultsDB, ResultsDBConfig from lume_services.services.results.results_service import ResultsDBService class MyCustomDB(ResultsDB): ... class CustomDBServiceConfig(ResultsDBConfig): url: str custom_db_service_config = CustomDBServiceConfig( url=\"blah://my-connection-url\", ) my_db_service = MyCustomDBService( custom_db_service_config ) results_db_service = ResultsDBService(my_db_service) Result documents Results are organized into artifacts called documents Custom indices It may be useful to overwrite the indices given in the base class... User roles https://www.mongodb.com/docs/manual/core/collection-level-access-control/","title":"Results DB Service"},{"location":"services/results/#results-database-service","text":"","title":"Results database service"},{"location":"services/results/#model-documents","text":"Model documents define the schema for a model's stored results","title":"Model documents"},{"location":"services/results/#files","text":"","title":"Files"},{"location":"services/results/#results-database-entries","text":"Results objects provide an easy interface with ... PrefectResults stored in Prefect Core's server","title":"Results Database Entries"},{"location":"services/results/#generic","text":"","title":"Generic"},{"location":"services/results/#impact","text":"","title":"Impact"},{"location":"services/results/#custom","text":"Subclasses of the generic Result must define the model_type as a pydantic field with the alias collection . class CustomResult(Result): \"\"\"Extends Result base and implements model specific attributes\"\"\" model_type: str = Field(\"MyCustomModel\", alias=\"collection\")","title":"Custom"},{"location":"services/results/#_1","text":"LUME-services is packaged with seveal pre-configured model results: Impact , Generic The model categories","title":""},{"location":"services/results/#development","text":"In the event that a different result storage scheme would like to be used the steps are as followed: 1. Subclass result - 2. Creation of database service - Implementation of ResultsDB class in lume_services.services.results.db . - Methods should manage connections (multiprocessing and thread-safe) & translate above custom document representations to database from lume_services.services.results.db import ResultsDB, ResultsDBConfig from lume_services.services.results.results_service import ResultsDBService class MyCustomDB(ResultsDB): ... class CustomDBServiceConfig(ResultsDBConfig): url: str custom_db_service_config = CustomDBServiceConfig( url=\"blah://my-connection-url\", ) my_db_service = MyCustomDBService( custom_db_service_config ) results_db_service = ResultsDBService(my_db_service)","title":"Development"},{"location":"services/results/#result-documents","text":"Results are organized into artifacts called documents","title":"Result documents"},{"location":"services/results/#custom-indices","text":"It may be useful to overwrite the indices given in the base class...","title":"Custom indices"},{"location":"services/results/#user-roles","text":"https://www.mongodb.com/docs/manual/core/collection-level-access-control/","title":"User roles"},{"location":"services/scheduling/","text":"Scheduling Service https://docs.prefect.io/core/concepts/configuration.html#user-configuration Scheduling service provides interface to Prefect Scheduling Configurable backends Backend returns a Prefect Run Config Prefect Core functionality - Ability to programatically create workflows - functional organization of workflow steps - mapping the outputs of one task to inputs of another - result persistence - Specifications for how to store the workflows How LUME-services uses Prefect: - Creation of workflows - Workflows defined a single flow file packaged with a project - Backends The Scheduling Service is set up to interface with different backends. Kubernetes Docker Agents Kubernetes Configuring with dictionary Local Configuring with dictionary Labels Results Results stored in Prefect backend Files Files FileResults require passing of a serializer Packaged with HDF5Result and TextResult get_file_result task will load results with packaged types DB Result Other results can be created very easily by composing a class from the generic lume_services.files.File class with a custom serializer with base class lume.serializers.base.SerializerBase . For example: from typing import List import csv from lume.serializers.base import SerializerBase from lume_services.files import File class CSVSerializer(SerializerBase): # serialize a csv with data represented as list of list w/ fields as first element def serialize(self, filename, data: List[list]): # writing to csv file with open(filename, 'w') as csvfile: # creating a csv writer object csvwriter = csv.writer(csvfile) # writing the fields csvwriter.writerow(list[0]) # writing the data rows csvwriter.writerows(list[1:]) @classmethod def deserialize(cls, filename): data = [] # opening the CSV file with open(filename, mode ='r')as file: # reading the CSV file csv_file = csv.reader(file) for line in csv_file: data += line CSVFile = File[CSVSerializer] MongoDB ... Flow-of-flows composition Flow-of-flows may be registered with Prefect using a YAML spec file describing the flow progression and mapping of flow outputs to input parameters. In the spec, flows are defined in semi-ordered execution, with dependencies occuring before flow definition if using upstream parameters. Validation with pydantic models FlowOfFlows","title":"Scheduling Service"},{"location":"services/scheduling/#scheduling-service","text":"https://docs.prefect.io/core/concepts/configuration.html#user-configuration Scheduling service provides interface to Prefect Scheduling Configurable backends Backend returns a Prefect Run Config","title":"Scheduling Service"},{"location":"services/scheduling/#prefect","text":"Core functionality - Ability to programatically create workflows - functional organization of workflow steps - mapping the outputs of one task to inputs of another - result persistence - Specifications for how to store the workflows How LUME-services uses Prefect: - Creation of workflows - Workflows defined a single flow file packaged with a project -","title":"Prefect"},{"location":"services/scheduling/#backends","text":"The Scheduling Service is set up to interface with different backends.","title":"Backends"},{"location":"services/scheduling/#kubernetes","text":"","title":"Kubernetes"},{"location":"services/scheduling/#docker","text":"","title":"Docker"},{"location":"services/scheduling/#agents","text":"","title":"Agents"},{"location":"services/scheduling/#kubernetes_1","text":"Configuring with dictionary","title":"Kubernetes"},{"location":"services/scheduling/#local","text":"Configuring with dictionary","title":"Local"},{"location":"services/scheduling/#labels","text":"","title":"Labels"},{"location":"services/scheduling/#results","text":"Results stored in Prefect backend","title":"Results"},{"location":"services/scheduling/#files","text":"Files FileResults require passing of a serializer Packaged with HDF5Result and TextResult get_file_result task will load results with packaged types","title":"Files"},{"location":"services/scheduling/#db-result","text":"Other results can be created very easily by composing a class from the generic lume_services.files.File class with a custom serializer with base class lume.serializers.base.SerializerBase . For example: from typing import List import csv from lume.serializers.base import SerializerBase from lume_services.files import File class CSVSerializer(SerializerBase): # serialize a csv with data represented as list of list w/ fields as first element def serialize(self, filename, data: List[list]): # writing to csv file with open(filename, 'w') as csvfile: # creating a csv writer object csvwriter = csv.writer(csvfile) # writing the fields csvwriter.writerow(list[0]) # writing the data rows csvwriter.writerows(list[1:]) @classmethod def deserialize(cls, filename): data = [] # opening the CSV file with open(filename, mode ='r')as file: # reading the CSV file csv_file = csv.reader(file) for line in csv_file: data += line CSVFile = File[CSVSerializer] MongoDB ...","title":"DB Result"},{"location":"services/scheduling/#flow-of-flows-composition","text":"Flow-of-flows may be registered with Prefect using a YAML spec file describing the flow progression and mapping of flow outputs to input parameters. In the spec, flows are defined in semi-ordered execution, with dependencies occuring before flow definition if using upstream parameters. Validation with pydantic models FlowOfFlows","title":"Flow-of-flows composition"}]}